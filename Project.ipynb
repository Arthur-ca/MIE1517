{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arthur-ca/MIE1517/blob/Jing-Guo/Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yq0MKgApDInX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "import torchvision\n",
        "from torchvision import datasets, models\n",
        "from collections import defaultdict\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms.functional as F1\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
        "from torchvision.datasets import ImageFolder\n",
        "import cv2 as cv\n",
        "# import tensorflow as tf\n",
        "import gc\n",
        "from collections import Counter\n",
        "import imgaug.augmenters as iaa\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjxPEAukDNt-",
        "outputId": "53008d8c-ceb6-477f-8410-fdb94d442ddc"
      },
      "outputs": [],
      "source": [
        "#First link it to google drive and check the subfolder of the data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive_content = os.listdir('/content/gdrive/My Drive/ColabNotebooks/archive')\n",
        "print(drive_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6_Ip_NB52CQ",
        "outputId": "440bc302-033a-49fe-e00e-f06bc2e8c711"
      },
      "outputs": [],
      "source": [
        "classeses = []\n",
        "for i in os.listdir('C:/Users/Admin/Desktop/MIE1517_Project/data'):\n",
        "    if i!=5:\n",
        "        classeses.append(i)\n",
        "classeses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjPs44Ion4HI",
        "outputId": "9e46df40-654e-4f44-ad67-d958ccd49889"
      },
      "outputs": [],
      "source": [
        "features_or = []\n",
        "labels_or = []\n",
        "train_data_or = []\n",
        "data_transform1 = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "def create_train2():\n",
        "    for i, photo in enumerate(classeses):\n",
        "        path = os.path.join('C:/Users/Admin/Desktop/MIE1517_Project/data', photo)\n",
        "        label = i  # Use the index of the class as the label\n",
        "\n",
        "        # Loop over to get every image in the current class\n",
        "        for img_name in os.listdir(path):\n",
        "            img_path = os.path.join(path, img_name)\n",
        "            img_pil = cv.imread(img_path)\n",
        "            img_pil = Image.fromarray(cv.cvtColor(img_pil, cv.COLOR_BGR2RGB))\n",
        "            transformed_image1 = data_transform1(img_pil)\n",
        "\n",
        "            if img_pil is None:\n",
        "                print(\"Error loading image:\", img_pil)\n",
        "                continue\n",
        "            # Append the original image and its label to the list\n",
        "            features_or.append(transformed_image1)\n",
        "            labels_or.append(label)\n",
        "\n",
        "            train_data_or.append([img_pil, label])\n",
        "create_train2()\n",
        "print(type(features_or[0]))\n",
        "# Count the occurrences of each label\n",
        "label_counts_or = Counter(labels_or)\n",
        "\n",
        "# Print the label counts\n",
        "for label, count in label_counts_or.items():\n",
        "    print(f\"Label {label}: {count} images\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mplacBAwPZbA",
        "outputId": "2cce35cf-bcfc-4ae4-c929-e29c38fc4249"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define the classes (folders) in your dataset\n",
        "classes = os.listdir('C:/Users/Admin/Desktop/MIE1517_Project/data')\n",
        "\n",
        "# Initialize empty lists for features (transformed images) and labels\n",
        "features = []\n",
        "labels = []\n",
        "\n",
        "data_transform2 = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomRotation(degrees=(-50, 50)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "data_transform3 = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "data_transform5 = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.GaussianBlur(kernel_size=(7, 13), sigma=(9, 11)),  # The argument here specifies the radius, not kernel size\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "\n",
        "def create_train():\n",
        "    for i, photo in enumerate(classes):\n",
        "        path = os.path.join('C:/Users/Admin/Desktop/MIE1517_Project/data', photo)\n",
        "        label = i  # Use the index of the class as the label\n",
        "\n",
        "        # Loop over to get every image in the current class\n",
        "        for img_name in os.listdir(path):\n",
        "            img_path = os.path.join(path, img_name)\n",
        "            img_pil = cv.imread(img_path)\n",
        "\n",
        "            if img_pil is None:\n",
        "                print(\"Error loading image:\", img_path)\n",
        "                continue\n",
        "            # Append the original image and its label to the list\n",
        "            # features.append(np.array(img_array))\n",
        "            # labels.append(label)\n",
        "\n",
        "            # Apply the defined transformations\n",
        "            img_pil = Image.fromarray(cv.cvtColor(img_pil, cv.COLOR_BGR2RGB))\n",
        "            transformed_image1 = data_transform2(img_pil)\n",
        "            #print(f\"1:{type(transformed_image1)}\")\n",
        "            #transformed_image2 = data_transform2(img_pil)\n",
        "            transformed_image3 = data_transform3(img_pil)\n",
        "            #print(f\"3:{type(transformed_image3)}\")\n",
        "            features.append(np.array(transformed_image1))\n",
        "            #features.append(np.array(transformed_image2))\n",
        "            features.append(np.array(transformed_image3))\n",
        "            labels.append(label)\n",
        "            labels.append(label)\n",
        "            #labels.append(label)\n",
        "            # train_data.append([transformed_image1, label])\n",
        "            # #train_data.append([transformed_image2, label])\n",
        "            # train_data.append([transformed_image3, label])\n",
        "create_train()\n",
        "\n",
        "# Count the occurrences of each label\n",
        "label_counts = Counter(labels)\n",
        "\n",
        "# Print the label counts\n",
        "for label, count in label_counts.items():\n",
        "    print(f\"Label {label}: {count} images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRyc-kNk2560",
        "outputId": "8accac54-d49a-43a7-ba91-f99b6e1d0db8"
      },
      "outputs": [],
      "source": [
        "n = 0\n",
        "for images in features_or:\n",
        "    print(f\"Image Data Type: {type(images)}\")\n",
        "    n=n+1\n",
        "    if n>10:\n",
        "      break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EifcKpmBYmz",
        "outputId": "bf50da8e-7782-4b5f-a135-8ced94658e6b"
      },
      "outputs": [],
      "source": [
        "n = 0\n",
        "for image in features_or:\n",
        "    if isinstance(image, np.ndarray):\n",
        "        image = torch.from_numpy(image).permute(2, 0, 1)\n",
        "for images in features_or:\n",
        "    print(f\"Image Data Type: {type(images)}\")\n",
        "    print(f\"Image Data Type: {images.shape}\")\n",
        "    n=n+1\n",
        "    if n>10:\n",
        "      break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "z61XyoRXbiYm",
        "outputId": "6180a704-6f0e-4a59-843c-70cebd9e227e"
      },
      "outputs": [],
      "source": [
        "def show_images(images, labels):\n",
        "    num_images = len(images)\n",
        "    rows = int(np.sqrt(num_images))\n",
        "    cols = int(np.ceil(num_images / rows))\n",
        "\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(5, 5))\n",
        "\n",
        "    for i, (image, label) in enumerate(zip(images, labels)):\n",
        "        ax = axes.flatten()[i]\n",
        "        ax.imshow(np.transpose(image, (1, 2, 0)))  # Swap axes for NumPy array\n",
        "        ax.set_title(f\"Label: {label}\")\n",
        "        ax.axis(\"off\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Iterate over the DataLoader\n",
        "for label in range(len(classes)):  # Assuming 'classes' contains the class names\n",
        "    # Filter images for the current label\n",
        "    label_indices = [i for i, l in enumerate(labels) if l == label]\n",
        "\n",
        "    # Randomly choose 5 images from the filtered indices\n",
        "    chosen_indices = np.random.choice(label_indices, size=min(8, len(label_indices)), replace=False)\n",
        "\n",
        "    # Extract images and labels for the chosen indices\n",
        "    chosen_images = [features[i] for i in chosen_indices]\n",
        "    chosen_labels = [labels[i] for i in chosen_indices]\n",
        "\n",
        "    # Show images for the current label\n",
        "    show_images(chosen_images, chosen_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOcsfB_6d-9P"
      },
      "outputs": [],
      "source": [
        "\n",
        "from torchvision import transforms\n",
        "from collections import defaultdict\n",
        "labels = labels_or\n",
        "features = features_or\n",
        "# Shuffle the labels and features in the same order\n",
        "combined = list(zip(labels, features))\n",
        "labels, features = zip(*combined)\n",
        "\n",
        "# Create a dictionary to store images by label\n",
        "label_to_images = defaultdict(list)\n",
        "\n",
        "# Group images by label\n",
        "for label, img in zip(labels, features):\n",
        "    label_to_images[label].append(img)\n",
        "\n",
        "# Set the ratios for train, validation, and test sets\n",
        "train_ratio = 0.6\n",
        "validation_ratio = 0.2\n",
        "test_ratio = 0.2\n",
        "\n",
        "train_data = []\n",
        "validation_data = []\n",
        "test_data = []\n",
        "\n",
        "# Split data for each label\n",
        "for label, images in label_to_images.items():\n",
        "    random.shuffle(images)  # Shuffle the images for each label\n",
        "\n",
        "    num_images = len(images)\n",
        "    num_train = int(train_ratio * num_images)\n",
        "    num_validation = int(validation_ratio * num_images)\n",
        "    num_test = num_images - num_train - num_validation\n",
        "\n",
        "    train_data.extend([(img, label) for img in images[:num_train]])\n",
        "    validation_data.extend([(img, label) for img in images[num_train:num_train + num_validation]])\n",
        "    test_data.extend([(img, label) for img in images[num_train + num_validation:]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0p-HrE4hxpNI",
        "outputId": "6df82cb9-d41d-485e-ab7b-6bd08c61d33a"
      },
      "outputs": [],
      "source": [
        "\n",
        "sample_index = 0  # Change this to the index of the sample you want to inspect\n",
        "\n",
        "for i in range(15):\n",
        "    sample_data, sample_label = test_data[i]\n",
        "    print(\"Sample data shape:\", sample_data.shape)\n",
        "\n",
        "print(\"Sample label:\", sample_label)\n",
        "print(len(test_data))\n",
        "print(len(validation_data))\n",
        "print(len(train_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2QuytyAZaIt",
        "outputId": "ce828303-3259-4ba0-d716-98df136a658c"
      },
      "outputs": [],
      "source": [
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img, label = self.data[index]\n",
        "\n",
        "        # Convert img to PyTorch tensor\n",
        "        img_tensor = torch.tensor(img, dtype=torch.float32)\n",
        "\n",
        "        return img_tensor, label\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = CustomDataset(train_data)\n",
        "validation_dataset = CustomDataset(validation_data)\n",
        "test_dataset = CustomDataset(test_data)\n",
        "\n",
        "# Create DataLoader instances\n",
        "batch_size = 64  # You can adjust this based on your needs\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Check the tensor size\n",
        "for images, labels in train_loader:\n",
        "    print(images.size())  # This will print the size of the tensor\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "Old Model and train func\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "In9y4e4UPIBo"
      },
      "outputs": [],
      "source": [
        "class CNNLargeNet(nn.Module):\n",
        "    def __init__(self, output1=32, output2=64, output3=128, output4=256):\n",
        "        super(CNNLargeNet, self).__init__()\n",
        "        self.name = \"large\"\n",
        "        \n",
        "        # Define the sequential layers\n",
        "        self.features = nn.Sequential(\n",
        "            # Convolutional Layer 1\n",
        "            nn.Conv2d(3, output1, kernel_size=7, stride=1, padding=3),\n",
        "            nn.BatchNorm2d(output1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(p=0.3),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            \n",
        "            # Convolutional Layer 2\n",
        "            nn.Conv2d(output1, output2, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(output2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(p=0.3),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            \n",
        "            # Convolutional Layer 3\n",
        "            nn.Conv2d(output2, output3, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(output3),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(p=0.3),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            \n",
        "            # Convolutional Layer 4\n",
        "            nn.Conv2d(output3, output4, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(output4),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(p=0.3),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "        \n",
        "        # Flatten the tensor for the fully connected layers\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(output4 * 14 * 14, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.3),\n",
        "            \n",
        "            nn.Linear(128, 64),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.3),\n",
        "            \n",
        "            nn.Linear(64, 8)  # Assuming 8 output classes\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)  # Pass the input through the feature layers\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor for the classifier\n",
        "        x = self.classifier(x)  # Pass the flattened tensor through the classifier\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqI-e7OXPE-F"
      },
      "outputs": [],
      "source": [
        "def trainmodel(model, train_dataset, val_dataset, batch=32, learningRate=0.01, num_epochs=500):\n",
        "    # Create loss function and optimizer.\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learningRate)\n",
        "    # Load data\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch, shuffle=True)\n",
        "    # Create accuracy lists\n",
        "    iters, losses, train_accuracy, validation_accuracy = [], [], [], []\n",
        "    n = 0  # Initialize the iteration counter\n",
        "    # Train the data\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for batch_data in train_loader:\n",
        "            imgs, labels = batch_data\n",
        "            # img_to_tensor = transforms.ToTensor()\n",
        "            # imgs = img_to_tensor(image)\n",
        "            if use_cuda and torch.cuda.is_available():\n",
        "                imgs = imgs.cuda()\n",
        "                labels = labels.cuda()\n",
        "\n",
        "            out = model(imgs)  # Forward pass\n",
        "            loss = criterion(out, labels)  # Compute the total loss\n",
        "            loss.backward()  # Backward pass (compute parameter updates)\n",
        "            optimizer.step()  # Make the updates for each parameter\n",
        "            optimizer.zero_grad()  # A clean-up step for PyTorch\n",
        "            n += 1\n",
        "            # print(\"Input image data type:\", imgs.dtype)\n",
        "            # print(\"Model parameters data types:\")\n",
        "            # for param in model.parameters():\n",
        "            #     print(param.dtype)\n",
        "            # Save the current training information\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        iters.append(n)\n",
        "        losses.append(running_loss / len(train_loader))  # Compute average loss for the epoch\n",
        "        train_accuracy.append(get_accuracy(model, train_dataset))  # Compute training accuracy\n",
        "\n",
        "        # Compute validation accuracy for this epoch\n",
        "        validation_accuracy.append(get_accuracy(model, val_dataset))  # Compute validation accuracy\n",
        "\n",
        "        # Print progress for the epoch\n",
        "        print(\"Epoch {}, Train Accuracy: {:.6f}%, Validation Accuracy: {:.6f}%\".format(\n",
        "            epoch, train_accuracy[epoch], validation_accuracy[epoch]))\n",
        "\n",
        "        # Save model checkpoint\n",
        "        model_checkpoint_path = 'C:/Users/Admin/Desktop/MIE1517_Project/output'  # You can change the directory as needed\n",
        "        model_checkpoint_file = os.path.join(model_checkpoint_path, f'{model.name} =Batch_size_{batch}_model_epoch{epoch + 1}.pth')\n",
        "        torch.save(model.state_dict(), model_checkpoint_file)\n",
        "        print(f\"Saved model checkpoint: {model_checkpoint_file}\")\n",
        "\n",
        "    print(\"Finished Training\")\n",
        "    return iters, losses, train_accuracy, validation_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "End Old Model and train func\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNNLargeNet2(nn.Module):\n",
        "    def __init__( self, output1=32, output2=64, output3=128, output4=256):\n",
        "        super(CNNLargeNet2, self).__init__()\n",
        "        self.name = \"CNN\"\n",
        "        \n",
        "        # Define the sequential layers for feature extraction\n",
        "        self.features = nn.Sequential(\n",
        "            # Convolutional Layer 1\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            \n",
        "            # Convolutional Layer 2\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # Convolutional Layer 3\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # Convolutional Layer 4\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # Convolutional Layer 5\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "        \n",
        "        # Flatten the tensor for the fully connected layers\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(512, 8)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)  # Pass the input through the feature layers\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor for the classifier\n",
        "        x = self.classifier(x)  # Pass the flattened tensor through the classifier\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_model_name(name, batch_size, learning_rate, epoch):\n",
        "    path = \"model_{0}_bs{1}_lr{2}_epoch{3}\".format(name, batch_size, learning_rate, epoch)\n",
        "    return path\n",
        "\n",
        "def evaluate(model, loader):\n",
        "    \"\"\" Evaluate the network \"\"\"\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in loader:\n",
        "      if use_cuda and torch.cuda.is_available():\n",
        "        inputs = inputs.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "      outputs = model(inputs)\n",
        "      predicted = outputs.max(1, keepdim=True)[1]\n",
        "      total += inputs.shape[0]\n",
        "      correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
        "    return correct / total\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def trainmodel2(model, train_dataset, val_dataset, batch=64, learningRate=0.03, num_epochs=300):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learningRate)\n",
        "    \n",
        "    model_checkpoint_path = 'C:/Users/Admin/Desktop/MIE1517_Project/output'  # You can change the directory as needed\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch, shuffle=False) \n",
        "\n",
        "    train_accuracy = np.zeros(num_epochs)\n",
        "    train_losses = np.zeros(num_epochs)\n",
        "    validation_accuracy = np.zeros(num_epochs)\n",
        "    validation_losses = np.zeros(num_epochs)\n",
        "    iters = []\n",
        "\n",
        "    # Check CUDA availability\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    if use_cuda:\n",
        "        model = model.cuda()\n",
        "\n",
        "    n = 0  # Initialize the iteration counter\n",
        "    # Training\n",
        "    print(\"Training Begin...\\n\")\n",
        "    start_time = time.time()\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set the model to training mode\n",
        "        running_loss = 0.0\n",
        "        \n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            # Get the inputs\n",
        "            inputs, labels = data\n",
        "            # Set up for gpu running\n",
        "            if use_cuda and torch.cuda.is_available():\n",
        "                inputs = inputs.cuda()\n",
        "                labels = labels.cuda()\n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "            # Forward pass, backward pass, and optimize\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            n += 1\n",
        "            # Calculate loss\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        train_losses[epoch] = running_loss\n",
        "        train_accuracy[epoch] = evaluate(model, train_loader)\n",
        "\n",
        "        model.eval()  # Set the model to evaluation mode for accuracy computation\n",
        "        valid_loss = 0.0\n",
        "        # Running without gradients are computed and model weights update\n",
        "        for inputs, labels in val_loader:\n",
        "            if use_cuda and torch.cuda.is_available():\n",
        "                inputs = inputs.cuda()\n",
        "                labels = labels.cuda()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            valid_loss += loss.item()\n",
        "\n",
        "        validation_losses[epoch] = valid_loss\n",
        "        validation_accuracy[epoch] = evaluate(model, val_loader)\n",
        "        iters.append(n)\n",
        "        \n",
        "        # Print progress for the epoch\n",
        "        print((\"Epoch {}: Train Accuracy: {}, Train loss: {} |\"+\n",
        "               \"Validation Accuracy: {}, Validation loss: {}\").format(\n",
        "                   epoch + 1,\n",
        "                   train_accuracy[epoch],\n",
        "                   train_losses[epoch],\n",
        "                   validation_accuracy[epoch],\n",
        "                   validation_losses[epoch]))\n",
        "\n",
        "        # Save model checkpoint every 5 epochs\n",
        "        # if (epoch + 1) % 5 == 0:  # +1 because epochs start from 0\n",
        "            # Save the current model checkpoint to a file\n",
        "        model_path = get_model_name(model.name, batch_size, learningRate, epoch)\n",
        "        model_path = os.path.join(model_checkpoint_path, model_path)\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "\n",
        "    print(\"Finshied Training\")\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    print(\"Total time elapsed: {:.2f} seconds\".format(elapsed_time))\n",
        "    # Write the train/test loss/err into CSV file for plotting later\n",
        "    # Save model checkpoint\n",
        "    epochs = np.arange(1, num_epochs + 1)\n",
        "    np.savetxt(\"{}_train_acc.csv\".format(model_path), train_accuracy)\n",
        "    np.savetxt(\"{}_train_loss.csv\".format(model_path), train_losses)\n",
        "    np.savetxt(\"{}_val_acc.csv\".format(model_path), validation_accuracy)\n",
        "    np.savetxt(\"{}_val_loss.csv\".format(model_path), validation_losses)\n",
        "\n",
        "    plt.title(\"Training Loss Curve\")\n",
        "    plt.plot(iters, train_losses, label=\"Train\")\n",
        "    plt.xlabel(\"iters\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Accuracy Curve\")\n",
        "    plt.plot(iters, train_accuracy, label=\"Train\")\n",
        "    plt.xlabel(\"iters\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.show()\n",
        "    print(\"Finished Training\")\n",
        "    return iters, train_losses, train_accuracy, validation_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HbBsnUppOWft"
      },
      "outputs": [],
      "source": [
        "def trainSmall(model, data, batch_size=32, learning_rate=0.01, num_epochs=260):\n",
        "    train_loader = torch.utils.data.DataLoader(data, batch_size=batch_size)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    train_acc = []\n",
        "\n",
        "    # training\n",
        "    print(\"Training Start\")\n",
        "    n = 0  # the number of iterations\n",
        "    for epoch in range(num_epochs):\n",
        "        for imgs, labels in iter(train_loader):\n",
        "            #############################################\n",
        "            # To Enable GPU Usage\n",
        "            imgs = imgs.cuda()\n",
        "            labels = labels.cuda()\n",
        "            #############################################\n",
        "\n",
        "            # Check if imgs is already a tensor\n",
        "            if not torch.is_tensor(imgs):\n",
        "                img_to_tensor = transforms.ToTensor()\n",
        "                imgs = img_to_tensor(imgs)\n",
        "\n",
        "                # Convert input to float\n",
        "                imgs = imgs.float()\n",
        "\n",
        "            # Convert the input tensor to the desired type\n",
        "            imgs = imgs.type(torch.float32)\n",
        "\n",
        "            out = model(imgs)  # forward pass\n",
        "            loss = criterion(out, labels)  # compute the total loss\n",
        "            loss.backward()  # backward pass (compute parameter updates)\n",
        "            optimizer.step()  # make the updates for each parameter\n",
        "            optimizer.zero_grad()  # a clean-up step for PyTorch\n",
        "            n += 1\n",
        "\n",
        "        train_accuracy = get_accuracy(model, data)\n",
        "        train_acc.append(train_accuracy)\n",
        "        print(\"Epoch:{}, Accuracy:{}\".format(epoch, train_accuracy))\n",
        "    return train_acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "Miqu5ClEFpms",
        "outputId": "bc5bc88e-72e8-4b5b-9a81-85530686451b"
      },
      "outputs": [],
      "source": [
        "batch_size = 3\n",
        "num_workers = 1\n",
        "small_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
        "\n",
        "# Visualize some sample data\n",
        "classes = ['neutrality', 'sadness', 'fear', 'surprise', 'contempt', 'happiness', 'anger', 'disgust']\n",
        "dataiter = iter(small_loader)\n",
        "images, labels = next(dataiter)\n",
        "images = images.numpy() # convert images to numpy for display\n",
        "\n",
        "# plot the images in the batch, along with the corresponding labels\n",
        "fig = plt.figure(figsize=(25, 4))\n",
        "for idx in np.arange(3):\n",
        "    ax = fig.add_subplot(2, 10, idx+1, xticks=[], yticks=[])\n",
        "\n",
        "    # If the image has three channels\n",
        "    if images[idx].shape[0] == 3:\n",
        "        plt.imshow(np.transpose(images[idx], (1, 2, 0)))\n",
        "    else:  # If the image is grayscale\n",
        "        plt.imshow(images[idx][0], cmap='gray')\n",
        "\n",
        "    ax.set_title(classes[labels[idx]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "bKZlLIGwPd0i",
        "outputId": "b6949fb4-0515-45b8-e331-5cd04032217b"
      },
      "outputs": [],
      "source": [
        "use_cuda = True\n",
        "if torch.cuda.is_available():\n",
        "    model = CNNLargeNet2().cuda()\n",
        "Y = trainmodel2(model, train_data, validation_data)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNKjhrpRYKfoHxX11YR45Ru",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
