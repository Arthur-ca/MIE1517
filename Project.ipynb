{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arthur-ca/MIE1517/blob/Jing-Guo/Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yq0MKgApDInX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "import torchvision\n",
        "from torchvision import datasets, models\n",
        "from collections import defaultdict\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms.functional as F1\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
        "from torchvision.datasets import ImageFolder\n",
        "import cv2 as cv\n",
        "# import tensorflow as tf\n",
        "import gc\n",
        "from collections import Counter\n",
        "import imgaug.augmenters as iaa\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjxPEAukDNt-",
        "outputId": "53008d8c-ceb6-477f-8410-fdb94d442ddc"
      },
      "outputs": [],
      "source": [
        "#First link it to google drive and check the subfolder of the data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive_content = os.listdir('/content/gdrive/My Drive/ColabNotebooks/archive')\n",
        "print(drive_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6_Ip_NB52CQ",
        "outputId": "440bc302-033a-49fe-e00e-f06bc2e8c711"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['anger',\n",
              " 'contempt',\n",
              " 'disgust',\n",
              " 'fear',\n",
              " 'happiness',\n",
              " 'neutrality',\n",
              " 'sadness',\n",
              " 'surprise']"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classeses = []\n",
        "for i in os.listdir('C:/Users/Admin/Desktop/MIE1517_Project/data'):\n",
        "    if i!=5:\n",
        "        classeses.append(i)\n",
        "classeses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "Our dataset contains over 5000 photos. Training on this dataset requires significant computing power. However, the best hardware we have is a computer equipped with an Nvidia RTX2080 GPU. To ensure that the model can be trained on the entire dataset, we plan to use 5% of the original data as our training dataset. Below is our code for extracting a small training dataset, a small training function, and the CNN model structure.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "Label 0: 44 images\n",
            "Label 1: 10 images\n",
            "Label 2: 21 images\n",
            "Label 3: 28 images\n",
            "Label 4: 70 images\n",
            "Label 5: 26 images\n",
            "Label 6: 37 images\n",
            "Label 7: 38 images\n"
          ]
        }
      ],
      "source": [
        "features_or = []\n",
        "labels_or = []\n",
        "train_data_or = []\n",
        "data_transform1 = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "def create_train2(data_percentage=5):\n",
        "    for i, photo in enumerate(classeses):\n",
        "        path = os.path.join('C:/Users/Admin/Desktop/MIE1517_Project/data', photo)\n",
        "        label = i  # Use the index of the class as the label\n",
        "\n",
        "        # List all images in the class folder\n",
        "        img_list = os.listdir(path)\n",
        "\n",
        "        # Calculate the number of images to load (5% of total)\n",
        "        num_images_to_load = int(len(img_list) * (data_percentage / 100))\n",
        "\n",
        "        # Randomly select a subset of images\n",
        "        selected_images = random.sample(img_list, num_images_to_load)\n",
        "\n",
        "\n",
        "        for img_name in selected_images:\n",
        "            img_path = os.path.join(path, img_name)\n",
        "            img_pil = Image.open(img_path)\n",
        "            transformed_image1 = data_transform1(img_pil)\n",
        "\n",
        "            if img_pil is None:\n",
        "                print(\"Error loading image:\", img_path)\n",
        "                continue\n",
        "\n",
        "            # Append the original image and its label to the list\n",
        "            features_or.append(transformed_image1)\n",
        "            labels_or.append(label)\n",
        "\n",
        "            train_data_or.append([img_pil, label])\n",
        "\n",
        "create_train2(data_percentage=5)  # Load only 5% of the data\n",
        "print(type(features_or[0]))\n",
        "# Count the occurrences of each label\n",
        "label_counts_or = Counter(labels_or)\n",
        "\n",
        "# Print the label counts\n",
        "for label, count in label_counts_or.items():\n",
        "    print(f\"Label {label}: {count} images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a transformation to convert PIL images to PyTorch tensors\n",
        "data_transform_to_tensor = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Convert images and labels to PyTorch tensors\n",
        "train_images = torch.stack([data_transform_to_tensor(data[0]) for data in train_data_or])\n",
        "train_labels = torch.tensor([data[1] for data in train_data_or])\n",
        "\n",
        "# Assuming you have a DataLoader for your training loop\n",
        "train_dataset = torch.utils.data.TensorDataset(train_images, train_labels)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_accuracy(model, dataset):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for imgs, labels in torch.utils.data.DataLoader(dataset, batch_size=64):\n",
        "        #############################################\n",
        "        #To Enable GPU Usage\n",
        "        if use_cuda and torch.cuda.is_available():\n",
        "          imgs = imgs.cuda()\n",
        "          labels = labels.cuda()\n",
        "        #############################################\n",
        "        output = model(imgs)\n",
        "        #select index with maximum prediction score\n",
        "        pred = output.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "        total += imgs.shape[0]\n",
        "    return correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def trainSmall(model, data, batch_size=64, learning_rate=0.01, num_epochs=500):\n",
        "    train_loader = torch.utils.data.DataLoader(data, batch_size=batch_size)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    train_acc = []\n",
        "\n",
        "    # training\n",
        "    print(\"Training Start\")\n",
        "    n = 0  # the number of iterations\n",
        "    for epoch in range(num_epochs):\n",
        "        for imgs, labels in iter(train_loader):\n",
        "            #############################################\n",
        "            # To Enable GPU Usage\n",
        "            imgs = imgs.cuda()\n",
        "            labels = labels.cuda()\n",
        "            #############################################\n",
        "\n",
        "            # Check if imgs is already a tensor\n",
        "            if not torch.is_tensor(imgs):\n",
        "                img_to_tensor = transforms.ToTensor()\n",
        "                imgs = img_to_tensor(imgs)\n",
        "\n",
        "                # Convert input to float\n",
        "                imgs = imgs.float()\n",
        "\n",
        "            # Convert the input tensor to the desired type\n",
        "            imgs = imgs.type(torch.float32)\n",
        "\n",
        "            out = model(imgs)  # forward pass\n",
        "            loss = criterion(out, labels)  # compute the total loss\n",
        "            loss.backward()  # backward pass (compute parameter updates)\n",
        "            optimizer.step()  # make the updates for each parameter\n",
        "            optimizer.zero_grad()  # a clean-up step for PyTorch\n",
        "            n += 1\n",
        "\n",
        "        train_accuracy = get_accuracy(model, data)\n",
        "        train_acc.append(train_accuracy)\n",
        "        print(\"Epoch:{}, Accuracy:{}\".format(epoch, train_accuracy))\n",
        "    return train_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNNLargeNet2(nn.Module):\n",
        "    def __init__( self, output1=32, output2=64, output3=128, output4=256):\n",
        "        super(CNNLargeNet2, self).__init__()\n",
        "        self.name = \"CNN\"\n",
        "\n",
        "        # Define the sequential layers for feature extraction\n",
        "        self.features = nn.Sequential(\n",
        "            # Convolutional Layer 1\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # Convolutional Layer 2\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # Convolutional Layer 3\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # Convolutional Layer 4\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # Convolutional Layer 5\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "\n",
        "        # Flatten the tensor for the fully connected layers\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            #nn.Dropout(p=0.5),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            #nn.Dropout(p=0.5),\n",
        "            nn.Linear(512, 8)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)  # Pass the input through the feature layers\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor for the classifier\n",
        "        x = self.classifier(x)  # Pass the flattened tensor through the classifier\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Start\n",
            "Epoch:0, Accuracy:0.1386861313868613\n",
            "Epoch:1, Accuracy:0.10218978102189781\n",
            "Epoch:2, Accuracy:0.1386861313868613\n",
            "Epoch:3, Accuracy:0.2591240875912409\n",
            "Epoch:4, Accuracy:0.15693430656934307\n",
            "Epoch:5, Accuracy:0.18248175182481752\n",
            "Epoch:6, Accuracy:0.18613138686131386\n",
            "Epoch:7, Accuracy:0.20437956204379562\n",
            "Epoch:8, Accuracy:0.20437956204379562\n",
            "Epoch:9, Accuracy:0.22262773722627738\n",
            "Epoch:10, Accuracy:0.22262773722627738\n",
            "Epoch:11, Accuracy:0.21897810218978103\n",
            "Epoch:12, Accuracy:0.22627737226277372\n",
            "Epoch:13, Accuracy:0.22262773722627738\n",
            "Epoch:14, Accuracy:0.22627737226277372\n",
            "Epoch:15, Accuracy:0.2518248175182482\n",
            "Epoch:16, Accuracy:0.21897810218978103\n",
            "Epoch:17, Accuracy:0.21532846715328466\n",
            "Epoch:18, Accuracy:0.22992700729927007\n",
            "Epoch:19, Accuracy:0.21532846715328466\n",
            "Epoch:20, Accuracy:0.23722627737226276\n",
            "Epoch:21, Accuracy:0.22992700729927007\n",
            "Epoch:22, Accuracy:0.24452554744525548\n",
            "Epoch:23, Accuracy:0.24452554744525548\n",
            "Epoch:24, Accuracy:0.25547445255474455\n",
            "Epoch:25, Accuracy:0.2591240875912409\n",
            "Epoch:26, Accuracy:0.25547445255474455\n",
            "Epoch:27, Accuracy:0.25547445255474455\n",
            "Epoch:28, Accuracy:0.31386861313868614\n",
            "Epoch:29, Accuracy:0.3029197080291971\n",
            "Epoch:30, Accuracy:0.35036496350364965\n",
            "Epoch:31, Accuracy:0.354014598540146\n",
            "Epoch:32, Accuracy:0.38686131386861317\n",
            "Epoch:33, Accuracy:0.35766423357664234\n",
            "Epoch:34, Accuracy:0.40875912408759124\n",
            "Epoch:35, Accuracy:0.35036496350364965\n",
            "Epoch:36, Accuracy:0.3467153284671533\n",
            "Epoch:37, Accuracy:0.3357664233576642\n",
            "Epoch:38, Accuracy:0.3795620437956204\n",
            "Epoch:39, Accuracy:0.28832116788321166\n",
            "Epoch:40, Accuracy:0.35766423357664234\n",
            "Epoch:41, Accuracy:0.36496350364963503\n",
            "Epoch:42, Accuracy:0.3722627737226277\n",
            "Epoch:43, Accuracy:0.3722627737226277\n",
            "Epoch:44, Accuracy:0.40875912408759124\n",
            "Epoch:45, Accuracy:0.3686131386861314\n",
            "Epoch:46, Accuracy:0.4124087591240876\n",
            "Epoch:47, Accuracy:0.3686131386861314\n",
            "Epoch:48, Accuracy:0.4416058394160584\n",
            "Epoch:49, Accuracy:0.41605839416058393\n",
            "Epoch:50, Accuracy:0.43795620437956206\n",
            "Epoch:51, Accuracy:0.4416058394160584\n",
            "Epoch:52, Accuracy:0.4343065693430657\n",
            "Epoch:53, Accuracy:0.41605839416058393\n",
            "Epoch:54, Accuracy:0.42700729927007297\n",
            "Epoch:55, Accuracy:0.45255474452554745\n",
            "Epoch:56, Accuracy:0.4927007299270073\n",
            "Epoch:57, Accuracy:0.4306569343065693\n",
            "Epoch:58, Accuracy:0.4854014598540146\n",
            "Epoch:59, Accuracy:0.4744525547445255\n",
            "Epoch:60, Accuracy:0.4343065693430657\n",
            "Epoch:61, Accuracy:0.4744525547445255\n",
            "Epoch:62, Accuracy:0.5255474452554745\n",
            "Epoch:63, Accuracy:0.4708029197080292\n",
            "Epoch:64, Accuracy:0.48905109489051096\n",
            "Epoch:65, Accuracy:0.5\n",
            "Epoch:66, Accuracy:0.5255474452554745\n",
            "Epoch:67, Accuracy:0.49635036496350365\n",
            "Epoch:68, Accuracy:0.5291970802919708\n",
            "Epoch:69, Accuracy:0.5328467153284672\n",
            "Epoch:70, Accuracy:0.5255474452554745\n",
            "Epoch:71, Accuracy:0.5656934306569343\n",
            "Epoch:72, Accuracy:0.5109489051094891\n",
            "Epoch:73, Accuracy:0.5693430656934306\n",
            "Epoch:74, Accuracy:0.583941605839416\n",
            "Epoch:75, Accuracy:0.5182481751824818\n",
            "Epoch:76, Accuracy:0.5583941605839416\n",
            "Epoch:77, Accuracy:0.4708029197080292\n",
            "Epoch:78, Accuracy:0.5656934306569343\n",
            "Epoch:79, Accuracy:0.38321167883211676\n",
            "Epoch:80, Accuracy:0.2737226277372263\n",
            "Epoch:81, Accuracy:0.3978102189781022\n",
            "Epoch:82, Accuracy:0.43795620437956206\n",
            "Epoch:83, Accuracy:0.4708029197080292\n",
            "Epoch:84, Accuracy:0.3722627737226277\n",
            "Epoch:85, Accuracy:0.4124087591240876\n",
            "Epoch:86, Accuracy:0.42700729927007297\n",
            "Epoch:87, Accuracy:0.5182481751824818\n",
            "Epoch:88, Accuracy:0.5072992700729927\n",
            "Epoch:89, Accuracy:0.49635036496350365\n",
            "Epoch:90, Accuracy:0.4343065693430657\n",
            "Epoch:91, Accuracy:0.4197080291970803\n",
            "Epoch:92, Accuracy:0.3357664233576642\n",
            "Epoch:93, Accuracy:0.4051094890510949\n",
            "Epoch:94, Accuracy:0.4635036496350365\n",
            "Epoch:95, Accuracy:0.48175182481751827\n",
            "Epoch:96, Accuracy:0.3978102189781022\n",
            "Epoch:97, Accuracy:0.40145985401459855\n",
            "Epoch:98, Accuracy:0.4306569343065693\n",
            "Epoch:99, Accuracy:0.4416058394160584\n",
            "Epoch:100, Accuracy:0.4489051094890511\n",
            "Epoch:101, Accuracy:0.5036496350364964\n",
            "Epoch:102, Accuracy:0.5583941605839416\n",
            "Epoch:103, Accuracy:0.583941605839416\n",
            "Epoch:104, Accuracy:0.5948905109489051\n",
            "Epoch:105, Accuracy:0.583941605839416\n",
            "Epoch:106, Accuracy:0.5985401459854015\n",
            "Epoch:107, Accuracy:0.6131386861313869\n",
            "Epoch:108, Accuracy:0.5985401459854015\n",
            "Epoch:109, Accuracy:0.5875912408759124\n",
            "Epoch:110, Accuracy:0.6496350364963503\n",
            "Epoch:111, Accuracy:0.6751824817518248\n",
            "Epoch:112, Accuracy:0.6240875912408759\n",
            "Epoch:113, Accuracy:0.6642335766423357\n",
            "Epoch:114, Accuracy:0.6459854014598541\n",
            "Epoch:115, Accuracy:0.6423357664233577\n",
            "Epoch:116, Accuracy:0.6751824817518248\n",
            "Epoch:117, Accuracy:0.6970802919708029\n",
            "Epoch:118, Accuracy:0.6824817518248175\n",
            "Epoch:119, Accuracy:0.6861313868613139\n",
            "Epoch:120, Accuracy:0.6094890510948905\n",
            "Epoch:121, Accuracy:0.4635036496350365\n",
            "Epoch:122, Accuracy:0.5401459854014599\n",
            "Epoch:123, Accuracy:0.3905109489051095\n",
            "Epoch:124, Accuracy:0.45255474452554745\n",
            "Epoch:125, Accuracy:0.4233576642335766\n",
            "Epoch:126, Accuracy:0.3978102189781022\n",
            "Epoch:127, Accuracy:0.3175182481751825\n",
            "Epoch:128, Accuracy:0.38686131386861317\n",
            "Epoch:129, Accuracy:0.35766423357664234\n",
            "Epoch:130, Accuracy:0.4744525547445255\n",
            "Epoch:131, Accuracy:0.4744525547445255\n",
            "Epoch:132, Accuracy:0.45255474452554745\n",
            "Epoch:133, Accuracy:0.4854014598540146\n",
            "Epoch:134, Accuracy:0.5328467153284672\n",
            "Epoch:135, Accuracy:0.5182481751824818\n",
            "Epoch:136, Accuracy:0.5218978102189781\n",
            "Epoch:137, Accuracy:0.5255474452554745\n",
            "Epoch:138, Accuracy:0.5145985401459854\n",
            "Epoch:139, Accuracy:0.5583941605839416\n",
            "Epoch:140, Accuracy:0.4562043795620438\n",
            "Epoch:141, Accuracy:0.44525547445255476\n",
            "Epoch:142, Accuracy:0.5109489051094891\n",
            "Epoch:143, Accuracy:0.5583941605839416\n",
            "Epoch:144, Accuracy:0.5437956204379562\n",
            "Epoch:145, Accuracy:0.5547445255474452\n",
            "Epoch:146, Accuracy:0.6277372262773723\n",
            "Epoch:147, Accuracy:0.6167883211678832\n",
            "Epoch:148, Accuracy:0.6824817518248175\n",
            "Epoch:149, Accuracy:0.6751824817518248\n",
            "Epoch:150, Accuracy:0.6605839416058394\n",
            "Epoch:151, Accuracy:0.6861313868613139\n",
            "Epoch:152, Accuracy:0.6240875912408759\n",
            "Epoch:153, Accuracy:0.6715328467153284\n",
            "Epoch:154, Accuracy:0.5145985401459854\n",
            "Epoch:155, Accuracy:0.6751824817518248\n",
            "Epoch:156, Accuracy:0.5948905109489051\n",
            "Epoch:157, Accuracy:0.6021897810218978\n",
            "Epoch:158, Accuracy:0.5766423357664233\n",
            "Epoch:159, Accuracy:0.6496350364963503\n",
            "Epoch:160, Accuracy:0.6532846715328468\n",
            "Epoch:161, Accuracy:0.6605839416058394\n",
            "Epoch:162, Accuracy:0.6496350364963503\n",
            "Epoch:163, Accuracy:0.6642335766423357\n",
            "Epoch:164, Accuracy:0.6386861313868614\n",
            "Epoch:165, Accuracy:0.7043795620437956\n",
            "Epoch:166, Accuracy:0.6824817518248175\n",
            "Epoch:167, Accuracy:0.7408759124087592\n",
            "Epoch:168, Accuracy:0.7153284671532847\n",
            "Epoch:169, Accuracy:0.8029197080291971\n",
            "Epoch:170, Accuracy:0.7591240875912408\n",
            "Epoch:171, Accuracy:0.7518248175182481\n",
            "Epoch:172, Accuracy:0.791970802919708\n",
            "Epoch:173, Accuracy:0.8284671532846716\n",
            "Epoch:174, Accuracy:0.8321167883211679\n",
            "Epoch:175, Accuracy:0.8175182481751825\n",
            "Epoch:176, Accuracy:0.8467153284671532\n",
            "Epoch:177, Accuracy:0.8576642335766423\n",
            "Epoch:178, Accuracy:0.8503649635036497\n",
            "Epoch:179, Accuracy:0.8613138686131386\n",
            "Epoch:180, Accuracy:0.8686131386861314\n",
            "Epoch:181, Accuracy:0.8540145985401459\n",
            "Epoch:182, Accuracy:0.8686131386861314\n",
            "Epoch:183, Accuracy:0.8503649635036497\n",
            "Epoch:184, Accuracy:0.8248175182481752\n",
            "Epoch:185, Accuracy:0.8467153284671532\n",
            "Epoch:186, Accuracy:0.7846715328467153\n",
            "Epoch:187, Accuracy:0.8138686131386861\n",
            "Epoch:188, Accuracy:0.8138686131386861\n",
            "Epoch:189, Accuracy:0.8467153284671532\n",
            "Epoch:190, Accuracy:0.7627737226277372\n",
            "Epoch:191, Accuracy:0.7335766423357665\n",
            "Epoch:192, Accuracy:0.6021897810218978\n",
            "Epoch:193, Accuracy:0.6094890510948905\n",
            "Epoch:194, Accuracy:0.4343065693430657\n",
            "Epoch:195, Accuracy:0.33941605839416056\n",
            "Epoch:196, Accuracy:0.3722627737226277\n",
            "Epoch:197, Accuracy:0.40875912408759124\n",
            "Epoch:198, Accuracy:0.4124087591240876\n",
            "Epoch:199, Accuracy:0.5\n",
            "Epoch:200, Accuracy:0.5109489051094891\n",
            "Epoch:201, Accuracy:0.5437956204379562\n",
            "Epoch:202, Accuracy:0.5656934306569343\n",
            "Epoch:203, Accuracy:0.6277372262773723\n",
            "Epoch:204, Accuracy:0.5912408759124088\n",
            "Epoch:205, Accuracy:0.6240875912408759\n",
            "Epoch:206, Accuracy:0.5109489051094891\n",
            "Epoch:207, Accuracy:0.6313868613138686\n",
            "Epoch:208, Accuracy:0.6131386861313869\n",
            "Epoch:209, Accuracy:0.6423357664233577\n",
            "Epoch:210, Accuracy:0.4489051094890511\n",
            "Epoch:211, Accuracy:0.4416058394160584\n",
            "Epoch:212, Accuracy:0.5291970802919708\n",
            "Epoch:213, Accuracy:0.5656934306569343\n",
            "Epoch:214, Accuracy:0.6788321167883211\n",
            "Epoch:215, Accuracy:0.6204379562043796\n",
            "Epoch:216, Accuracy:0.6605839416058394\n",
            "Epoch:217, Accuracy:0.6824817518248175\n",
            "Epoch:218, Accuracy:0.6094890510948905\n",
            "Epoch:219, Accuracy:0.6058394160583942\n",
            "Epoch:220, Accuracy:0.6532846715328468\n",
            "Epoch:221, Accuracy:0.6167883211678832\n",
            "Epoch:222, Accuracy:0.6788321167883211\n",
            "Epoch:223, Accuracy:0.7554744525547445\n",
            "Epoch:224, Accuracy:0.7335766423357665\n",
            "Epoch:225, Accuracy:0.7591240875912408\n",
            "Epoch:226, Accuracy:0.7518248175182481\n",
            "Epoch:227, Accuracy:0.7773722627737226\n",
            "Epoch:228, Accuracy:0.791970802919708\n",
            "Epoch:229, Accuracy:0.8102189781021898\n",
            "Epoch:230, Accuracy:0.8175182481751825\n",
            "Epoch:231, Accuracy:0.8102189781021898\n",
            "Epoch:232, Accuracy:0.8138686131386861\n",
            "Epoch:233, Accuracy:0.8284671532846716\n",
            "Epoch:234, Accuracy:0.8248175182481752\n",
            "Epoch:235, Accuracy:0.8321167883211679\n",
            "Epoch:236, Accuracy:0.8357664233576643\n",
            "Epoch:237, Accuracy:0.8321167883211679\n",
            "Epoch:238, Accuracy:0.8467153284671532\n",
            "Epoch:239, Accuracy:0.7773722627737226\n",
            "Epoch:240, Accuracy:0.5948905109489051\n",
            "Epoch:241, Accuracy:0.4635036496350365\n",
            "Epoch:242, Accuracy:0.5036496350364964\n",
            "Epoch:243, Accuracy:0.5328467153284672\n",
            "Epoch:244, Accuracy:0.6678832116788321\n",
            "Epoch:245, Accuracy:0.6751824817518248\n",
            "Epoch:246, Accuracy:0.7335766423357665\n",
            "Epoch:247, Accuracy:0.7664233576642335\n",
            "Epoch:248, Accuracy:0.7372262773722628\n",
            "Epoch:249, Accuracy:0.7700729927007299\n",
            "Epoch:250, Accuracy:0.7846715328467153\n",
            "Epoch:251, Accuracy:0.7956204379562044\n",
            "Epoch:252, Accuracy:0.7664233576642335\n",
            "Epoch:253, Accuracy:0.6970802919708029\n",
            "Epoch:254, Accuracy:0.7299270072992701\n",
            "Epoch:255, Accuracy:0.7773722627737226\n",
            "Epoch:256, Accuracy:0.6970802919708029\n",
            "Epoch:257, Accuracy:0.6277372262773723\n",
            "Epoch:258, Accuracy:0.718978102189781\n",
            "Epoch:259, Accuracy:0.7153284671532847\n",
            "Epoch:260, Accuracy:0.781021897810219\n",
            "Epoch:261, Accuracy:0.6897810218978102\n",
            "Epoch:262, Accuracy:0.7664233576642335\n",
            "Epoch:263, Accuracy:0.7773722627737226\n",
            "Epoch:264, Accuracy:0.8029197080291971\n",
            "Epoch:265, Accuracy:0.7846715328467153\n",
            "Epoch:266, Accuracy:0.8394160583941606\n",
            "Epoch:267, Accuracy:0.8357664233576643\n",
            "Epoch:268, Accuracy:0.7153284671532847\n",
            "Epoch:269, Accuracy:0.6313868613138686\n",
            "Epoch:270, Accuracy:0.708029197080292\n",
            "Epoch:271, Accuracy:0.6423357664233577\n",
            "Epoch:272, Accuracy:0.656934306569343\n",
            "Epoch:273, Accuracy:0.6824817518248175\n",
            "Epoch:274, Accuracy:0.7554744525547445\n",
            "Epoch:275, Accuracy:0.7883211678832117\n",
            "Epoch:276, Accuracy:0.8284671532846716\n",
            "Epoch:277, Accuracy:0.843065693430657\n",
            "Epoch:278, Accuracy:0.8467153284671532\n",
            "Epoch:279, Accuracy:0.8394160583941606\n",
            "Epoch:280, Accuracy:0.8759124087591241\n",
            "Epoch:281, Accuracy:0.8795620437956204\n",
            "Epoch:282, Accuracy:0.8722627737226277\n",
            "Epoch:283, Accuracy:0.8868613138686131\n",
            "Epoch:284, Accuracy:0.8905109489051095\n",
            "Epoch:285, Accuracy:0.8905109489051095\n",
            "Epoch:286, Accuracy:0.8905109489051095\n",
            "Epoch:287, Accuracy:0.8868613138686131\n",
            "Epoch:288, Accuracy:0.8868613138686131\n",
            "Epoch:289, Accuracy:0.8795620437956204\n",
            "Epoch:290, Accuracy:0.8832116788321168\n",
            "Epoch:291, Accuracy:0.8868613138686131\n",
            "Epoch:292, Accuracy:0.8759124087591241\n",
            "Epoch:293, Accuracy:0.8467153284671532\n",
            "Epoch:294, Accuracy:0.8722627737226277\n",
            "Epoch:295, Accuracy:0.8832116788321168\n",
            "Epoch:296, Accuracy:0.8868613138686131\n",
            "Epoch:297, Accuracy:0.8832116788321168\n",
            "Epoch:298, Accuracy:0.9014598540145985\n",
            "Epoch:299, Accuracy:0.9014598540145985\n",
            "Epoch:300, Accuracy:0.9014598540145985\n",
            "Epoch:301, Accuracy:0.9051094890510949\n",
            "Epoch:302, Accuracy:0.9014598540145985\n",
            "Epoch:303, Accuracy:0.9014598540145985\n",
            "Epoch:304, Accuracy:0.9014598540145985\n",
            "Epoch:305, Accuracy:0.9051094890510949\n",
            "Epoch:306, Accuracy:0.9087591240875912\n",
            "Epoch:307, Accuracy:0.9087591240875912\n",
            "Epoch:308, Accuracy:0.916058394160584\n",
            "Epoch:309, Accuracy:0.9087591240875912\n",
            "Epoch:310, Accuracy:0.9087591240875912\n",
            "Epoch:311, Accuracy:0.916058394160584\n",
            "Epoch:312, Accuracy:0.9087591240875912\n",
            "Epoch:313, Accuracy:0.9197080291970803\n",
            "Epoch:314, Accuracy:0.9197080291970803\n",
            "Epoch:315, Accuracy:0.9197080291970803\n",
            "Epoch:316, Accuracy:0.9197080291970803\n",
            "Epoch:317, Accuracy:0.9197080291970803\n",
            "Epoch:318, Accuracy:0.916058394160584\n",
            "Epoch:319, Accuracy:0.916058394160584\n",
            "Epoch:320, Accuracy:0.9197080291970803\n",
            "Epoch:321, Accuracy:0.9087591240875912\n",
            "Epoch:322, Accuracy:0.9124087591240876\n",
            "Epoch:323, Accuracy:0.9233576642335767\n",
            "Epoch:324, Accuracy:0.9124087591240876\n",
            "Epoch:325, Accuracy:0.9197080291970803\n",
            "Epoch:326, Accuracy:0.9197080291970803\n",
            "Epoch:327, Accuracy:0.9233576642335767\n",
            "Epoch:328, Accuracy:0.927007299270073\n",
            "Epoch:329, Accuracy:0.9233576642335767\n",
            "Epoch:330, Accuracy:0.927007299270073\n",
            "Epoch:331, Accuracy:0.927007299270073\n",
            "Epoch:332, Accuracy:0.927007299270073\n",
            "Epoch:333, Accuracy:0.927007299270073\n",
            "Epoch:334, Accuracy:0.927007299270073\n",
            "Epoch:335, Accuracy:0.927007299270073\n",
            "Epoch:336, Accuracy:0.927007299270073\n",
            "Epoch:337, Accuracy:0.9306569343065694\n",
            "Epoch:338, Accuracy:0.9233576642335767\n",
            "Epoch:339, Accuracy:0.9233576642335767\n",
            "Epoch:340, Accuracy:0.9233576642335767\n",
            "Epoch:341, Accuracy:0.9233576642335767\n",
            "Epoch:342, Accuracy:0.9233576642335767\n",
            "Epoch:343, Accuracy:0.9233576642335767\n",
            "Epoch:344, Accuracy:0.927007299270073\n",
            "Epoch:345, Accuracy:0.9233576642335767\n",
            "Epoch:346, Accuracy:0.9233576642335767\n",
            "Epoch:347, Accuracy:0.9233576642335767\n",
            "Epoch:348, Accuracy:0.9233576642335767\n",
            "Epoch:349, Accuracy:0.9233576642335767\n",
            "Epoch:350, Accuracy:0.9233576642335767\n",
            "Epoch:351, Accuracy:0.9233576642335767\n",
            "Epoch:352, Accuracy:0.9233576642335767\n",
            "Epoch:353, Accuracy:0.927007299270073\n",
            "Epoch:354, Accuracy:0.927007299270073\n",
            "Epoch:355, Accuracy:0.9197080291970803\n",
            "Epoch:356, Accuracy:0.9014598540145985\n",
            "Epoch:357, Accuracy:0.8905109489051095\n",
            "Epoch:358, Accuracy:0.8795620437956204\n",
            "Epoch:359, Accuracy:0.7700729927007299\n",
            "Epoch:360, Accuracy:0.7445255474452555\n",
            "Epoch:361, Accuracy:0.7372262773722628\n",
            "Epoch:362, Accuracy:0.583941605839416\n",
            "Epoch:363, Accuracy:0.4708029197080292\n",
            "Epoch:364, Accuracy:0.40875912408759124\n",
            "Epoch:365, Accuracy:0.5912408759124088\n",
            "Epoch:366, Accuracy:0.6788321167883211\n",
            "Epoch:367, Accuracy:0.6605839416058394\n",
            "Epoch:368, Accuracy:0.6715328467153284\n",
            "Epoch:369, Accuracy:0.6970802919708029\n",
            "Epoch:370, Accuracy:0.7846715328467153\n",
            "Epoch:371, Accuracy:0.8029197080291971\n",
            "Epoch:372, Accuracy:0.8211678832116789\n",
            "Epoch:373, Accuracy:0.8321167883211679\n",
            "Epoch:374, Accuracy:0.8503649635036497\n",
            "Epoch:375, Accuracy:0.8759124087591241\n",
            "Epoch:376, Accuracy:0.8795620437956204\n",
            "Epoch:377, Accuracy:0.8832116788321168\n",
            "Epoch:378, Accuracy:0.8795620437956204\n",
            "Epoch:379, Accuracy:0.8868613138686131\n",
            "Epoch:380, Accuracy:0.8941605839416058\n",
            "Epoch:381, Accuracy:0.8941605839416058\n",
            "Epoch:382, Accuracy:0.8905109489051095\n",
            "Epoch:383, Accuracy:0.8905109489051095\n",
            "Epoch:384, Accuracy:0.8941605839416058\n",
            "Epoch:385, Accuracy:0.8978102189781022\n",
            "Epoch:386, Accuracy:0.8978102189781022\n",
            "Epoch:387, Accuracy:0.8941605839416058\n",
            "Epoch:388, Accuracy:0.8941605839416058\n",
            "Epoch:389, Accuracy:0.8941605839416058\n",
            "Epoch:390, Accuracy:0.8978102189781022\n",
            "Epoch:391, Accuracy:0.9051094890510949\n",
            "Epoch:392, Accuracy:0.8941605839416058\n",
            "Epoch:393, Accuracy:0.9014598540145985\n",
            "Epoch:394, Accuracy:0.9087591240875912\n",
            "Epoch:395, Accuracy:0.9051094890510949\n",
            "Epoch:396, Accuracy:0.9051094890510949\n",
            "Epoch:397, Accuracy:0.9087591240875912\n",
            "Epoch:398, Accuracy:0.8613138686131386\n",
            "Epoch:399, Accuracy:0.7554744525547445\n",
            "Epoch:400, Accuracy:0.5620437956204379\n",
            "Epoch:401, Accuracy:0.6058394160583942\n",
            "Epoch:402, Accuracy:0.4854014598540146\n",
            "Epoch:403, Accuracy:0.5109489051094891\n",
            "Epoch:404, Accuracy:0.5145985401459854\n",
            "Epoch:405, Accuracy:0.5583941605839416\n",
            "Epoch:406, Accuracy:0.5693430656934306\n",
            "Epoch:407, Accuracy:0.5437956204379562\n",
            "Epoch:408, Accuracy:0.5620437956204379\n",
            "Epoch:409, Accuracy:0.6094890510948905\n",
            "Epoch:410, Accuracy:0.6204379562043796\n",
            "Epoch:411, Accuracy:0.6459854014598541\n",
            "Epoch:412, Accuracy:0.5985401459854015\n",
            "Epoch:413, Accuracy:0.5693430656934306\n",
            "Epoch:414, Accuracy:0.6642335766423357\n",
            "Epoch:415, Accuracy:0.6532846715328468\n",
            "Epoch:416, Accuracy:0.6496350364963503\n",
            "Epoch:417, Accuracy:0.6970802919708029\n",
            "Epoch:418, Accuracy:0.7153284671532847\n",
            "Epoch:419, Accuracy:0.7226277372262774\n",
            "Epoch:420, Accuracy:0.7372262773722628\n",
            "Epoch:421, Accuracy:0.7481751824817519\n",
            "Epoch:422, Accuracy:0.7445255474452555\n",
            "Epoch:423, Accuracy:0.7700729927007299\n",
            "Epoch:424, Accuracy:0.7737226277372263\n",
            "Epoch:425, Accuracy:0.7591240875912408\n",
            "Epoch:426, Accuracy:0.7737226277372263\n",
            "Epoch:427, Accuracy:0.7773722627737226\n",
            "Epoch:428, Accuracy:0.7737226277372263\n",
            "Epoch:429, Accuracy:0.7846715328467153\n",
            "Epoch:430, Accuracy:0.8065693430656934\n",
            "Epoch:431, Accuracy:0.8065693430656934\n",
            "Epoch:432, Accuracy:0.7992700729927007\n",
            "Epoch:433, Accuracy:0.7883211678832117\n",
            "Epoch:434, Accuracy:0.8175182481751825\n",
            "Epoch:435, Accuracy:0.8211678832116789\n",
            "Epoch:436, Accuracy:0.8357664233576643\n",
            "Epoch:437, Accuracy:0.8284671532846716\n",
            "Epoch:438, Accuracy:0.7664233576642335\n",
            "Epoch:439, Accuracy:0.7153284671532847\n",
            "Epoch:440, Accuracy:0.6861313868613139\n",
            "Epoch:441, Accuracy:0.7262773722627737\n",
            "Epoch:442, Accuracy:0.6788321167883211\n",
            "Epoch:443, Accuracy:0.5437956204379562\n",
            "Epoch:444, Accuracy:0.6240875912408759\n",
            "Epoch:445, Accuracy:0.5656934306569343\n",
            "Epoch:446, Accuracy:0.718978102189781\n",
            "Epoch:447, Accuracy:0.7445255474452555\n",
            "Epoch:448, Accuracy:0.7737226277372263\n",
            "Epoch:449, Accuracy:0.791970802919708\n",
            "Epoch:450, Accuracy:0.8102189781021898\n",
            "Epoch:451, Accuracy:0.8138686131386861\n",
            "Epoch:452, Accuracy:0.8065693430656934\n",
            "Epoch:453, Accuracy:0.8248175182481752\n",
            "Epoch:454, Accuracy:0.8102189781021898\n",
            "Epoch:455, Accuracy:0.8284671532846716\n",
            "Epoch:456, Accuracy:0.8175182481751825\n",
            "Epoch:457, Accuracy:0.8211678832116789\n",
            "Epoch:458, Accuracy:0.8394160583941606\n",
            "Epoch:459, Accuracy:0.8357664233576643\n",
            "Epoch:460, Accuracy:0.843065693430657\n",
            "Epoch:461, Accuracy:0.843065693430657\n",
            "Epoch:462, Accuracy:0.8503649635036497\n",
            "Epoch:463, Accuracy:0.8394160583941606\n",
            "Epoch:464, Accuracy:0.8321167883211679\n",
            "Epoch:465, Accuracy:0.8248175182481752\n",
            "Epoch:466, Accuracy:0.8321167883211679\n",
            "Epoch:467, Accuracy:0.843065693430657\n",
            "Epoch:468, Accuracy:0.7992700729927007\n",
            "Epoch:469, Accuracy:0.8540145985401459\n",
            "Epoch:470, Accuracy:0.8540145985401459\n",
            "Epoch:471, Accuracy:0.8613138686131386\n",
            "Epoch:472, Accuracy:0.7992700729927007\n",
            "Epoch:473, Accuracy:0.8065693430656934\n",
            "Epoch:474, Accuracy:0.8029197080291971\n",
            "Epoch:475, Accuracy:0.8175182481751825\n",
            "Epoch:476, Accuracy:0.8138686131386861\n",
            "Epoch:477, Accuracy:0.7773722627737226\n",
            "Epoch:478, Accuracy:0.781021897810219\n",
            "Epoch:479, Accuracy:0.6204379562043796\n",
            "Epoch:480, Accuracy:0.7408759124087592\n",
            "Epoch:481, Accuracy:0.718978102189781\n",
            "Epoch:482, Accuracy:0.7700729927007299\n",
            "Epoch:483, Accuracy:0.8248175182481752\n",
            "Epoch:484, Accuracy:0.791970802919708\n",
            "Epoch:485, Accuracy:0.8321167883211679\n",
            "Epoch:486, Accuracy:0.8248175182481752\n",
            "Epoch:487, Accuracy:0.8321167883211679\n",
            "Epoch:488, Accuracy:0.8503649635036497\n",
            "Epoch:489, Accuracy:0.8613138686131386\n",
            "Epoch:490, Accuracy:0.8795620437956204\n",
            "Epoch:491, Accuracy:0.8868613138686131\n",
            "Epoch:492, Accuracy:0.8832116788321168\n",
            "Epoch:493, Accuracy:0.8832116788321168\n",
            "Epoch:494, Accuracy:0.8832116788321168\n",
            "Epoch:495, Accuracy:0.8832116788321168\n",
            "Epoch:496, Accuracy:0.8175182481751825\n",
            "Epoch:497, Accuracy:0.6058394160583942\n",
            "Epoch:498, Accuracy:0.6532846715328468\n",
            "Epoch:499, Accuracy:0.6167883211678832\n"
          ]
        }
      ],
      "source": [
        "use_cuda = True\n",
        "if torch.cuda.is_available():\n",
        "    model = CNNLargeNet2().cuda()\n",
        "Y = trainSmall(model, train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Start\n",
            "Epoch:0, Accuracy:0.1386861313868613\n",
            "Epoch:1, Accuracy:0.2518248175182482\n",
            "Epoch:2, Accuracy:0.16423357664233576\n",
            "Epoch:3, Accuracy:0.16058394160583941\n",
            "Epoch:4, Accuracy:0.1897810218978102\n",
            "Epoch:5, Accuracy:0.19708029197080293\n",
            "Epoch:6, Accuracy:0.1897810218978102\n",
            "Epoch:7, Accuracy:0.20072992700729927\n",
            "Epoch:8, Accuracy:0.20802919708029197\n",
            "Epoch:9, Accuracy:0.22262773722627738\n",
            "Epoch:10, Accuracy:0.21897810218978103\n",
            "Epoch:11, Accuracy:0.23357664233576642\n",
            "Epoch:12, Accuracy:0.24087591240875914\n",
            "Epoch:13, Accuracy:0.2664233576642336\n",
            "Epoch:14, Accuracy:0.24817518248175183\n",
            "Epoch:15, Accuracy:0.2591240875912409\n",
            "Epoch:16, Accuracy:0.2518248175182482\n",
            "Epoch:17, Accuracy:0.22262773722627738\n",
            "Epoch:18, Accuracy:0.24452554744525548\n",
            "Epoch:19, Accuracy:0.22627737226277372\n",
            "Epoch:20, Accuracy:0.24817518248175183\n",
            "Epoch:21, Accuracy:0.24087591240875914\n",
            "Epoch:22, Accuracy:0.2737226277372263\n",
            "Epoch:23, Accuracy:0.2518248175182482\n",
            "Epoch:24, Accuracy:0.2956204379562044\n",
            "Epoch:25, Accuracy:0.27007299270072993\n",
            "Epoch:26, Accuracy:0.2664233576642336\n",
            "Epoch:27, Accuracy:0.2518248175182482\n",
            "Epoch:28, Accuracy:0.27007299270072993\n",
            "Epoch:29, Accuracy:0.3029197080291971\n",
            "Epoch:30, Accuracy:0.30656934306569344\n",
            "Epoch:31, Accuracy:0.3284671532846715\n",
            "Epoch:32, Accuracy:0.4051094890510949\n",
            "Epoch:33, Accuracy:0.3248175182481752\n",
            "Epoch:34, Accuracy:0.3284671532846715\n",
            "Epoch:35, Accuracy:0.33211678832116787\n",
            "Epoch:36, Accuracy:0.3357664233576642\n",
            "Epoch:37, Accuracy:0.35036496350364965\n",
            "Epoch:38, Accuracy:0.354014598540146\n",
            "Epoch:39, Accuracy:0.3686131386861314\n",
            "Epoch:40, Accuracy:0.40145985401459855\n",
            "Epoch:41, Accuracy:0.40875912408759124\n",
            "Epoch:42, Accuracy:0.38321167883211676\n",
            "Epoch:43, Accuracy:0.3905109489051095\n",
            "Epoch:44, Accuracy:0.3248175182481752\n",
            "Epoch:45, Accuracy:0.28102189781021897\n",
            "Epoch:46, Accuracy:0.3467153284671533\n",
            "Epoch:47, Accuracy:0.27007299270072993\n",
            "Epoch:48, Accuracy:0.33211678832116787\n",
            "Epoch:49, Accuracy:0.3175182481751825\n",
            "Epoch:50, Accuracy:0.22627737226277372\n",
            "Epoch:51, Accuracy:0.25547445255474455\n",
            "Epoch:52, Accuracy:0.2518248175182482\n",
            "Epoch:53, Accuracy:0.3029197080291971\n",
            "Epoch:54, Accuracy:0.26277372262773724\n",
            "Epoch:55, Accuracy:0.33211678832116787\n",
            "Epoch:56, Accuracy:0.33941605839416056\n",
            "Epoch:57, Accuracy:0.3284671532846715\n",
            "Epoch:58, Accuracy:0.38321167883211676\n",
            "Epoch:59, Accuracy:0.3795620437956204\n",
            "Epoch:60, Accuracy:0.3795620437956204\n",
            "Epoch:61, Accuracy:0.40145985401459855\n",
            "Epoch:62, Accuracy:0.3759124087591241\n",
            "Epoch:63, Accuracy:0.3613138686131387\n",
            "Epoch:64, Accuracy:0.4197080291970803\n",
            "Epoch:65, Accuracy:0.3795620437956204\n",
            "Epoch:66, Accuracy:0.40875912408759124\n",
            "Epoch:67, Accuracy:0.42700729927007297\n",
            "Epoch:68, Accuracy:0.41605839416058393\n",
            "Epoch:69, Accuracy:0.42700729927007297\n",
            "Epoch:70, Accuracy:0.4124087591240876\n",
            "Epoch:71, Accuracy:0.3905109489051095\n",
            "Epoch:72, Accuracy:0.4233576642335766\n",
            "Epoch:73, Accuracy:0.43795620437956206\n",
            "Epoch:74, Accuracy:0.45985401459854014\n",
            "Epoch:75, Accuracy:0.5109489051094891\n",
            "Epoch:76, Accuracy:0.4416058394160584\n",
            "Epoch:77, Accuracy:0.4233576642335766\n",
            "Epoch:78, Accuracy:0.48175182481751827\n",
            "Epoch:79, Accuracy:0.4562043795620438\n",
            "Epoch:80, Accuracy:0.45985401459854014\n",
            "Epoch:81, Accuracy:0.36496350364963503\n",
            "Epoch:82, Accuracy:0.41605839416058393\n",
            "Epoch:83, Accuracy:0.291970802919708\n",
            "Epoch:84, Accuracy:0.3722627737226277\n",
            "Epoch:85, Accuracy:0.4197080291970803\n",
            "Epoch:86, Accuracy:0.35036496350364965\n",
            "Epoch:87, Accuracy:0.354014598540146\n",
            "Epoch:88, Accuracy:0.4124087591240876\n",
            "Epoch:89, Accuracy:0.42700729927007297\n",
            "Epoch:90, Accuracy:0.40875912408759124\n",
            "Epoch:91, Accuracy:0.4051094890510949\n",
            "Epoch:92, Accuracy:0.3686131386861314\n",
            "Epoch:93, Accuracy:0.43795620437956206\n",
            "Epoch:94, Accuracy:0.43795620437956206\n",
            "Epoch:95, Accuracy:0.3978102189781022\n",
            "Epoch:96, Accuracy:0.45255474452554745\n",
            "Epoch:97, Accuracy:0.36496350364963503\n",
            "Epoch:98, Accuracy:0.3467153284671533\n",
            "Epoch:99, Accuracy:0.3357664233576642\n",
            "Epoch:100, Accuracy:0.29927007299270075\n",
            "Epoch:101, Accuracy:0.3686131386861314\n",
            "Epoch:102, Accuracy:0.30656934306569344\n",
            "Epoch:103, Accuracy:0.2773722627737226\n",
            "Epoch:104, Accuracy:0.2773722627737226\n",
            "Epoch:105, Accuracy:0.33941605839416056\n",
            "Epoch:106, Accuracy:0.33941605839416056\n",
            "Epoch:107, Accuracy:0.3357664233576642\n",
            "Epoch:108, Accuracy:0.3613138686131387\n",
            "Epoch:109, Accuracy:0.36496350364963503\n",
            "Epoch:110, Accuracy:0.36496350364963503\n",
            "Epoch:111, Accuracy:0.3759124087591241\n",
            "Epoch:112, Accuracy:0.38686131386861317\n",
            "Epoch:113, Accuracy:0.39416058394160586\n",
            "Epoch:114, Accuracy:0.3905109489051095\n",
            "Epoch:115, Accuracy:0.3978102189781022\n",
            "Epoch:116, Accuracy:0.39416058394160586\n",
            "Epoch:117, Accuracy:0.40145985401459855\n",
            "Epoch:118, Accuracy:0.4051094890510949\n",
            "Epoch:119, Accuracy:0.40145985401459855\n",
            "Epoch:120, Accuracy:0.38686131386861317\n",
            "Epoch:121, Accuracy:0.34306569343065696\n",
            "Epoch:122, Accuracy:0.38686131386861317\n",
            "Epoch:123, Accuracy:0.4124087591240876\n",
            "Epoch:124, Accuracy:0.3905109489051095\n",
            "Epoch:125, Accuracy:0.38686131386861317\n",
            "Epoch:126, Accuracy:0.3759124087591241\n",
            "Epoch:127, Accuracy:0.38686131386861317\n",
            "Epoch:128, Accuracy:0.3722627737226277\n",
            "Epoch:129, Accuracy:0.39416058394160586\n",
            "Epoch:130, Accuracy:0.38686131386861317\n",
            "Epoch:131, Accuracy:0.3795620437956204\n",
            "Epoch:132, Accuracy:0.3905109489051095\n",
            "Epoch:133, Accuracy:0.42700729927007297\n",
            "Epoch:134, Accuracy:0.40145985401459855\n",
            "Epoch:135, Accuracy:0.3978102189781022\n",
            "Epoch:136, Accuracy:0.4124087591240876\n",
            "Epoch:137, Accuracy:0.41605839416058393\n",
            "Epoch:138, Accuracy:0.4343065693430657\n",
            "Epoch:139, Accuracy:0.4124087591240876\n",
            "Epoch:140, Accuracy:0.40875912408759124\n",
            "Epoch:141, Accuracy:0.42700729927007297\n",
            "Epoch:142, Accuracy:0.46715328467153283\n",
            "Epoch:143, Accuracy:0.4197080291970803\n",
            "Epoch:144, Accuracy:0.45255474452554745\n",
            "Epoch:145, Accuracy:0.43795620437956206\n",
            "Epoch:146, Accuracy:0.4781021897810219\n",
            "Epoch:147, Accuracy:0.42700729927007297\n",
            "Epoch:148, Accuracy:0.4197080291970803\n",
            "Epoch:149, Accuracy:0.4489051094890511\n",
            "Epoch:150, Accuracy:0.3759124087591241\n",
            "Epoch:151, Accuracy:0.4416058394160584\n",
            "Epoch:152, Accuracy:0.4233576642335766\n",
            "Epoch:153, Accuracy:0.40875912408759124\n",
            "Epoch:154, Accuracy:0.4051094890510949\n",
            "Epoch:155, Accuracy:0.42700729927007297\n",
            "Epoch:156, Accuracy:0.45255474452554745\n",
            "Epoch:157, Accuracy:0.4854014598540146\n",
            "Epoch:158, Accuracy:0.4416058394160584\n",
            "Epoch:159, Accuracy:0.43795620437956206\n",
            "Epoch:160, Accuracy:0.3978102189781022\n",
            "Epoch:161, Accuracy:0.40145985401459855\n",
            "Epoch:162, Accuracy:0.3759124087591241\n",
            "Epoch:163, Accuracy:0.3905109489051095\n",
            "Epoch:164, Accuracy:0.4197080291970803\n",
            "Epoch:165, Accuracy:0.40145985401459855\n",
            "Epoch:166, Accuracy:0.4233576642335766\n",
            "Epoch:167, Accuracy:0.4562043795620438\n",
            "Epoch:168, Accuracy:0.45255474452554745\n",
            "Epoch:169, Accuracy:0.42700729927007297\n",
            "Epoch:170, Accuracy:0.42700729927007297\n",
            "Epoch:171, Accuracy:0.38321167883211676\n",
            "Epoch:172, Accuracy:0.4306569343065693\n",
            "Epoch:173, Accuracy:0.3759124087591241\n",
            "Epoch:174, Accuracy:0.4489051094890511\n",
            "Epoch:175, Accuracy:0.4781021897810219\n",
            "Epoch:176, Accuracy:0.45985401459854014\n",
            "Epoch:177, Accuracy:0.4854014598540146\n",
            "Epoch:178, Accuracy:0.4927007299270073\n",
            "Epoch:179, Accuracy:0.49635036496350365\n",
            "Epoch:180, Accuracy:0.49635036496350365\n",
            "Epoch:181, Accuracy:0.5\n",
            "Epoch:182, Accuracy:0.5109489051094891\n",
            "Epoch:183, Accuracy:0.5072992700729927\n",
            "Epoch:184, Accuracy:0.5\n",
            "Epoch:185, Accuracy:0.5\n",
            "Epoch:186, Accuracy:0.5036496350364964\n",
            "Epoch:187, Accuracy:0.5036496350364964\n",
            "Epoch:188, Accuracy:0.5109489051094891\n",
            "Epoch:189, Accuracy:0.49635036496350365\n",
            "Epoch:190, Accuracy:0.5\n",
            "Epoch:191, Accuracy:0.4781021897810219\n",
            "Epoch:192, Accuracy:0.4927007299270073\n",
            "Epoch:193, Accuracy:0.5291970802919708\n",
            "Epoch:194, Accuracy:0.5437956204379562\n",
            "Epoch:195, Accuracy:0.5364963503649635\n",
            "Epoch:196, Accuracy:0.5437956204379562\n",
            "Epoch:197, Accuracy:0.5255474452554745\n",
            "Epoch:198, Accuracy:0.5072992700729927\n",
            "Epoch:199, Accuracy:0.5145985401459854\n",
            "Epoch:200, Accuracy:0.5036496350364964\n",
            "Epoch:201, Accuracy:0.4744525547445255\n",
            "Epoch:202, Accuracy:0.5109489051094891\n",
            "Epoch:203, Accuracy:0.48905109489051096\n",
            "Epoch:204, Accuracy:0.5291970802919708\n",
            "Epoch:205, Accuracy:0.49635036496350365\n",
            "Epoch:206, Accuracy:0.5401459854014599\n",
            "Epoch:207, Accuracy:0.5437956204379562\n",
            "Epoch:208, Accuracy:0.5328467153284672\n",
            "Epoch:209, Accuracy:0.5364963503649635\n",
            "Epoch:210, Accuracy:0.5328467153284672\n",
            "Epoch:211, Accuracy:0.49635036496350365\n",
            "Epoch:212, Accuracy:0.45985401459854014\n",
            "Epoch:213, Accuracy:0.48905109489051096\n",
            "Epoch:214, Accuracy:0.45985401459854014\n",
            "Epoch:215, Accuracy:0.4343065693430657\n",
            "Epoch:216, Accuracy:0.46715328467153283\n",
            "Epoch:217, Accuracy:0.4562043795620438\n",
            "Epoch:218, Accuracy:0.3759124087591241\n",
            "Epoch:219, Accuracy:0.4562043795620438\n",
            "Epoch:220, Accuracy:0.44525547445255476\n",
            "Epoch:221, Accuracy:0.38321167883211676\n",
            "Epoch:222, Accuracy:0.3978102189781022\n",
            "Epoch:223, Accuracy:0.4489051094890511\n",
            "Epoch:224, Accuracy:0.38321167883211676\n",
            "Epoch:225, Accuracy:0.4306569343065693\n",
            "Epoch:226, Accuracy:0.3978102189781022\n",
            "Epoch:227, Accuracy:0.4124087591240876\n",
            "Epoch:228, Accuracy:0.4635036496350365\n",
            "Epoch:229, Accuracy:0.46715328467153283\n",
            "Epoch:230, Accuracy:0.4854014598540146\n",
            "Epoch:231, Accuracy:0.5072992700729927\n",
            "Epoch:232, Accuracy:0.5218978102189781\n",
            "Epoch:233, Accuracy:0.5218978102189781\n",
            "Epoch:234, Accuracy:0.5291970802919708\n",
            "Epoch:235, Accuracy:0.5145985401459854\n",
            "Epoch:236, Accuracy:0.5328467153284672\n",
            "Epoch:237, Accuracy:0.5072992700729927\n",
            "Epoch:238, Accuracy:0.5437956204379562\n",
            "Epoch:239, Accuracy:0.5182481751824818\n",
            "Epoch:240, Accuracy:0.5364963503649635\n",
            "Epoch:241, Accuracy:0.5109489051094891\n",
            "Epoch:242, Accuracy:0.46715328467153283\n",
            "Epoch:243, Accuracy:0.4306569343065693\n",
            "Epoch:244, Accuracy:0.5109489051094891\n",
            "Epoch:245, Accuracy:0.4744525547445255\n",
            "Epoch:246, Accuracy:0.45255474452554745\n",
            "Epoch:247, Accuracy:0.4124087591240876\n",
            "Epoch:248, Accuracy:0.48905109489051096\n",
            "Epoch:249, Accuracy:0.5401459854014599\n",
            "Epoch:250, Accuracy:0.4927007299270073\n",
            "Epoch:251, Accuracy:0.5364963503649635\n",
            "Epoch:252, Accuracy:0.551094890510949\n",
            "Epoch:253, Accuracy:0.551094890510949\n",
            "Epoch:254, Accuracy:0.5474452554744526\n",
            "Epoch:255, Accuracy:0.5547445255474452\n",
            "Epoch:256, Accuracy:0.5620437956204379\n",
            "Epoch:257, Accuracy:0.5620437956204379\n",
            "Epoch:258, Accuracy:0.551094890510949\n",
            "Epoch:259, Accuracy:0.5656934306569343\n"
          ]
        }
      ],
      "source": [
        "use_cuda = True\n",
        "if torch.cuda.is_available():\n",
        "    model = CNNLargeNet2().cuda()\n",
        "Y = trainSmall(model, train_dataset, batch_size=64, learning_rate=0.005, num_epochs=260)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "************************************************************************\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjPs44Ion4HI",
        "outputId": "9e46df40-654e-4f44-ad67-d958ccd49889"
      },
      "outputs": [],
      "source": [
        "features_or = []\n",
        "labels_or = []\n",
        "train_data_or = []\n",
        "data_transform1 = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "def create_train2():\n",
        "    for i, photo in enumerate(classeses):\n",
        "        path = os.path.join('C:/Users/Admin/Desktop/MIE1517_Project/data', photo)\n",
        "        label = i  # Use the index of the class as the label\n",
        "\n",
        "        # Loop over to get every image in the current class\n",
        "        for img_name in os.listdir(path):\n",
        "            img_path = os.path.join(path, img_name)\n",
        "            img_pil = cv.imread(img_path)\n",
        "            img_pil = Image.fromarray(cv.cvtColor(img_pil, cv.COLOR_BGR2RGB))\n",
        "            transformed_image1 = data_transform1(img_pil)\n",
        "\n",
        "            if img_pil is None:\n",
        "                print(\"Error loading image:\", img_pil)\n",
        "                continue\n",
        "            # Append the original image and its label to the list\n",
        "            features_or.append(transformed_image1)\n",
        "            labels_or.append(label)\n",
        "\n",
        "            train_data_or.append([img_pil, label])\n",
        "create_train2()\n",
        "print(type(features_or[0]))\n",
        "# Count the occurrences of each label\n",
        "label_counts_or = Counter(labels_or)\n",
        "\n",
        "# Print the label counts\n",
        "for label, count in label_counts_or.items():\n",
        "    print(f\"Label {label}: {count} images\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOcsfB_6d-9P"
      },
      "outputs": [],
      "source": [
        "\n",
        "from torchvision import transforms\n",
        "from collections import defaultdict\n",
        "labels = labels_or\n",
        "features = features_or\n",
        "# Shuffle the labels and features in the same order\n",
        "combined = list(zip(labels, features))\n",
        "labels, features = zip(*combined)\n",
        "\n",
        "# Create a dictionary to store images by label\n",
        "label_to_images = defaultdict(list)\n",
        "\n",
        "# Group images by label\n",
        "for label, img in zip(labels, features):\n",
        "    label_to_images[label].append(img)\n",
        "\n",
        "# Set the ratios for train, validation, and test sets\n",
        "train_ratio = 0.6\n",
        "validation_ratio = 0.2\n",
        "test_ratio = 0.2\n",
        "\n",
        "train_data = []\n",
        "validation_data = []\n",
        "test_data = []\n",
        "\n",
        "# Split data for each label\n",
        "for label, images in label_to_images.items():\n",
        "    random.shuffle(images)  # Shuffle the images for each label\n",
        "\n",
        "    num_images = len(images)\n",
        "    num_train = int(train_ratio * num_images)\n",
        "    num_validation = int(validation_ratio * num_images)\n",
        "    num_test = num_images - num_train - num_validation\n",
        "\n",
        "    train_data.extend([(img, label) for img in images[:num_train]])\n",
        "    validation_data.extend([(img, label) for img in images[num_train:num_train + num_validation]])\n",
        "    test_data.extend([(img, label) for img in images[num_train + num_validation:]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2QuytyAZaIt",
        "outputId": "ce828303-3259-4ba0-d716-98df136a658c"
      },
      "outputs": [],
      "source": [
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img, label = self.data[index]\n",
        "\n",
        "        # Convert img to PyTorch tensor\n",
        "        img_tensor = torch.tensor(img, dtype=torch.float32)\n",
        "\n",
        "        return img_tensor, label\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = CustomDataset(train_data)\n",
        "validation_dataset = CustomDataset(validation_data)\n",
        "test_dataset = CustomDataset(test_data)\n",
        "\n",
        "# Create DataLoader instances\n",
        "batch_size = 64  # You can adjust this based on your needs\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Check the tensor size\n",
        "for images, labels in train_loader:\n",
        "    print(images.size())  # This will print the size of the tensor\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "Old Model and train func\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "In9y4e4UPIBo"
      },
      "outputs": [],
      "source": [
        "class CNNLargeNet(nn.Module):\n",
        "    def __init__(self, output1=32, output2=64, output3=128, output4=256):\n",
        "        super(CNNLargeNet, self).__init__()\n",
        "        self.name = \"large\"\n",
        "        \n",
        "        # Define the sequential layers\n",
        "        self.features = nn.Sequential(\n",
        "            # Convolutional Layer 1\n",
        "            nn.Conv2d(3, output1, kernel_size=7, stride=1, padding=3),\n",
        "            nn.BatchNorm2d(output1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(p=0.3),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            \n",
        "            # Convolutional Layer 2\n",
        "            nn.Conv2d(output1, output2, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(output2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(p=0.3),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            \n",
        "            # Convolutional Layer 3\n",
        "            nn.Conv2d(output2, output3, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(output3),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(p=0.3),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            \n",
        "            # Convolutional Layer 4\n",
        "            nn.Conv2d(output3, output4, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(output4),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(p=0.3),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "        \n",
        "        # Flatten the tensor for the fully connected layers\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(output4 * 14 * 14, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.3),\n",
        "            \n",
        "            nn.Linear(128, 64),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.3),\n",
        "            \n",
        "            nn.Linear(64, 8)  # Assuming 8 output classes\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)  # Pass the input through the feature layers\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor for the classifier\n",
        "        x = self.classifier(x)  # Pass the flattened tensor through the classifier\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqI-e7OXPE-F"
      },
      "outputs": [],
      "source": [
        "def trainmodel(model, train_dataset, val_dataset, batch=32, learningRate=0.01, num_epochs=500):\n",
        "    # Create loss function and optimizer.\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learningRate)\n",
        "    # Load data\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch, shuffle=True)\n",
        "    # Create accuracy lists\n",
        "    iters, losses, train_accuracy, validation_accuracy = [], [], [], []\n",
        "    n = 0  # Initialize the iteration counter\n",
        "    # Train the data\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for batch_data in train_loader:\n",
        "            imgs, labels = batch_data\n",
        "            # img_to_tensor = transforms.ToTensor()\n",
        "            # imgs = img_to_tensor(image)\n",
        "            if use_cuda and torch.cuda.is_available():\n",
        "                imgs = imgs.cuda()\n",
        "                labels = labels.cuda()\n",
        "\n",
        "            out = model(imgs)  # Forward pass\n",
        "            loss = criterion(out, labels)  # Compute the total loss\n",
        "            loss.backward()  # Backward pass (compute parameter updates)\n",
        "            optimizer.step()  # Make the updates for each parameter\n",
        "            optimizer.zero_grad()  # A clean-up step for PyTorch\n",
        "            n += 1\n",
        "            # print(\"Input image data type:\", imgs.dtype)\n",
        "            # print(\"Model parameters data types:\")\n",
        "            # for param in model.parameters():\n",
        "            #     print(param.dtype)\n",
        "            # Save the current training information\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        iters.append(n)\n",
        "        losses.append(running_loss / len(train_loader))  # Compute average loss for the epoch\n",
        "        train_accuracy.append(get_accuracy(model, train_dataset))  # Compute training accuracy\n",
        "\n",
        "        # Compute validation accuracy for this epoch\n",
        "        validation_accuracy.append(get_accuracy(model, val_dataset))  # Compute validation accuracy\n",
        "\n",
        "        # Print progress for the epoch\n",
        "        print(\"Epoch {}, Train Accuracy: {:.6f}%, Validation Accuracy: {:.6f}%\".format(\n",
        "            epoch, train_accuracy[epoch], validation_accuracy[epoch]))\n",
        "\n",
        "        # Save model checkpoint\n",
        "        model_checkpoint_path = 'C:/Users/Admin/Desktop/MIE1517_Project/output'  # You can change the directory as needed\n",
        "        model_checkpoint_file = os.path.join(model_checkpoint_path, f'{model.name} =Batch_size_{batch}_model_epoch{epoch + 1}.pth')\n",
        "        torch.save(model.state_dict(), model_checkpoint_file)\n",
        "        print(f\"Saved model checkpoint: {model_checkpoint_file}\")\n",
        "\n",
        "    print(\"Finished Training\")\n",
        "    return iters, losses, train_accuracy, validation_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "End Old Model and train func\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNNLargeNet2(nn.Module):\n",
        "    def __init__( self, output1=32, output2=64, output3=128, output4=256):\n",
        "        super(CNNLargeNet2, self).__init__()\n",
        "        self.name = \"CNN\"\n",
        "        \n",
        "        # Define the sequential layers for feature extraction\n",
        "        self.features = nn.Sequential(\n",
        "            # Convolutional Layer 1\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            \n",
        "            # Convolutional Layer 2\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # Convolutional Layer 3\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # Convolutional Layer 4\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # Convolutional Layer 5\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "        \n",
        "        # Flatten the tensor for the fully connected layers\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(512, 8)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)  # Pass the input through the feature layers\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor for the classifier\n",
        "        x = self.classifier(x)  # Pass the flattened tensor through the classifier\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_model_name(name, batch_size, learning_rate, epoch):\n",
        "    path = \"model_{0}_bs{1}_lr{2}_epoch{3}\".format(name, batch_size, learning_rate, epoch)\n",
        "    return path\n",
        "\n",
        "def evaluate(model, loader):\n",
        "    \"\"\" Evaluate the network \"\"\"\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in loader:\n",
        "      if use_cuda and torch.cuda.is_available():\n",
        "        inputs = inputs.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "      outputs = model(inputs)\n",
        "      predicted = outputs.max(1, keepdim=True)[1]\n",
        "      total += inputs.shape[0]\n",
        "      correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
        "    return correct / total\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def trainmodel2(model, train_dataset, val_dataset, batch=64, learningRate=0.01, num_epochs=300):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learningRate)\n",
        "    \n",
        "    model_checkpoint_path = 'C:/Users/Admin/Desktop/MIE1517_Project/output'  # You can change the directory as needed\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch, shuffle=False) \n",
        "\n",
        "    train_accuracy = np.zeros(num_epochs)\n",
        "    train_losses = np.zeros(num_epochs)\n",
        "    validation_accuracy = np.zeros(num_epochs)\n",
        "    validation_losses = np.zeros(num_epochs)\n",
        "    iters = []\n",
        "\n",
        "    # Check CUDA availability\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    if use_cuda:\n",
        "        model = model.cuda()\n",
        "\n",
        "    n = 0  # Initialize the iteration counter\n",
        "    # Training\n",
        "    print(\"Training Begin...\\n\")\n",
        "    start_time = time.time()\n",
        "    for epoch in range(num_epochs):\n",
        "        # Train mode\n",
        "        model.train()  # Set the model to training mode\n",
        "        running_loss = 0.0\n",
        "        \n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            # Get the inputs\n",
        "            inputs, labels = data\n",
        "            # Set up for gpu running\n",
        "            if use_cuda and torch.cuda.is_available():\n",
        "                inputs = inputs.cuda()\n",
        "                labels = labels.cuda()\n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "            # Forward pass, backward pass, and optimize\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            n += 1\n",
        "            # Calculate loss\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        train_losses[epoch] = running_loss\n",
        "        train_accuracy[epoch] = evaluate(model, train_loader)\n",
        "        \n",
        "        # Evaluation mode\n",
        "        model.eval()  # Set the model to evaluation mode for accuracy computation\n",
        "        valid_loss = 0.0\n",
        "        # Running without gradients are computed and model weights update\n",
        "        for inputs, labels in val_loader:\n",
        "            if use_cuda and torch.cuda.is_available():\n",
        "                inputs = inputs.cuda()\n",
        "                labels = labels.cuda()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            valid_loss += loss.item()\n",
        "\n",
        "        validation_losses[epoch] = valid_loss\n",
        "        validation_accuracy[epoch] = evaluate(model, val_loader)\n",
        "        iters.append(n)\n",
        "        \n",
        "        # Print progress for the epoch\n",
        "        print((\"Epoch {}: Train Accuracy: {}, Train loss: {} |\"+\n",
        "               \"Validation Accuracy: {}, Validation loss: {}\").format(\n",
        "                   epoch + 1,\n",
        "                   train_accuracy[epoch],\n",
        "                   train_losses[epoch],\n",
        "                   validation_accuracy[epoch],\n",
        "                   validation_losses[epoch]))\n",
        "\n",
        "        # Save model checkpoint every 5 epochs\n",
        "        # if (epoch + 1) % 5 == 0:  # +1 because epochs start from 0\n",
        "            # Save the current model checkpoint to a file\n",
        "        model_path = get_model_name(model.name, batch_size, learningRate, epoch)\n",
        "        model_path = os.path.join(model_checkpoint_path, model_path)\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "\n",
        "    print(\"Finshied Training\")\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    print(\"Total time elapsed: {:.2f} seconds\".format(elapsed_time))\n",
        "    # Write the train/test loss/err into CSV file for plotting later\n",
        "    # Save model checkpoint\n",
        "    epochs = np.arange(1, num_epochs + 1)\n",
        "    np.savetxt(\"{}_train_acc.csv\".format(model_path), train_accuracy)\n",
        "    np.savetxt(\"{}_train_loss.csv\".format(model_path), train_losses)\n",
        "    np.savetxt(\"{}_val_acc.csv\".format(model_path), validation_accuracy)\n",
        "    np.savetxt(\"{}_val_loss.csv\".format(model_path), validation_losses)\n",
        "\n",
        "    plt.title(\"Training Loss Curve\")\n",
        "    plt.plot(iters, train_losses, label=\"Train\")\n",
        "    plt.xlabel(\"iters\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Accuracy Curve\")\n",
        "    plt.plot(iters, train_accuracy, label=\"Train\")\n",
        "    plt.xlabel(\"iters\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.show()\n",
        "    print(\"Finished Training\")\n",
        "    return iters, train_losses, train_accuracy, validation_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HbBsnUppOWft"
      },
      "outputs": [],
      "source": [
        "def trainSmall(model, data, batch_size=32, learning_rate=0.01, num_epochs=260):\n",
        "    train_loader = torch.utils.data.DataLoader(data, batch_size=batch_size)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    train_acc = []\n",
        "\n",
        "    # training\n",
        "    print(\"Training Start\")\n",
        "    n = 0  # the number of iterations\n",
        "    for epoch in range(num_epochs):\n",
        "        for imgs, labels in iter(train_loader):\n",
        "            #############################################\n",
        "            # To Enable GPU Usage\n",
        "            imgs = imgs.cuda()\n",
        "            labels = labels.cuda()\n",
        "            #############################################\n",
        "\n",
        "            # Check if imgs is already a tensor\n",
        "            if not torch.is_tensor(imgs):\n",
        "                img_to_tensor = transforms.ToTensor()\n",
        "                imgs = img_to_tensor(imgs)\n",
        "\n",
        "                # Convert input to float\n",
        "                imgs = imgs.float()\n",
        "\n",
        "            # Convert the input tensor to the desired type\n",
        "            imgs = imgs.type(torch.float32)\n",
        "\n",
        "            out = model(imgs)  # forward pass\n",
        "            loss = criterion(out, labels)  # compute the total loss\n",
        "            loss.backward()  # backward pass (compute parameter updates)\n",
        "            optimizer.step()  # make the updates for each parameter\n",
        "            optimizer.zero_grad()  # a clean-up step for PyTorch\n",
        "            n += 1\n",
        "\n",
        "        train_accuracy = get_accuracy(model, data)\n",
        "        train_acc.append(train_accuracy)\n",
        "        print(\"Epoch:{}, Accuracy:{}\".format(epoch, train_accuracy))\n",
        "    return train_acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "Miqu5ClEFpms",
        "outputId": "bc5bc88e-72e8-4b5b-9a81-85530686451b"
      },
      "outputs": [],
      "source": [
        "batch_size = 3\n",
        "num_workers = 1\n",
        "small_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
        "\n",
        "# Visualize some sample data\n",
        "classes = ['neutrality', 'sadness', 'fear', 'surprise', 'contempt', 'happiness', 'anger', 'disgust']\n",
        "dataiter = iter(small_loader)\n",
        "images, labels = next(dataiter)\n",
        "images = images.numpy() # convert images to numpy for display\n",
        "\n",
        "# plot the images in the batch, along with the corresponding labels\n",
        "fig = plt.figure(figsize=(25, 4))\n",
        "for idx in np.arange(3):\n",
        "    ax = fig.add_subplot(2, 10, idx+1, xticks=[], yticks=[])\n",
        "\n",
        "    # If the image has three channels\n",
        "    if images[idx].shape[0] == 3:\n",
        "        plt.imshow(np.transpose(images[idx], (1, 2, 0)))\n",
        "    else:  # If the image is grayscale\n",
        "        plt.imshow(images[idx][0], cmap='gray')\n",
        "\n",
        "    ax.set_title(classes[labels[idx]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "bKZlLIGwPd0i",
        "outputId": "b6949fb4-0515-45b8-e331-5cd04032217b"
      },
      "outputs": [],
      "source": [
        "use_cuda = True\n",
        "if torch.cuda.is_available():\n",
        "    model = CNNLargeNet2().cuda()\n",
        "Y = trainmodel2(model, train_data, validation_data, batch=64, learningRate=0.01, num_epochs=300)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNKjhrpRYKfoHxX11YR45Ru",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
