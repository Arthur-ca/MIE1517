{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Arthur-ca/MIE1517/blob/YayunYang/Project_small.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-12T19:40:11.603938107Z",
     "start_time": "2023-11-12T19:40:09.387315148Z"
    },
    "id": "yq0MKgApDInX"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import torchvision\n",
    "import time\n",
    "import cv2 as cv\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as F1\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import imgaug.augmenters as iaa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import datasets, models, transforms\n",
    "from collections import defaultdict\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-12T19:40:11.612871727Z",
     "start_time": "2023-11-12T19:40:11.605457967Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fTd6YA73JsJC",
    "outputId": "11591e23-0766-4fcc-b198-d7831c3014c3"
   },
   "outputs": [],
   "source": [
    "directory_path = '/content/gdrive/MyDrive/archive'\n",
    "ds_store_path = os.path.join(directory_path, '.DS_Store')\n",
    "\n",
    "if os.path.exists(ds_store_path):\n",
    "    os.remove(ds_store_path)\n",
    "else:\n",
    "    print(\".DS_Store file does not exist in the directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-12T19:40:11.623339999Z",
     "start_time": "2023-11-12T19:40:11.607784429Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "PjxPEAukDNt-",
    "outputId": "0434ef2d-373a-4498-8a0f-1f57f4f16bf2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger', 'contempt', 'disgust', 'fear', 'happiness', 'neutrality', 'sadness', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "#First link it to google drive and check the subfolder of the data\n",
    "# data_path = '/home/qinghao/backup/MIE1517/dataset'\n",
    "data_path = 'C:/Users/Z/Desktop/MIE1517/data'\n",
    "drive_content = os.listdir(data_path)\n",
    "print(drive_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-12T19:40:11.623428127Z",
     "start_time": "2023-11-12T19:40:11.619135809Z"
    },
    "id": "lHFVdw5apSEu"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-12T19:40:11.663491795Z",
     "start_time": "2023-11-12T19:40:11.622755681Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T6_Ip_NB52CQ",
    "outputId": "c32d294c-3d28-4010-8340-c747d34b8a47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anger',\n",
       " 'contempt',\n",
       " 'disgust',\n",
       " 'fear',\n",
       " 'happiness',\n",
       " 'neutrality',\n",
       " 'sadness',\n",
       " 'surprise']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classeses = []\n",
    "for i in os.listdir(data_path):\n",
    "    if i!=5:\n",
    "        classeses.append(i)\n",
    "classeses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-12T19:40:11.663905150Z",
     "start_time": "2023-11-12T19:40:11.663263045Z"
    },
    "id": "EkEP0L_ASYVb"
   },
   "outputs": [],
   "source": [
    "# def gauss_noise_tensor(img):\n",
    "#     assert isinstance(img, torch.Tensor)\n",
    "#     dtype = img.dtype\n",
    "#     if not img.is_floating_point():\n",
    "#         img = img.to(torch.float32)\n",
    "\n",
    "#     sigma = 25.0\n",
    "\n",
    "#     out = img + sigma * torch.randn_like(img)\n",
    "\n",
    "#     if out.dtype != dtype:\n",
    "#         out = out.to(dtype)\n",
    "\n",
    "#     return out\n",
    "# class ImgAugTransform:\n",
    "#     def __init__(self):\n",
    "#         self.aug = iaa.Sequential([\n",
    "#             iaa.Resize({\"height\": 224, \"width\": 224}),\n",
    "#             iaa.Sometimes(0.25, iaa.GaussianBlur(sigma=(0, 3.0))),\n",
    "#             iaa.Sometimes(0.25, iaa.Affine(rotate=(-20, 20), mode='symmetric')),\n",
    "#             iaa.Sometimes(0.25, iaa.OneOf([\n",
    "#                 iaa.Dropout(p=(0, 0.1)),\n",
    "#                 iaa.CoarseDropout(0.1, size_percent=0.5)\n",
    "#             ])),\n",
    "#             iaa.AddToHueAndSaturation(value=(-10, 10), per_channel=True)\n",
    "#         ])\n",
    "\n",
    "#     def __call__(self, img):\n",
    "#         img = np.array(img)\n",
    "\n",
    "#         augmented_img = self.aug.augment_image(img)\n",
    "\n",
    "#         # Convert the augmented image to PyTorch tensor\n",
    "#         augmented_tensor = F1.to_tensor(augmented_img)\n",
    "#         return self.aug.augment_image(img)\n",
    "#   imgaug_transform = ImgAugTransform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "```\n",
    "Our dataset contains over 5000 photos. Training on this dataset requires significant computing power. However, the best hardware we have is a computer equipped with an Nvidia RTX2080 GPU. To ensure that the model can be trained on the entire dataset, we plan to use 5% of the original data as our training dataset. Below is our code for extracting a small training dataset, a small training function, and the CNN model structure.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-12T19:40:11.839983308Z",
     "start_time": "2023-11-12T19:40:11.663367478Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EjPs44Ion4HI",
    "outputId": "fbcb4fd7-c826-43bb-c41f-22eaa10adc66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "Label 0: 37 images\n",
      "Label 1: 10 images\n",
      "Label 2: 21 images\n",
      "Label 3: 26 images\n",
      "Label 4: 28 images\n",
      "Label 5: 70 images\n",
      "Label 6: 38 images\n",
      "Label 7: 44 images\n"
     ]
    }
   ],
   "source": [
    "features_or = []\n",
    "labels_or = []\n",
    "train_data_or = []\n",
    "data_transform1 = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "def create_train2(data_percentage=5):\n",
    "    for i, photo in enumerate(classeses):\n",
    "        path = os.path.join(data_path, photo)\n",
    "        label = i  # Use the index of the class as the label\n",
    "\n",
    "        # List all images in the class folder\n",
    "        img_list = os.listdir(path)\n",
    "\n",
    "        # Calculate the number of images to load (5% of total)\n",
    "        num_images_to_load = int(len(img_list) * (data_percentage / 100))\n",
    "\n",
    "        # Randomly select a subset of images\n",
    "        selected_images = random.sample(img_list, num_images_to_load)\n",
    "\n",
    "\n",
    "        for img_name in selected_images:\n",
    "            img_path = os.path.join(path, img_name)\n",
    "            img_pil = Image.open(img_path)\n",
    "            transformed_image1 = data_transform1(img_pil)\n",
    "\n",
    "            if img_pil is None:\n",
    "                print(\"Error loading image:\", img_path)\n",
    "                continue\n",
    "\n",
    "            # Append the original image and its label to the list\n",
    "            features_or.append(transformed_image1)\n",
    "            labels_or.append(label)\n",
    "\n",
    "            train_data_or.append([img_pil, label])\n",
    "\n",
    "create_train2(data_percentage=5)  # Load only 5% of the data\n",
    "print(type(features_or[0]))\n",
    "# Count the occurrences of each label\n",
    "label_counts_or = Counter(labels_or)\n",
    "\n",
    "# Print the label counts\n",
    "for label, count in label_counts_or.items():\n",
    "    print(f\"Label {label}: {count} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-12T19:40:11.897057207Z",
     "start_time": "2023-11-12T19:40:11.841400630Z"
    },
    "id": "46ITZDBRT51_"
   },
   "outputs": [],
   "source": [
    "# Define a transformation to convert PIL images to PyTorch tensors\n",
    "data_transform_to_tensor = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Convert images and labels to PyTorch tensors\n",
    "train_images = torch.stack([data_transform_to_tensor(data[0]) for data in train_data_or])\n",
    "train_labels = torch.tensor([data[1] for data in train_data_or])\n",
    "\n",
    "# Assuming you have a DataLoader for your training loop\n",
    "train_dataset = torch.utils.data.TensorDataset(train_images, train_labels)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-12T19:40:11.939482143Z",
     "start_time": "2023-11-12T19:40:11.898803195Z"
    },
    "id": "bxh0XEA-SRrE"
   },
   "outputs": [],
   "source": [
    "def get_accuracy(model, dataset):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for imgs, labels in torch.utils.data.DataLoader(dataset, batch_size=64):\n",
    "        #############################################\n",
    "        #To Enable GPU Usage\n",
    "        if use_cuda and torch.cuda.is_available():\n",
    "          imgs = imgs.cuda()\n",
    "          labels = labels.cuda()\n",
    "        #############################################\n",
    "        output = model(imgs)\n",
    "        #select index with maximum prediction score\n",
    "        pred = output.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "        total += imgs.shape[0]\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-12T19:40:11.939654343Z",
     "start_time": "2023-11-12T19:40:11.939390940Z"
    },
    "id": "FE_M9cyTQ9_l"
   },
   "outputs": [],
   "source": [
    "def trainSmall(model, data, batch_size, learning_rate, num_epochs):\n",
    "    train_loader = torch.utils.data.DataLoader(data, batch_size=batch_size)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    train_acc = []\n",
    "\n",
    "    # training\n",
    "    print(\"Training Start\")\n",
    "    n = 0  # the number of iterations\n",
    "    for epoch in range(num_epochs):\n",
    "        for imgs, labels in iter(train_loader):\n",
    "            #############################################\n",
    "            # To Enable GPU Usage\n",
    "            imgs = imgs.cuda()\n",
    "            labels = labels.cuda()\n",
    "            #############################################\n",
    "\n",
    "            # Check if imgs is already a tensor\n",
    "            if not torch.is_tensor(imgs):\n",
    "                img_to_tensor = transforms.ToTensor()\n",
    "                imgs = img_to_tensor(imgs)\n",
    "\n",
    "                # Convert input to float\n",
    "                imgs = imgs.float()\n",
    "\n",
    "            # Convert the input tensor to the desired type\n",
    "            imgs = imgs.type(torch.float32)\n",
    "\n",
    "            out = model(imgs)  # forward pass\n",
    "            loss = criterion(out, labels)  # compute the total loss\n",
    "            loss.backward()  # backward pass (compute parameter updates)\n",
    "            optimizer.step()  # make the updates for each parameter\n",
    "            optimizer.zero_grad()  # a clean-up step for PyTorch\n",
    "            n += 1\n",
    "\n",
    "        train_accuracy = get_accuracy(model, data)\n",
    "        train_acc.append(train_accuracy)\n",
    "        print(\"Epoch:{}, Accuracy:{}\".format(epoch, train_accuracy))\n",
    "    return train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-12T19:40:11.939961348Z",
     "start_time": "2023-11-12T19:40:11.939564648Z"
    },
    "id": "ghFYeltCS2-l"
   },
   "outputs": [],
   "source": [
    "class CNNLargeNet2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNLargeNet2, self).__init__()\n",
    "        self.name = \"CNN\"\n",
    "\n",
    "        # Define the sequential layers for feature extraction\n",
    "        self.features = nn.Sequential(\n",
    "            # Convolutional Layer 1\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            # Convolutional Layer 2\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            # Convolutional Layer 3\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            # Convolutional Layer 4\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            # Convolutional Layer 5\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "        # Flatten the tensor for the fully connected layers\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            #nn.Dropout(p=0.5),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            #nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, 8)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)  # Pass the input through the feature layers\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor for the classifier\n",
    "        x = self.classifier(x)  # Pass the flattened tensor through the classifier\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Below is the process by which we tuned the hyperparameters and trained the model to achieve overfitting. During this process we tried many different combinations of hyperparameters, and only a few examples are shown below along with their results. In the end, we reached overfitting after 260 epochs with batch_size = 64 and learning_rate = 0.005."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-12T20:27:15.904408860Z",
     "start_time": "2023-11-12T20:21:55.027701485Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Start\n",
      "Epoch:0, Accuracy:0.07664233576642336\n",
      "Epoch:1, Accuracy:0.2591240875912409\n",
      "Epoch:2, Accuracy:0.16058394160583941\n",
      "Epoch:3, Accuracy:0.1678832116788321\n",
      "Epoch:4, Accuracy:0.1678832116788321\n",
      "Epoch:5, Accuracy:0.16058394160583941\n",
      "Epoch:6, Accuracy:0.1678832116788321\n",
      "Epoch:7, Accuracy:0.17883211678832117\n",
      "Epoch:8, Accuracy:0.17883211678832117\n",
      "Epoch:9, Accuracy:0.18248175182481752\n",
      "Epoch:10, Accuracy:0.17883211678832117\n",
      "Epoch:11, Accuracy:0.17883211678832117\n",
      "Epoch:12, Accuracy:0.19708029197080293\n",
      "Epoch:13, Accuracy:0.18613138686131386\n",
      "Epoch:14, Accuracy:0.17883211678832117\n",
      "Epoch:15, Accuracy:0.1678832116788321\n",
      "Epoch:16, Accuracy:0.17153284671532848\n",
      "Epoch:17, Accuracy:0.19343065693430658\n",
      "Epoch:18, Accuracy:0.1897810218978102\n",
      "Epoch:19, Accuracy:0.18248175182481752\n",
      "Epoch:20, Accuracy:0.18613138686131386\n",
      "Epoch:21, Accuracy:0.20072992700729927\n",
      "Epoch:22, Accuracy:0.20437956204379562\n",
      "Epoch:23, Accuracy:0.20437956204379562\n",
      "Epoch:24, Accuracy:0.20802919708029197\n",
      "Epoch:25, Accuracy:0.21532846715328466\n",
      "Epoch:26, Accuracy:0.20802919708029197\n",
      "Epoch:27, Accuracy:0.21897810218978103\n",
      "Epoch:28, Accuracy:0.2116788321167883\n",
      "Epoch:29, Accuracy:0.20802919708029197\n",
      "Epoch:30, Accuracy:0.19708029197080293\n",
      "Epoch:31, Accuracy:0.2116788321167883\n",
      "Epoch:32, Accuracy:0.21532846715328466\n",
      "Epoch:33, Accuracy:0.21532846715328466\n",
      "Epoch:34, Accuracy:0.21897810218978103\n",
      "Epoch:35, Accuracy:0.22262773722627738\n",
      "Epoch:36, Accuracy:0.22627737226277372\n",
      "Epoch:37, Accuracy:0.23357664233576642\n",
      "Epoch:38, Accuracy:0.22992700729927007\n",
      "Epoch:39, Accuracy:0.23722627737226276\n",
      "Epoch:40, Accuracy:0.24087591240875914\n",
      "Epoch:41, Accuracy:0.24452554744525548\n",
      "Epoch:42, Accuracy:0.24452554744525548\n",
      "Epoch:43, Accuracy:0.23722627737226276\n",
      "Epoch:44, Accuracy:0.27007299270072993\n",
      "Epoch:45, Accuracy:0.22262773722627738\n",
      "Epoch:46, Accuracy:0.3175182481751825\n",
      "Epoch:47, Accuracy:0.22992700729927007\n",
      "Epoch:48, Accuracy:0.354014598540146\n",
      "Epoch:49, Accuracy:0.2518248175182482\n",
      "Epoch:50, Accuracy:0.3284671532846715\n",
      "Epoch:51, Accuracy:0.3102189781021898\n",
      "Epoch:52, Accuracy:0.3284671532846715\n",
      "Epoch:53, Accuracy:0.3357664233576642\n",
      "Epoch:54, Accuracy:0.34306569343065696\n",
      "Epoch:55, Accuracy:0.33941605839416056\n",
      "Epoch:56, Accuracy:0.35766423357664234\n",
      "Epoch:57, Accuracy:0.36496350364963503\n",
      "Epoch:58, Accuracy:0.40875912408759124\n",
      "Epoch:59, Accuracy:0.36496350364963503\n",
      "Epoch:60, Accuracy:0.40145985401459855\n",
      "Epoch:61, Accuracy:0.3686131386861314\n",
      "Epoch:62, Accuracy:0.4562043795620438\n",
      "Epoch:63, Accuracy:0.3795620437956204\n",
      "Epoch:64, Accuracy:0.4343065693430657\n",
      "Epoch:65, Accuracy:0.4781021897810219\n",
      "Epoch:66, Accuracy:0.32116788321167883\n",
      "Epoch:67, Accuracy:0.20072992700729927\n",
      "Epoch:68, Accuracy:0.18248175182481752\n",
      "Epoch:69, Accuracy:0.17518248175182483\n",
      "Epoch:70, Accuracy:0.18248175182481752\n",
      "Epoch:71, Accuracy:0.1678832116788321\n",
      "Epoch:72, Accuracy:0.15328467153284672\n",
      "Epoch:73, Accuracy:0.28102189781021897\n",
      "Epoch:74, Accuracy:0.28832116788321166\n",
      "Epoch:75, Accuracy:0.18613138686131386\n",
      "Epoch:76, Accuracy:0.18613138686131386\n",
      "Epoch:77, Accuracy:0.18613138686131386\n",
      "Epoch:78, Accuracy:0.18248175182481752\n",
      "Epoch:79, Accuracy:0.18613138686131386\n",
      "Epoch:80, Accuracy:0.18613138686131386\n",
      "Epoch:81, Accuracy:0.18613138686131386\n",
      "Epoch:82, Accuracy:0.18613138686131386\n",
      "Epoch:83, Accuracy:0.1897810218978102\n",
      "Epoch:84, Accuracy:0.18613138686131386\n",
      "Epoch:85, Accuracy:0.18613138686131386\n",
      "Epoch:86, Accuracy:0.18613138686131386\n",
      "Epoch:87, Accuracy:0.19343065693430658\n",
      "Epoch:88, Accuracy:0.1897810218978102\n",
      "Epoch:89, Accuracy:0.19343065693430658\n",
      "Epoch:90, Accuracy:0.19343065693430658\n",
      "Epoch:91, Accuracy:0.19343065693430658\n",
      "Epoch:92, Accuracy:0.19343065693430658\n",
      "Epoch:93, Accuracy:0.19343065693430658\n",
      "Epoch:94, Accuracy:0.1897810218978102\n",
      "Epoch:95, Accuracy:0.19343065693430658\n",
      "Epoch:96, Accuracy:0.19343065693430658\n",
      "Epoch:97, Accuracy:0.1897810218978102\n",
      "Epoch:98, Accuracy:0.1897810218978102\n",
      "Epoch:99, Accuracy:0.19343065693430658\n",
      "Epoch:100, Accuracy:0.19343065693430658\n",
      "Epoch:101, Accuracy:0.19343065693430658\n",
      "Epoch:102, Accuracy:0.19343065693430658\n",
      "Epoch:103, Accuracy:0.19343065693430658\n",
      "Epoch:104, Accuracy:0.19343065693430658\n",
      "Epoch:105, Accuracy:0.19343065693430658\n",
      "Epoch:106, Accuracy:0.18613138686131386\n",
      "Epoch:107, Accuracy:0.19343065693430658\n",
      "Epoch:108, Accuracy:0.19343065693430658\n",
      "Epoch:109, Accuracy:0.19343065693430658\n",
      "Epoch:110, Accuracy:0.1897810218978102\n",
      "Epoch:111, Accuracy:0.19343065693430658\n",
      "Epoch:112, Accuracy:0.19343065693430658\n",
      "Epoch:113, Accuracy:0.19343065693430658\n",
      "Epoch:114, Accuracy:0.1897810218978102\n",
      "Epoch:115, Accuracy:0.19343065693430658\n",
      "Epoch:116, Accuracy:0.19343065693430658\n",
      "Epoch:117, Accuracy:0.19343065693430658\n",
      "Epoch:118, Accuracy:0.19343065693430658\n",
      "Epoch:119, Accuracy:0.19343065693430658\n",
      "Epoch:120, Accuracy:0.19343065693430658\n",
      "Epoch:121, Accuracy:0.19343065693430658\n",
      "Epoch:122, Accuracy:0.19343065693430658\n",
      "Epoch:123, Accuracy:0.19343065693430658\n",
      "Epoch:124, Accuracy:0.19343065693430658\n",
      "Epoch:125, Accuracy:0.19343065693430658\n",
      "Epoch:126, Accuracy:0.19343065693430658\n",
      "Epoch:127, Accuracy:0.19343065693430658\n",
      "Epoch:128, Accuracy:0.19343065693430658\n",
      "Epoch:129, Accuracy:0.19343065693430658\n",
      "Epoch:130, Accuracy:0.19343065693430658\n",
      "Epoch:131, Accuracy:0.19343065693430658\n",
      "Epoch:132, Accuracy:0.19343065693430658\n",
      "Epoch:133, Accuracy:0.19343065693430658\n",
      "Epoch:134, Accuracy:0.19343065693430658\n",
      "Epoch:135, Accuracy:0.19343065693430658\n",
      "Epoch:136, Accuracy:0.19343065693430658\n",
      "Epoch:137, Accuracy:0.19343065693430658\n",
      "Epoch:138, Accuracy:0.19343065693430658\n",
      "Epoch:139, Accuracy:0.19343065693430658\n",
      "Epoch:140, Accuracy:0.19343065693430658\n",
      "Epoch:141, Accuracy:0.19343065693430658\n",
      "Epoch:142, Accuracy:0.19343065693430658\n",
      "Epoch:143, Accuracy:0.19343065693430658\n",
      "Epoch:144, Accuracy:0.19343065693430658\n",
      "Epoch:145, Accuracy:0.19343065693430658\n",
      "Epoch:146, Accuracy:0.19343065693430658\n",
      "Epoch:147, Accuracy:0.19343065693430658\n",
      "Epoch:148, Accuracy:0.19343065693430658\n",
      "Epoch:149, Accuracy:0.19343065693430658\n",
      "Epoch:150, Accuracy:0.19708029197080293\n",
      "Epoch:151, Accuracy:0.19708029197080293\n",
      "Epoch:152, Accuracy:0.19708029197080293\n",
      "Epoch:153, Accuracy:0.19343065693430658\n",
      "Epoch:154, Accuracy:0.19343065693430658\n",
      "Epoch:155, Accuracy:0.19343065693430658\n",
      "Epoch:156, Accuracy:0.19343065693430658\n",
      "Epoch:157, Accuracy:0.19343065693430658\n",
      "Epoch:158, Accuracy:0.19343065693430658\n",
      "Epoch:159, Accuracy:0.19343065693430658\n",
      "Epoch:160, Accuracy:0.19343065693430658\n",
      "Epoch:161, Accuracy:0.19343065693430658\n",
      "Epoch:162, Accuracy:0.19343065693430658\n",
      "Epoch:163, Accuracy:0.19343065693430658\n",
      "Epoch:164, Accuracy:0.19343065693430658\n",
      "Epoch:165, Accuracy:0.19343065693430658\n",
      "Epoch:166, Accuracy:0.19343065693430658\n",
      "Epoch:167, Accuracy:0.19343065693430658\n",
      "Epoch:168, Accuracy:0.19343065693430658\n",
      "Epoch:169, Accuracy:0.19343065693430658\n",
      "Epoch:170, Accuracy:0.19343065693430658\n",
      "Epoch:171, Accuracy:0.19343065693430658\n",
      "Epoch:172, Accuracy:0.19343065693430658\n",
      "Epoch:173, Accuracy:0.19343065693430658\n",
      "Epoch:174, Accuracy:0.19343065693430658\n",
      "Epoch:175, Accuracy:0.19343065693430658\n",
      "Epoch:176, Accuracy:0.19343065693430658\n",
      "Epoch:177, Accuracy:0.19343065693430658\n",
      "Epoch:178, Accuracy:0.19708029197080293\n",
      "Epoch:179, Accuracy:0.19343065693430658\n",
      "Epoch:180, Accuracy:0.19708029197080293\n",
      "Epoch:181, Accuracy:0.19708029197080293\n",
      "Epoch:182, Accuracy:0.19708029197080293\n",
      "Epoch:183, Accuracy:0.19708029197080293\n",
      "Epoch:184, Accuracy:0.1897810218978102\n",
      "Epoch:185, Accuracy:0.19708029197080293\n",
      "Epoch:186, Accuracy:0.19708029197080293\n",
      "Epoch:187, Accuracy:0.19708029197080293\n",
      "Epoch:188, Accuracy:0.19343065693430658\n",
      "Epoch:189, Accuracy:0.19343065693430658\n",
      "Epoch:190, Accuracy:0.19343065693430658\n",
      "Epoch:191, Accuracy:0.19343065693430658\n",
      "Epoch:192, Accuracy:0.19343065693430658\n",
      "Epoch:193, Accuracy:0.19343065693430658\n",
      "Epoch:194, Accuracy:0.19343065693430658\n",
      "Epoch:195, Accuracy:0.19343065693430658\n",
      "Epoch:196, Accuracy:0.19343065693430658\n",
      "Epoch:197, Accuracy:0.19343065693430658\n",
      "Epoch:198, Accuracy:0.19343065693430658\n",
      "Epoch:199, Accuracy:0.19343065693430658\n",
      "Epoch:200, Accuracy:0.19708029197080293\n",
      "Epoch:201, Accuracy:0.19708029197080293\n",
      "Epoch:202, Accuracy:0.19708029197080293\n",
      "Epoch:203, Accuracy:0.19708029197080293\n",
      "Epoch:204, Accuracy:0.19708029197080293\n",
      "Epoch:205, Accuracy:0.19708029197080293\n",
      "Epoch:206, Accuracy:0.19708029197080293\n",
      "Epoch:207, Accuracy:0.19708029197080293\n",
      "Epoch:208, Accuracy:0.19708029197080293\n",
      "Epoch:209, Accuracy:0.19708029197080293\n",
      "Epoch:210, Accuracy:0.18613138686131386\n",
      "Epoch:211, Accuracy:0.19708029197080293\n",
      "Epoch:212, Accuracy:0.19708029197080293\n",
      "Epoch:213, Accuracy:0.19343065693430658\n",
      "Epoch:214, Accuracy:0.19343065693430658\n",
      "Epoch:215, Accuracy:0.19708029197080293\n",
      "Epoch:216, Accuracy:0.20072992700729927\n",
      "Epoch:217, Accuracy:0.1897810218978102\n",
      "Epoch:218, Accuracy:0.1897810218978102\n",
      "Epoch:219, Accuracy:0.17883211678832117\n",
      "Epoch:220, Accuracy:0.16058394160583941\n",
      "Epoch:221, Accuracy:0.16058394160583941\n",
      "Epoch:222, Accuracy:0.16423357664233576\n",
      "Epoch:223, Accuracy:0.16058394160583941\n",
      "Epoch:224, Accuracy:0.16423357664233576\n",
      "Epoch:225, Accuracy:0.16423357664233576\n",
      "Epoch:226, Accuracy:0.16423357664233576\n",
      "Epoch:227, Accuracy:0.16058394160583941\n",
      "Epoch:228, Accuracy:0.16058394160583941\n",
      "Epoch:229, Accuracy:0.16058394160583941\n",
      "Epoch:230, Accuracy:0.16423357664233576\n",
      "Epoch:231, Accuracy:0.16423357664233576\n",
      "Epoch:232, Accuracy:0.16058394160583941\n",
      "Epoch:233, Accuracy:0.16058394160583941\n",
      "Epoch:234, Accuracy:0.16423357664233576\n",
      "Epoch:235, Accuracy:0.16423357664233576\n",
      "Epoch:236, Accuracy:0.16423357664233576\n",
      "Epoch:237, Accuracy:0.16423357664233576\n",
      "Epoch:238, Accuracy:0.16423357664233576\n",
      "Epoch:239, Accuracy:0.16423357664233576\n",
      "Epoch:240, Accuracy:0.16423357664233576\n",
      "Epoch:241, Accuracy:0.16423357664233576\n",
      "Epoch:242, Accuracy:0.16423357664233576\n",
      "Epoch:243, Accuracy:0.16058394160583941\n",
      "Epoch:244, Accuracy:0.16423357664233576\n",
      "Epoch:245, Accuracy:0.16423357664233576\n",
      "Epoch:246, Accuracy:0.16058394160583941\n",
      "Epoch:247, Accuracy:0.16058394160583941\n",
      "Epoch:248, Accuracy:0.16058394160583941\n",
      "Epoch:249, Accuracy:0.16058394160583941\n",
      "Epoch:250, Accuracy:0.16058394160583941\n",
      "Epoch:251, Accuracy:0.16058394160583941\n",
      "Epoch:252, Accuracy:0.16058394160583941\n",
      "Epoch:253, Accuracy:0.16058394160583941\n",
      "Epoch:254, Accuracy:0.16058394160583941\n",
      "Epoch:255, Accuracy:0.16058394160583941\n",
      "Epoch:256, Accuracy:0.16058394160583941\n",
      "Epoch:257, Accuracy:0.16058394160583941\n",
      "Epoch:258, Accuracy:0.16058394160583941\n",
      "Epoch:259, Accuracy:0.16058394160583941\n",
      "Epoch:260, Accuracy:0.16058394160583941\n",
      "Epoch:261, Accuracy:0.16058394160583941\n",
      "Epoch:262, Accuracy:0.16058394160583941\n",
      "Epoch:263, Accuracy:0.16058394160583941\n",
      "Epoch:264, Accuracy:0.16058394160583941\n",
      "Epoch:265, Accuracy:0.16058394160583941\n",
      "Epoch:266, Accuracy:0.16058394160583941\n",
      "Epoch:267, Accuracy:0.16058394160583941\n",
      "Epoch:268, Accuracy:0.16058394160583941\n",
      "Epoch:269, Accuracy:0.16058394160583941\n",
      "Epoch:270, Accuracy:0.16058394160583941\n",
      "Epoch:271, Accuracy:0.16058394160583941\n",
      "Epoch:272, Accuracy:0.16058394160583941\n",
      "Epoch:273, Accuracy:0.16058394160583941\n",
      "Epoch:274, Accuracy:0.16058394160583941\n",
      "Epoch:275, Accuracy:0.16058394160583941\n",
      "Epoch:276, Accuracy:0.16058394160583941\n",
      "Epoch:277, Accuracy:0.16058394160583941\n",
      "Epoch:278, Accuracy:0.16058394160583941\n",
      "Epoch:279, Accuracy:0.16058394160583941\n",
      "Epoch:280, Accuracy:0.16058394160583941\n",
      "Epoch:281, Accuracy:0.16058394160583941\n",
      "Epoch:282, Accuracy:0.16058394160583941\n",
      "Epoch:283, Accuracy:0.16058394160583941\n",
      "Epoch:284, Accuracy:0.16058394160583941\n",
      "Epoch:285, Accuracy:0.16058394160583941\n",
      "Epoch:286, Accuracy:0.16058394160583941\n",
      "Epoch:287, Accuracy:0.16058394160583941\n",
      "Epoch:288, Accuracy:0.16058394160583941\n",
      "Epoch:289, Accuracy:0.16058394160583941\n",
      "Epoch:290, Accuracy:0.16058394160583941\n",
      "Epoch:291, Accuracy:0.16058394160583941\n",
      "Epoch:292, Accuracy:0.16058394160583941\n",
      "Epoch:293, Accuracy:0.16058394160583941\n",
      "Epoch:294, Accuracy:0.16058394160583941\n",
      "Epoch:295, Accuracy:0.16058394160583941\n",
      "Epoch:296, Accuracy:0.16058394160583941\n",
      "Epoch:297, Accuracy:0.16058394160583941\n",
      "Epoch:298, Accuracy:0.16058394160583941\n",
      "Epoch:299, Accuracy:0.16058394160583941\n",
      "Epoch:300, Accuracy:0.16058394160583941\n",
      "Epoch:301, Accuracy:0.16058394160583941\n",
      "Epoch:302, Accuracy:0.16058394160583941\n",
      "Epoch:303, Accuracy:0.16058394160583941\n",
      "Epoch:304, Accuracy:0.16058394160583941\n",
      "Epoch:305, Accuracy:0.16058394160583941\n",
      "Epoch:306, Accuracy:0.16058394160583941\n",
      "Epoch:307, Accuracy:0.16058394160583941\n",
      "Epoch:308, Accuracy:0.16058394160583941\n",
      "Epoch:309, Accuracy:0.16058394160583941\n",
      "Epoch:310, Accuracy:0.16058394160583941\n",
      "Epoch:311, Accuracy:0.16058394160583941\n",
      "Epoch:312, Accuracy:0.16058394160583941\n",
      "Epoch:313, Accuracy:0.16058394160583941\n",
      "Epoch:314, Accuracy:0.16058394160583941\n",
      "Epoch:315, Accuracy:0.16058394160583941\n",
      "Epoch:316, Accuracy:0.16058394160583941\n",
      "Epoch:317, Accuracy:0.16058394160583941\n",
      "Epoch:318, Accuracy:0.16058394160583941\n",
      "Epoch:319, Accuracy:0.16058394160583941\n",
      "Epoch:320, Accuracy:0.16058394160583941\n",
      "Epoch:321, Accuracy:0.16058394160583941\n",
      "Epoch:322, Accuracy:0.16058394160583941\n",
      "Epoch:323, Accuracy:0.16058394160583941\n",
      "Epoch:324, Accuracy:0.16058394160583941\n",
      "Epoch:325, Accuracy:0.16058394160583941\n",
      "Epoch:326, Accuracy:0.16058394160583941\n",
      "Epoch:327, Accuracy:0.16058394160583941\n",
      "Epoch:328, Accuracy:0.16058394160583941\n",
      "Epoch:329, Accuracy:0.16058394160583941\n",
      "Epoch:330, Accuracy:0.16058394160583941\n",
      "Epoch:331, Accuracy:0.16058394160583941\n",
      "Epoch:332, Accuracy:0.16058394160583941\n",
      "Epoch:333, Accuracy:0.16058394160583941\n",
      "Epoch:334, Accuracy:0.16058394160583941\n",
      "Epoch:335, Accuracy:0.16058394160583941\n",
      "Epoch:336, Accuracy:0.16058394160583941\n",
      "Epoch:337, Accuracy:0.16058394160583941\n",
      "Epoch:338, Accuracy:0.16058394160583941\n",
      "Epoch:339, Accuracy:0.16058394160583941\n",
      "Epoch:340, Accuracy:0.16058394160583941\n",
      "Epoch:341, Accuracy:0.16058394160583941\n",
      "Epoch:342, Accuracy:0.16058394160583941\n",
      "Epoch:343, Accuracy:0.16058394160583941\n",
      "Epoch:344, Accuracy:0.16058394160583941\n",
      "Epoch:345, Accuracy:0.16058394160583941\n",
      "Epoch:346, Accuracy:0.16058394160583941\n",
      "Epoch:347, Accuracy:0.16058394160583941\n",
      "Epoch:348, Accuracy:0.16058394160583941\n",
      "Epoch:349, Accuracy:0.16058394160583941\n",
      "Epoch:350, Accuracy:0.16058394160583941\n",
      "Epoch:351, Accuracy:0.16058394160583941\n",
      "Epoch:352, Accuracy:0.16058394160583941\n",
      "Epoch:353, Accuracy:0.16058394160583941\n",
      "Epoch:354, Accuracy:0.16058394160583941\n",
      "Epoch:355, Accuracy:0.16058394160583941\n",
      "Epoch:356, Accuracy:0.16058394160583941\n",
      "Epoch:357, Accuracy:0.16058394160583941\n",
      "Epoch:358, Accuracy:0.16058394160583941\n",
      "Epoch:359, Accuracy:0.16058394160583941\n",
      "Epoch:360, Accuracy:0.16058394160583941\n",
      "Epoch:361, Accuracy:0.16058394160583941\n",
      "Epoch:362, Accuracy:0.16058394160583941\n",
      "Epoch:363, Accuracy:0.16058394160583941\n",
      "Epoch:364, Accuracy:0.16058394160583941\n",
      "Epoch:365, Accuracy:0.16058394160583941\n",
      "Epoch:366, Accuracy:0.16058394160583941\n",
      "Epoch:367, Accuracy:0.16058394160583941\n",
      "Epoch:368, Accuracy:0.16058394160583941\n",
      "Epoch:369, Accuracy:0.16058394160583941\n",
      "Epoch:370, Accuracy:0.16058394160583941\n",
      "Epoch:371, Accuracy:0.16058394160583941\n",
      "Epoch:372, Accuracy:0.16058394160583941\n",
      "Epoch:373, Accuracy:0.16058394160583941\n",
      "Epoch:374, Accuracy:0.16058394160583941\n",
      "Epoch:375, Accuracy:0.16058394160583941\n",
      "Epoch:376, Accuracy:0.16058394160583941\n",
      "Epoch:377, Accuracy:0.16058394160583941\n",
      "Epoch:378, Accuracy:0.16058394160583941\n",
      "Epoch:379, Accuracy:0.16058394160583941\n",
      "Epoch:380, Accuracy:0.16058394160583941\n",
      "Epoch:381, Accuracy:0.16058394160583941\n",
      "Epoch:382, Accuracy:0.16058394160583941\n",
      "Epoch:383, Accuracy:0.16058394160583941\n",
      "Epoch:384, Accuracy:0.16058394160583941\n",
      "Epoch:385, Accuracy:0.16058394160583941\n",
      "Epoch:386, Accuracy:0.16058394160583941\n",
      "Epoch:387, Accuracy:0.16058394160583941\n",
      "Epoch:388, Accuracy:0.16058394160583941\n",
      "Epoch:389, Accuracy:0.16058394160583941\n",
      "Epoch:390, Accuracy:0.16058394160583941\n",
      "Epoch:391, Accuracy:0.16058394160583941\n",
      "Epoch:392, Accuracy:0.16058394160583941\n",
      "Epoch:393, Accuracy:0.16058394160583941\n",
      "Epoch:394, Accuracy:0.16058394160583941\n",
      "Epoch:395, Accuracy:0.16058394160583941\n",
      "Epoch:396, Accuracy:0.16058394160583941\n",
      "Epoch:397, Accuracy:0.16058394160583941\n",
      "Epoch:398, Accuracy:0.16058394160583941\n",
      "Epoch:399, Accuracy:0.16058394160583941\n",
      "Epoch:400, Accuracy:0.16058394160583941\n",
      "Epoch:401, Accuracy:0.16058394160583941\n",
      "Epoch:402, Accuracy:0.16058394160583941\n",
      "Epoch:403, Accuracy:0.16058394160583941\n",
      "Epoch:404, Accuracy:0.16058394160583941\n",
      "Epoch:405, Accuracy:0.16058394160583941\n",
      "Epoch:406, Accuracy:0.16058394160583941\n",
      "Epoch:407, Accuracy:0.16058394160583941\n",
      "Epoch:408, Accuracy:0.16058394160583941\n",
      "Epoch:409, Accuracy:0.16058394160583941\n",
      "Epoch:410, Accuracy:0.16058394160583941\n",
      "Epoch:411, Accuracy:0.16058394160583941\n",
      "Epoch:412, Accuracy:0.16058394160583941\n",
      "Epoch:413, Accuracy:0.16058394160583941\n",
      "Epoch:414, Accuracy:0.16058394160583941\n",
      "Epoch:415, Accuracy:0.16058394160583941\n",
      "Epoch:416, Accuracy:0.16058394160583941\n",
      "Epoch:417, Accuracy:0.16058394160583941\n",
      "Epoch:418, Accuracy:0.16058394160583941\n",
      "Epoch:419, Accuracy:0.16058394160583941\n",
      "Epoch:420, Accuracy:0.16058394160583941\n",
      "Epoch:421, Accuracy:0.16058394160583941\n",
      "Epoch:422, Accuracy:0.16058394160583941\n",
      "Epoch:423, Accuracy:0.16058394160583941\n",
      "Epoch:424, Accuracy:0.16058394160583941\n",
      "Epoch:425, Accuracy:0.16058394160583941\n",
      "Epoch:426, Accuracy:0.16058394160583941\n",
      "Epoch:427, Accuracy:0.16058394160583941\n",
      "Epoch:428, Accuracy:0.16058394160583941\n",
      "Epoch:429, Accuracy:0.16058394160583941\n",
      "Epoch:430, Accuracy:0.16058394160583941\n",
      "Epoch:431, Accuracy:0.16058394160583941\n",
      "Epoch:432, Accuracy:0.16058394160583941\n",
      "Epoch:433, Accuracy:0.16058394160583941\n",
      "Epoch:434, Accuracy:0.16058394160583941\n",
      "Epoch:435, Accuracy:0.16058394160583941\n",
      "Epoch:436, Accuracy:0.16058394160583941\n",
      "Epoch:437, Accuracy:0.16058394160583941\n",
      "Epoch:438, Accuracy:0.16058394160583941\n",
      "Epoch:439, Accuracy:0.16058394160583941\n",
      "Epoch:440, Accuracy:0.16058394160583941\n",
      "Epoch:441, Accuracy:0.16058394160583941\n",
      "Epoch:442, Accuracy:0.16058394160583941\n",
      "Epoch:443, Accuracy:0.16058394160583941\n",
      "Epoch:444, Accuracy:0.16058394160583941\n",
      "Epoch:445, Accuracy:0.16058394160583941\n",
      "Epoch:446, Accuracy:0.16058394160583941\n",
      "Epoch:447, Accuracy:0.16058394160583941\n",
      "Epoch:448, Accuracy:0.16058394160583941\n",
      "Epoch:449, Accuracy:0.16058394160583941\n",
      "Epoch:450, Accuracy:0.16058394160583941\n",
      "Epoch:451, Accuracy:0.16058394160583941\n",
      "Epoch:452, Accuracy:0.16058394160583941\n",
      "Epoch:453, Accuracy:0.16058394160583941\n",
      "Epoch:454, Accuracy:0.16058394160583941\n",
      "Epoch:455, Accuracy:0.16058394160583941\n",
      "Epoch:456, Accuracy:0.16058394160583941\n",
      "Epoch:457, Accuracy:0.16058394160583941\n",
      "Epoch:458, Accuracy:0.16058394160583941\n",
      "Epoch:459, Accuracy:0.16058394160583941\n",
      "Epoch:460, Accuracy:0.16058394160583941\n",
      "Epoch:461, Accuracy:0.16058394160583941\n",
      "Epoch:462, Accuracy:0.16058394160583941\n",
      "Epoch:463, Accuracy:0.16058394160583941\n",
      "Epoch:464, Accuracy:0.16058394160583941\n",
      "Epoch:465, Accuracy:0.16058394160583941\n",
      "Epoch:466, Accuracy:0.16058394160583941\n",
      "Epoch:467, Accuracy:0.16058394160583941\n",
      "Epoch:468, Accuracy:0.16058394160583941\n",
      "Epoch:469, Accuracy:0.16058394160583941\n",
      "Epoch:470, Accuracy:0.16058394160583941\n",
      "Epoch:471, Accuracy:0.16058394160583941\n",
      "Epoch:472, Accuracy:0.16058394160583941\n",
      "Epoch:473, Accuracy:0.16058394160583941\n",
      "Epoch:474, Accuracy:0.16058394160583941\n",
      "Epoch:475, Accuracy:0.16058394160583941\n",
      "Epoch:476, Accuracy:0.16058394160583941\n",
      "Epoch:477, Accuracy:0.16058394160583941\n",
      "Epoch:478, Accuracy:0.16058394160583941\n",
      "Epoch:479, Accuracy:0.16058394160583941\n",
      "Epoch:480, Accuracy:0.16058394160583941\n",
      "Epoch:481, Accuracy:0.16058394160583941\n",
      "Epoch:482, Accuracy:0.16058394160583941\n",
      "Epoch:483, Accuracy:0.16058394160583941\n",
      "Epoch:484, Accuracy:0.16058394160583941\n",
      "Epoch:485, Accuracy:0.16058394160583941\n",
      "Epoch:486, Accuracy:0.16058394160583941\n",
      "Epoch:487, Accuracy:0.16058394160583941\n",
      "Epoch:488, Accuracy:0.16058394160583941\n",
      "Epoch:489, Accuracy:0.16058394160583941\n",
      "Epoch:490, Accuracy:0.16058394160583941\n",
      "Epoch:491, Accuracy:0.16058394160583941\n",
      "Epoch:492, Accuracy:0.16058394160583941\n",
      "Epoch:493, Accuracy:0.16058394160583941\n",
      "Epoch:494, Accuracy:0.16058394160583941\n",
      "Epoch:495, Accuracy:0.16058394160583941\n",
      "Epoch:496, Accuracy:0.16058394160583941\n",
      "Epoch:497, Accuracy:0.16058394160583941\n",
      "Epoch:498, Accuracy:0.16058394160583941\n",
      "Epoch:499, Accuracy:0.16058394160583941\n"
     ]
    }
   ],
   "source": [
    "use_cuda = True\n",
    "if torch.cuda.is_available():\n",
    "    model = CNNLargeNet2().cuda()\n",
    "Y = trainSmall(model, train_dataset, batch_size=128, learning_rate=0.01, num_epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-12T19:46:09.041882034Z",
     "start_time": "2023-11-12T19:40:11.939633793Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iRPxddC5TKOk",
    "outputId": "36b893f9-dfd9-412c-939e-1cb163f31fec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Start\n",
      "Epoch:0, Accuracy:0.16058394160583941\n",
      "Epoch:1, Accuracy:0.0948905109489051\n",
      "Epoch:2, Accuracy:0.16058394160583941\n",
      "Epoch:3, Accuracy:0.16423357664233576\n",
      "Epoch:4, Accuracy:0.15328467153284672\n",
      "Epoch:5, Accuracy:0.18613138686131386\n",
      "Epoch:6, Accuracy:0.1897810218978102\n",
      "Epoch:7, Accuracy:0.18248175182481752\n",
      "Epoch:8, Accuracy:0.17883211678832117\n",
      "Epoch:9, Accuracy:0.17883211678832117\n",
      "Epoch:10, Accuracy:0.18613138686131386\n",
      "Epoch:11, Accuracy:0.18613138686131386\n",
      "Epoch:12, Accuracy:0.18613138686131386\n",
      "Epoch:13, Accuracy:0.20072992700729927\n",
      "Epoch:14, Accuracy:0.20072992700729927\n",
      "Epoch:15, Accuracy:0.19343065693430658\n",
      "Epoch:16, Accuracy:0.20437956204379562\n",
      "Epoch:17, Accuracy:0.21532846715328466\n",
      "Epoch:18, Accuracy:0.2116788321167883\n",
      "Epoch:19, Accuracy:0.20802919708029197\n",
      "Epoch:20, Accuracy:0.21897810218978103\n",
      "Epoch:21, Accuracy:0.20072992700729927\n",
      "Epoch:22, Accuracy:0.22627737226277372\n",
      "Epoch:23, Accuracy:0.30656934306569344\n",
      "Epoch:24, Accuracy:0.2664233576642336\n",
      "Epoch:25, Accuracy:0.33941605839416056\n",
      "Epoch:26, Accuracy:0.3759124087591241\n",
      "Epoch:27, Accuracy:0.3795620437956204\n",
      "Epoch:28, Accuracy:0.41605839416058393\n",
      "Epoch:29, Accuracy:0.42700729927007297\n",
      "Epoch:30, Accuracy:0.45985401459854014\n",
      "Epoch:31, Accuracy:0.42700729927007297\n",
      "Epoch:32, Accuracy:0.20437956204379562\n",
      "Epoch:33, Accuracy:0.21532846715328466\n",
      "Epoch:34, Accuracy:0.24817518248175183\n",
      "Epoch:35, Accuracy:0.25547445255474455\n",
      "Epoch:36, Accuracy:0.25547445255474455\n",
      "Epoch:37, Accuracy:0.26277372262773724\n",
      "Epoch:38, Accuracy:0.2664233576642336\n",
      "Epoch:39, Accuracy:0.2664233576642336\n",
      "Epoch:40, Accuracy:0.24452554744525548\n",
      "Epoch:41, Accuracy:0.22262773722627738\n",
      "Epoch:42, Accuracy:0.23722627737226276\n",
      "Epoch:43, Accuracy:0.17153284671532848\n",
      "Epoch:44, Accuracy:0.1897810218978102\n",
      "Epoch:45, Accuracy:0.21532846715328466\n",
      "Epoch:46, Accuracy:0.20072992700729927\n",
      "Epoch:47, Accuracy:0.21897810218978103\n",
      "Epoch:48, Accuracy:0.20072992700729927\n",
      "Epoch:49, Accuracy:0.20437956204379562\n",
      "Epoch:50, Accuracy:0.2116788321167883\n",
      "Epoch:51, Accuracy:0.24087591240875914\n",
      "Epoch:52, Accuracy:0.21897810218978103\n",
      "Epoch:53, Accuracy:0.21532846715328466\n",
      "Epoch:54, Accuracy:0.20802919708029197\n",
      "Epoch:55, Accuracy:0.21897810218978103\n",
      "Epoch:56, Accuracy:0.22262773722627738\n",
      "Epoch:57, Accuracy:0.20072992700729927\n",
      "Epoch:58, Accuracy:0.19708029197080293\n",
      "Epoch:59, Accuracy:0.21897810218978103\n",
      "Epoch:60, Accuracy:0.21897810218978103\n",
      "Epoch:61, Accuracy:0.20072992700729927\n",
      "Epoch:62, Accuracy:0.24817518248175183\n",
      "Epoch:63, Accuracy:0.23722627737226276\n",
      "Epoch:64, Accuracy:0.22627737226277372\n",
      "Epoch:65, Accuracy:0.21532846715328466\n",
      "Epoch:66, Accuracy:0.20437956204379562\n",
      "Epoch:67, Accuracy:0.21532846715328466\n",
      "Epoch:68, Accuracy:0.23722627737226276\n",
      "Epoch:69, Accuracy:0.24817518248175183\n",
      "Epoch:70, Accuracy:0.21897810218978103\n",
      "Epoch:71, Accuracy:0.24087591240875914\n",
      "Epoch:72, Accuracy:0.2591240875912409\n",
      "Epoch:73, Accuracy:0.22262773722627738\n",
      "Epoch:74, Accuracy:0.20072992700729927\n",
      "Epoch:75, Accuracy:0.22627737226277372\n",
      "Epoch:76, Accuracy:0.2116788321167883\n",
      "Epoch:77, Accuracy:0.19708029197080293\n",
      "Epoch:78, Accuracy:0.2116788321167883\n",
      "Epoch:79, Accuracy:0.20072992700729927\n",
      "Epoch:80, Accuracy:0.21532846715328466\n",
      "Epoch:81, Accuracy:0.19708029197080293\n",
      "Epoch:82, Accuracy:0.2116788321167883\n",
      "Epoch:83, Accuracy:0.24087591240875914\n",
      "Epoch:84, Accuracy:0.24087591240875914\n",
      "Epoch:85, Accuracy:0.22992700729927007\n",
      "Epoch:86, Accuracy:0.21532846715328466\n",
      "Epoch:87, Accuracy:0.19343065693430658\n",
      "Epoch:88, Accuracy:0.21897810218978103\n",
      "Epoch:89, Accuracy:0.20437956204379562\n",
      "Epoch:90, Accuracy:0.20802919708029197\n",
      "Epoch:91, Accuracy:0.22992700729927007\n",
      "Epoch:92, Accuracy:0.22992700729927007\n",
      "Epoch:93, Accuracy:0.21897810218978103\n",
      "Epoch:94, Accuracy:0.20802919708029197\n",
      "Epoch:95, Accuracy:0.21532846715328466\n",
      "Epoch:96, Accuracy:0.21897810218978103\n",
      "Epoch:97, Accuracy:0.20072992700729927\n",
      "Epoch:98, Accuracy:0.22262773722627738\n",
      "Epoch:99, Accuracy:0.22627737226277372\n",
      "Epoch:100, Accuracy:0.22992700729927007\n",
      "Epoch:101, Accuracy:0.22262773722627738\n",
      "Epoch:102, Accuracy:0.20802919708029197\n",
      "Epoch:103, Accuracy:0.21532846715328466\n",
      "Epoch:104, Accuracy:0.22627737226277372\n",
      "Epoch:105, Accuracy:0.23357664233576642\n",
      "Epoch:106, Accuracy:0.24087591240875914\n",
      "Epoch:107, Accuracy:0.21532846715328466\n",
      "Epoch:108, Accuracy:0.22262773722627738\n",
      "Epoch:109, Accuracy:0.2116788321167883\n",
      "Epoch:110, Accuracy:0.20437956204379562\n",
      "Epoch:111, Accuracy:0.20072992700729927\n",
      "Epoch:112, Accuracy:0.2116788321167883\n",
      "Epoch:113, Accuracy:0.20802919708029197\n",
      "Epoch:114, Accuracy:0.22262773722627738\n",
      "Epoch:115, Accuracy:0.21897810218978103\n",
      "Epoch:116, Accuracy:0.2116788321167883\n",
      "Epoch:117, Accuracy:0.2116788321167883\n",
      "Epoch:118, Accuracy:0.21532846715328466\n",
      "Epoch:119, Accuracy:0.21897810218978103\n",
      "Epoch:120, Accuracy:0.21897810218978103\n",
      "Epoch:121, Accuracy:0.21897810218978103\n",
      "Epoch:122, Accuracy:0.22992700729927007\n",
      "Epoch:123, Accuracy:0.20802919708029197\n",
      "Epoch:124, Accuracy:0.21532846715328466\n",
      "Epoch:125, Accuracy:0.24087591240875914\n",
      "Epoch:126, Accuracy:0.24817518248175183\n",
      "Epoch:127, Accuracy:0.23722627737226276\n",
      "Epoch:128, Accuracy:0.22262773722627738\n",
      "Epoch:129, Accuracy:0.2116788321167883\n",
      "Epoch:130, Accuracy:0.22262773722627738\n",
      "Epoch:131, Accuracy:0.21897810218978103\n",
      "Epoch:132, Accuracy:0.23722627737226276\n",
      "Epoch:133, Accuracy:0.22992700729927007\n",
      "Epoch:134, Accuracy:0.23357664233576642\n",
      "Epoch:135, Accuracy:0.22992700729927007\n",
      "Epoch:136, Accuracy:0.23357664233576642\n",
      "Epoch:137, Accuracy:0.23722627737226276\n",
      "Epoch:138, Accuracy:0.23357664233576642\n",
      "Epoch:139, Accuracy:0.21897810218978103\n",
      "Epoch:140, Accuracy:0.23357664233576642\n",
      "Epoch:141, Accuracy:0.23722627737226276\n",
      "Epoch:142, Accuracy:0.24452554744525548\n",
      "Epoch:143, Accuracy:0.24087591240875914\n",
      "Epoch:144, Accuracy:0.2591240875912409\n",
      "Epoch:145, Accuracy:0.26277372262773724\n",
      "Epoch:146, Accuracy:0.24817518248175183\n",
      "Epoch:147, Accuracy:0.2591240875912409\n",
      "Epoch:148, Accuracy:0.24817518248175183\n",
      "Epoch:149, Accuracy:0.25547445255474455\n",
      "Epoch:150, Accuracy:0.2518248175182482\n",
      "Epoch:151, Accuracy:0.24452554744525548\n",
      "Epoch:152, Accuracy:0.26277372262773724\n",
      "Epoch:153, Accuracy:0.2773722627737226\n",
      "Epoch:154, Accuracy:0.24817518248175183\n",
      "Epoch:155, Accuracy:0.2591240875912409\n",
      "Epoch:156, Accuracy:0.27007299270072993\n",
      "Epoch:157, Accuracy:0.2773722627737226\n",
      "Epoch:158, Accuracy:0.29927007299270075\n",
      "Epoch:159, Accuracy:0.28102189781021897\n",
      "Epoch:160, Accuracy:0.28102189781021897\n",
      "Epoch:161, Accuracy:0.2737226277372263\n",
      "Epoch:162, Accuracy:0.27007299270072993\n",
      "Epoch:163, Accuracy:0.28102189781021897\n",
      "Epoch:164, Accuracy:0.2737226277372263\n",
      "Epoch:165, Accuracy:0.2773722627737226\n",
      "Epoch:166, Accuracy:0.26277372262773724\n",
      "Epoch:167, Accuracy:0.2664233576642336\n",
      "Epoch:168, Accuracy:0.2846715328467153\n",
      "Epoch:169, Accuracy:0.2846715328467153\n",
      "Epoch:170, Accuracy:0.28832116788321166\n",
      "Epoch:171, Accuracy:0.28102189781021897\n",
      "Epoch:172, Accuracy:0.28102189781021897\n",
      "Epoch:173, Accuracy:0.2956204379562044\n",
      "Epoch:174, Accuracy:0.2846715328467153\n",
      "Epoch:175, Accuracy:0.28102189781021897\n",
      "Epoch:176, Accuracy:0.3029197080291971\n",
      "Epoch:177, Accuracy:0.2956204379562044\n",
      "Epoch:178, Accuracy:0.28832116788321166\n",
      "Epoch:179, Accuracy:0.28832116788321166\n",
      "Epoch:180, Accuracy:0.3175182481751825\n",
      "Epoch:181, Accuracy:0.28832116788321166\n",
      "Epoch:182, Accuracy:0.3029197080291971\n",
      "Epoch:183, Accuracy:0.29927007299270075\n",
      "Epoch:184, Accuracy:0.2956204379562044\n",
      "Epoch:185, Accuracy:0.2956204379562044\n",
      "Epoch:186, Accuracy:0.29927007299270075\n",
      "Epoch:187, Accuracy:0.29927007299270075\n",
      "Epoch:188, Accuracy:0.3175182481751825\n",
      "Epoch:189, Accuracy:0.3102189781021898\n",
      "Epoch:190, Accuracy:0.3102189781021898\n",
      "Epoch:191, Accuracy:0.3248175182481752\n",
      "Epoch:192, Accuracy:0.31386861313868614\n",
      "Epoch:193, Accuracy:0.3175182481751825\n",
      "Epoch:194, Accuracy:0.3248175182481752\n",
      "Epoch:195, Accuracy:0.3248175182481752\n",
      "Epoch:196, Accuracy:0.291970802919708\n",
      "Epoch:197, Accuracy:0.3284671532846715\n",
      "Epoch:198, Accuracy:0.3284671532846715\n",
      "Epoch:199, Accuracy:0.31386861313868614\n",
      "Epoch:200, Accuracy:0.3175182481751825\n",
      "Epoch:201, Accuracy:0.3284671532846715\n",
      "Epoch:202, Accuracy:0.3248175182481752\n",
      "Epoch:203, Accuracy:0.33211678832116787\n",
      "Epoch:204, Accuracy:0.31386861313868614\n",
      "Epoch:205, Accuracy:0.3284671532846715\n",
      "Epoch:206, Accuracy:0.3284671532846715\n",
      "Epoch:207, Accuracy:0.3284671532846715\n",
      "Epoch:208, Accuracy:0.3284671532846715\n",
      "Epoch:209, Accuracy:0.33211678832116787\n",
      "Epoch:210, Accuracy:0.3357664233576642\n",
      "Epoch:211, Accuracy:0.33211678832116787\n",
      "Epoch:212, Accuracy:0.3284671532846715\n",
      "Epoch:213, Accuracy:0.3248175182481752\n",
      "Epoch:214, Accuracy:0.29927007299270075\n",
      "Epoch:215, Accuracy:0.2956204379562044\n",
      "Epoch:216, Accuracy:0.2956204379562044\n",
      "Epoch:217, Accuracy:0.30656934306569344\n",
      "Epoch:218, Accuracy:0.3175182481751825\n",
      "Epoch:219, Accuracy:0.3284671532846715\n",
      "Epoch:220, Accuracy:0.31386861313868614\n",
      "Epoch:221, Accuracy:0.31386861313868614\n",
      "Epoch:222, Accuracy:0.3722627737226277\n",
      "Epoch:223, Accuracy:0.3722627737226277\n",
      "Epoch:224, Accuracy:0.35766423357664234\n",
      "Epoch:225, Accuracy:0.3795620437956204\n",
      "Epoch:226, Accuracy:0.31386861313868614\n",
      "Epoch:227, Accuracy:0.33211678832116787\n",
      "Epoch:228, Accuracy:0.3248175182481752\n",
      "Epoch:229, Accuracy:0.3248175182481752\n",
      "Epoch:230, Accuracy:0.33211678832116787\n",
      "Epoch:231, Accuracy:0.33211678832116787\n",
      "Epoch:232, Accuracy:0.3357664233576642\n",
      "Epoch:233, Accuracy:0.35036496350364965\n",
      "Epoch:234, Accuracy:0.34306569343065696\n",
      "Epoch:235, Accuracy:0.35036496350364965\n",
      "Epoch:236, Accuracy:0.3467153284671533\n",
      "Epoch:237, Accuracy:0.2846715328467153\n",
      "Epoch:238, Accuracy:0.2773722627737226\n",
      "Epoch:239, Accuracy:0.29927007299270075\n",
      "Epoch:240, Accuracy:0.2956204379562044\n",
      "Epoch:241, Accuracy:0.3102189781021898\n",
      "Epoch:242, Accuracy:0.33211678832116787\n",
      "Epoch:243, Accuracy:0.33211678832116787\n",
      "Epoch:244, Accuracy:0.33211678832116787\n",
      "Epoch:245, Accuracy:0.3467153284671533\n",
      "Epoch:246, Accuracy:0.3467153284671533\n",
      "Epoch:247, Accuracy:0.3613138686131387\n",
      "Epoch:248, Accuracy:0.36496350364963503\n",
      "Epoch:249, Accuracy:0.35036496350364965\n",
      "Epoch:250, Accuracy:0.3795620437956204\n",
      "Epoch:251, Accuracy:0.3795620437956204\n",
      "Epoch:252, Accuracy:0.3686131386861314\n",
      "Epoch:253, Accuracy:0.38686131386861317\n",
      "Epoch:254, Accuracy:0.3722627737226277\n",
      "Epoch:255, Accuracy:0.3467153284671533\n",
      "Epoch:256, Accuracy:0.34306569343065696\n",
      "Epoch:257, Accuracy:0.36496350364963503\n",
      "Epoch:258, Accuracy:0.3795620437956204\n",
      "Epoch:259, Accuracy:0.3905109489051095\n",
      "Epoch:260, Accuracy:0.3686131386861314\n",
      "Epoch:261, Accuracy:0.40145985401459855\n",
      "Epoch:262, Accuracy:0.35766423357664234\n",
      "Epoch:263, Accuracy:0.3978102189781022\n",
      "Epoch:264, Accuracy:0.3613138686131387\n",
      "Epoch:265, Accuracy:0.3686131386861314\n",
      "Epoch:266, Accuracy:0.3795620437956204\n",
      "Epoch:267, Accuracy:0.38686131386861317\n",
      "Epoch:268, Accuracy:0.3722627737226277\n",
      "Epoch:269, Accuracy:0.3686131386861314\n",
      "Epoch:270, Accuracy:0.3978102189781022\n",
      "Epoch:271, Accuracy:0.3978102189781022\n",
      "Epoch:272, Accuracy:0.4051094890510949\n",
      "Epoch:273, Accuracy:0.3795620437956204\n",
      "Epoch:274, Accuracy:0.3795620437956204\n",
      "Epoch:275, Accuracy:0.38686131386861317\n",
      "Epoch:276, Accuracy:0.38686131386861317\n",
      "Epoch:277, Accuracy:0.3795620437956204\n",
      "Epoch:278, Accuracy:0.3795620437956204\n",
      "Epoch:279, Accuracy:0.3905109489051095\n",
      "Epoch:280, Accuracy:0.3722627737226277\n",
      "Epoch:281, Accuracy:0.38321167883211676\n",
      "Epoch:282, Accuracy:0.38321167883211676\n",
      "Epoch:283, Accuracy:0.38686131386861317\n",
      "Epoch:284, Accuracy:0.3759124087591241\n",
      "Epoch:285, Accuracy:0.3722627737226277\n",
      "Epoch:286, Accuracy:0.3978102189781022\n",
      "Epoch:287, Accuracy:0.38321167883211676\n",
      "Epoch:288, Accuracy:0.3284671532846715\n",
      "Epoch:289, Accuracy:0.34306569343065696\n",
      "Epoch:290, Accuracy:0.3357664233576642\n",
      "Epoch:291, Accuracy:0.34306569343065696\n",
      "Epoch:292, Accuracy:0.35766423357664234\n",
      "Epoch:293, Accuracy:0.3613138686131387\n",
      "Epoch:294, Accuracy:0.3175182481751825\n",
      "Epoch:295, Accuracy:0.3284671532846715\n",
      "Epoch:296, Accuracy:0.2846715328467153\n",
      "Epoch:297, Accuracy:0.2846715328467153\n",
      "Epoch:298, Accuracy:0.32116788321167883\n",
      "Epoch:299, Accuracy:0.291970802919708\n",
      "Epoch:300, Accuracy:0.30656934306569344\n",
      "Epoch:301, Accuracy:0.29927007299270075\n",
      "Epoch:302, Accuracy:0.31386861313868614\n",
      "Epoch:303, Accuracy:0.3175182481751825\n",
      "Epoch:304, Accuracy:0.3175182481751825\n",
      "Epoch:305, Accuracy:0.34306569343065696\n",
      "Epoch:306, Accuracy:0.3357664233576642\n",
      "Epoch:307, Accuracy:0.17518248175182483\n",
      "Epoch:308, Accuracy:0.3175182481751825\n",
      "Epoch:309, Accuracy:0.31386861313868614\n",
      "Epoch:310, Accuracy:0.3248175182481752\n",
      "Epoch:311, Accuracy:0.29927007299270075\n",
      "Epoch:312, Accuracy:0.3102189781021898\n",
      "Epoch:313, Accuracy:0.31386861313868614\n",
      "Epoch:314, Accuracy:0.33941605839416056\n",
      "Epoch:315, Accuracy:0.33211678832116787\n",
      "Epoch:316, Accuracy:0.354014598540146\n",
      "Epoch:317, Accuracy:0.33211678832116787\n",
      "Epoch:318, Accuracy:0.3357664233576642\n",
      "Epoch:319, Accuracy:0.34306569343065696\n",
      "Epoch:320, Accuracy:0.3284671532846715\n",
      "Epoch:321, Accuracy:0.3284671532846715\n",
      "Epoch:322, Accuracy:0.33941605839416056\n",
      "Epoch:323, Accuracy:0.33211678832116787\n",
      "Epoch:324, Accuracy:0.3759124087591241\n",
      "Epoch:325, Accuracy:0.3795620437956204\n",
      "Epoch:326, Accuracy:0.38686131386861317\n",
      "Epoch:327, Accuracy:0.3905109489051095\n",
      "Epoch:328, Accuracy:0.35036496350364965\n",
      "Epoch:329, Accuracy:0.36496350364963503\n",
      "Epoch:330, Accuracy:0.354014598540146\n",
      "Epoch:331, Accuracy:0.3613138686131387\n",
      "Epoch:332, Accuracy:0.3613138686131387\n",
      "Epoch:333, Accuracy:0.38321167883211676\n",
      "Epoch:334, Accuracy:0.35036496350364965\n",
      "Epoch:335, Accuracy:0.3795620437956204\n",
      "Epoch:336, Accuracy:0.38321167883211676\n",
      "Epoch:337, Accuracy:0.39416058394160586\n",
      "Epoch:338, Accuracy:0.3795620437956204\n",
      "Epoch:339, Accuracy:0.4124087591240876\n",
      "Epoch:340, Accuracy:0.40145985401459855\n",
      "Epoch:341, Accuracy:0.40145985401459855\n",
      "Epoch:342, Accuracy:0.3795620437956204\n",
      "Epoch:343, Accuracy:0.3978102189781022\n",
      "Epoch:344, Accuracy:0.39416058394160586\n",
      "Epoch:345, Accuracy:0.35766423357664234\n",
      "Epoch:346, Accuracy:0.33941605839416056\n",
      "Epoch:347, Accuracy:0.3759124087591241\n",
      "Epoch:348, Accuracy:0.38321167883211676\n",
      "Epoch:349, Accuracy:0.38321167883211676\n",
      "Epoch:350, Accuracy:0.38686131386861317\n",
      "Epoch:351, Accuracy:0.40875912408759124\n",
      "Epoch:352, Accuracy:0.3978102189781022\n",
      "Epoch:353, Accuracy:0.3978102189781022\n",
      "Epoch:354, Accuracy:0.3905109489051095\n",
      "Epoch:355, Accuracy:0.39416058394160586\n",
      "Epoch:356, Accuracy:0.39416058394160586\n",
      "Epoch:357, Accuracy:0.3795620437956204\n",
      "Epoch:358, Accuracy:0.4051094890510949\n",
      "Epoch:359, Accuracy:0.41605839416058393\n",
      "Epoch:360, Accuracy:0.40875912408759124\n",
      "Epoch:361, Accuracy:0.41605839416058393\n",
      "Epoch:362, Accuracy:0.4124087591240876\n",
      "Epoch:363, Accuracy:0.40875912408759124\n",
      "Epoch:364, Accuracy:0.41605839416058393\n",
      "Epoch:365, Accuracy:0.4197080291970803\n",
      "Epoch:366, Accuracy:0.40875912408759124\n",
      "Epoch:367, Accuracy:0.41605839416058393\n",
      "Epoch:368, Accuracy:0.4306569343065693\n",
      "Epoch:369, Accuracy:0.4343065693430657\n",
      "Epoch:370, Accuracy:0.41605839416058393\n",
      "Epoch:371, Accuracy:0.43795620437956206\n",
      "Epoch:372, Accuracy:0.41605839416058393\n",
      "Epoch:373, Accuracy:0.4306569343065693\n",
      "Epoch:374, Accuracy:0.43795620437956206\n",
      "Epoch:375, Accuracy:0.4306569343065693\n",
      "Epoch:376, Accuracy:0.40145985401459855\n",
      "Epoch:377, Accuracy:0.41605839416058393\n",
      "Epoch:378, Accuracy:0.43795620437956206\n",
      "Epoch:379, Accuracy:0.4343065693430657\n",
      "Epoch:380, Accuracy:0.4233576642335766\n",
      "Epoch:381, Accuracy:0.4306569343065693\n",
      "Epoch:382, Accuracy:0.42700729927007297\n",
      "Epoch:383, Accuracy:0.42700729927007297\n",
      "Epoch:384, Accuracy:0.3795620437956204\n",
      "Epoch:385, Accuracy:0.4343065693430657\n",
      "Epoch:386, Accuracy:0.4124087591240876\n",
      "Epoch:387, Accuracy:0.4233576642335766\n",
      "Epoch:388, Accuracy:0.4343065693430657\n",
      "Epoch:389, Accuracy:0.4051094890510949\n",
      "Epoch:390, Accuracy:0.3759124087591241\n",
      "Epoch:391, Accuracy:0.3759124087591241\n",
      "Epoch:392, Accuracy:0.3759124087591241\n",
      "Epoch:393, Accuracy:0.38321167883211676\n",
      "Epoch:394, Accuracy:0.40875912408759124\n",
      "Epoch:395, Accuracy:0.3613138686131387\n",
      "Epoch:396, Accuracy:0.38686131386861317\n",
      "Epoch:397, Accuracy:0.3978102189781022\n",
      "Epoch:398, Accuracy:0.3759124087591241\n",
      "Epoch:399, Accuracy:0.39416058394160586\n",
      "Epoch:400, Accuracy:0.38686131386861317\n",
      "Epoch:401, Accuracy:0.3905109489051095\n",
      "Epoch:402, Accuracy:0.40145985401459855\n",
      "Epoch:403, Accuracy:0.41605839416058393\n",
      "Epoch:404, Accuracy:0.4197080291970803\n",
      "Epoch:405, Accuracy:0.4233576642335766\n",
      "Epoch:406, Accuracy:0.42700729927007297\n",
      "Epoch:407, Accuracy:0.42700729927007297\n",
      "Epoch:408, Accuracy:0.4197080291970803\n",
      "Epoch:409, Accuracy:0.4233576642335766\n",
      "Epoch:410, Accuracy:0.4051094890510949\n",
      "Epoch:411, Accuracy:0.4343065693430657\n",
      "Epoch:412, Accuracy:0.4489051094890511\n",
      "Epoch:413, Accuracy:0.42700729927007297\n",
      "Epoch:414, Accuracy:0.44525547445255476\n",
      "Epoch:415, Accuracy:0.4562043795620438\n",
      "Epoch:416, Accuracy:0.46715328467153283\n",
      "Epoch:417, Accuracy:0.4744525547445255\n",
      "Epoch:418, Accuracy:0.46715328467153283\n",
      "Epoch:419, Accuracy:0.4854014598540146\n",
      "Epoch:420, Accuracy:0.48175182481751827\n",
      "Epoch:421, Accuracy:0.4927007299270073\n",
      "Epoch:422, Accuracy:0.48175182481751827\n",
      "Epoch:423, Accuracy:0.4927007299270073\n",
      "Epoch:424, Accuracy:0.4744525547445255\n",
      "Epoch:425, Accuracy:0.4708029197080292\n",
      "Epoch:426, Accuracy:0.4708029197080292\n",
      "Epoch:427, Accuracy:0.4562043795620438\n",
      "Epoch:428, Accuracy:0.48905109489051096\n",
      "Epoch:429, Accuracy:0.4708029197080292\n",
      "Epoch:430, Accuracy:0.48175182481751827\n",
      "Epoch:431, Accuracy:0.43795620437956206\n",
      "Epoch:432, Accuracy:0.4489051094890511\n",
      "Epoch:433, Accuracy:0.42700729927007297\n",
      "Epoch:434, Accuracy:0.38321167883211676\n",
      "Epoch:435, Accuracy:0.3905109489051095\n",
      "Epoch:436, Accuracy:0.4306569343065693\n",
      "Epoch:437, Accuracy:0.4416058394160584\n",
      "Epoch:438, Accuracy:0.4306569343065693\n",
      "Epoch:439, Accuracy:0.41605839416058393\n",
      "Epoch:440, Accuracy:0.3978102189781022\n",
      "Epoch:441, Accuracy:0.40875912408759124\n",
      "Epoch:442, Accuracy:0.43795620437956206\n",
      "Epoch:443, Accuracy:0.43795620437956206\n",
      "Epoch:444, Accuracy:0.44525547445255476\n",
      "Epoch:445, Accuracy:0.45255474452554745\n",
      "Epoch:446, Accuracy:0.45255474452554745\n",
      "Epoch:447, Accuracy:0.4489051094890511\n",
      "Epoch:448, Accuracy:0.46715328467153283\n",
      "Epoch:449, Accuracy:0.4744525547445255\n",
      "Epoch:450, Accuracy:0.4781021897810219\n",
      "Epoch:451, Accuracy:0.41605839416058393\n",
      "Epoch:452, Accuracy:0.41605839416058393\n",
      "Epoch:453, Accuracy:0.4197080291970803\n",
      "Epoch:454, Accuracy:0.4197080291970803\n",
      "Epoch:455, Accuracy:0.44525547445255476\n",
      "Epoch:456, Accuracy:0.4343065693430657\n",
      "Epoch:457, Accuracy:0.4306569343065693\n",
      "Epoch:458, Accuracy:0.43795620437956206\n",
      "Epoch:459, Accuracy:0.44525547445255476\n",
      "Epoch:460, Accuracy:0.44525547445255476\n",
      "Epoch:461, Accuracy:0.45985401459854014\n",
      "Epoch:462, Accuracy:0.46715328467153283\n",
      "Epoch:463, Accuracy:0.4854014598540146\n",
      "Epoch:464, Accuracy:0.48905109489051096\n",
      "Epoch:465, Accuracy:0.4744525547445255\n",
      "Epoch:466, Accuracy:0.45255474452554745\n",
      "Epoch:467, Accuracy:0.4562043795620438\n",
      "Epoch:468, Accuracy:0.44525547445255476\n",
      "Epoch:469, Accuracy:0.45255474452554745\n",
      "Epoch:470, Accuracy:0.44525547445255476\n",
      "Epoch:471, Accuracy:0.4635036496350365\n",
      "Epoch:472, Accuracy:0.4489051094890511\n",
      "Epoch:473, Accuracy:0.4306569343065693\n",
      "Epoch:474, Accuracy:0.4233576642335766\n",
      "Epoch:475, Accuracy:0.4306569343065693\n",
      "Epoch:476, Accuracy:0.4416058394160584\n",
      "Epoch:477, Accuracy:0.43795620437956206\n",
      "Epoch:478, Accuracy:0.45985401459854014\n",
      "Epoch:479, Accuracy:0.4708029197080292\n",
      "Epoch:480, Accuracy:0.49635036496350365\n",
      "Epoch:481, Accuracy:0.46715328467153283\n",
      "Epoch:482, Accuracy:0.5\n",
      "Epoch:483, Accuracy:0.5145985401459854\n",
      "Epoch:484, Accuracy:0.5109489051094891\n",
      "Epoch:485, Accuracy:0.5036496350364964\n",
      "Epoch:486, Accuracy:0.5\n",
      "Epoch:487, Accuracy:0.49635036496350365\n",
      "Epoch:488, Accuracy:0.4927007299270073\n",
      "Epoch:489, Accuracy:0.5\n",
      "Epoch:490, Accuracy:0.5036496350364964\n",
      "Epoch:491, Accuracy:0.5\n",
      "Epoch:492, Accuracy:0.5255474452554745\n",
      "Epoch:493, Accuracy:0.5218978102189781\n",
      "Epoch:494, Accuracy:0.5109489051094891\n",
      "Epoch:495, Accuracy:0.5109489051094891\n",
      "Epoch:496, Accuracy:0.5\n",
      "Epoch:497, Accuracy:0.5\n",
      "Epoch:498, Accuracy:0.49635036496350365\n",
      "Epoch:499, Accuracy:0.5\n"
     ]
    }
   ],
   "source": [
    "use_cuda = True\n",
    "if torch.cuda.is_available():\n",
    "    model = CNNLargeNet2().cuda()\n",
    "Y = trainSmall(model, train_dataset, batch_size=64, learning_rate=0.01, num_epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-12T19:49:06.164585684Z",
     "start_time": "2023-11-12T19:46:09.045451655Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TUfbTExPwd0U",
    "outputId": "162126e6-ea50-459e-c867-f6dfa2169b57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Start\n",
      "Epoch:0, Accuracy:0.16058394160583941\n",
      "Epoch:1, Accuracy:0.0948905109489051\n",
      "Epoch:2, Accuracy:0.16058394160583941\n",
      "Epoch:3, Accuracy:0.17518248175182483\n",
      "Epoch:4, Accuracy:0.18613138686131386\n",
      "Epoch:5, Accuracy:0.17518248175182483\n",
      "Epoch:6, Accuracy:0.18613138686131386\n",
      "Epoch:7, Accuracy:0.18613138686131386\n",
      "Epoch:8, Accuracy:0.1897810218978102\n",
      "Epoch:9, Accuracy:0.20437956204379562\n",
      "Epoch:10, Accuracy:0.20437956204379562\n",
      "Epoch:11, Accuracy:0.20802919708029197\n",
      "Epoch:12, Accuracy:0.20802919708029197\n",
      "Epoch:13, Accuracy:0.20437956204379562\n",
      "Epoch:14, Accuracy:0.21897810218978103\n",
      "Epoch:15, Accuracy:0.22992700729927007\n",
      "Epoch:16, Accuracy:0.23722627737226276\n",
      "Epoch:17, Accuracy:0.2518248175182482\n",
      "Epoch:18, Accuracy:0.24817518248175183\n",
      "Epoch:19, Accuracy:0.27007299270072993\n",
      "Epoch:20, Accuracy:0.2664233576642336\n",
      "Epoch:21, Accuracy:0.2591240875912409\n",
      "Epoch:22, Accuracy:0.24817518248175183\n",
      "Epoch:23, Accuracy:0.24452554744525548\n",
      "Epoch:24, Accuracy:0.2591240875912409\n",
      "Epoch:25, Accuracy:0.20437956204379562\n",
      "Epoch:26, Accuracy:0.33211678832116787\n",
      "Epoch:27, Accuracy:0.23722627737226276\n",
      "Epoch:28, Accuracy:0.2591240875912409\n",
      "Epoch:29, Accuracy:0.27007299270072993\n",
      "Epoch:30, Accuracy:0.27007299270072993\n",
      "Epoch:31, Accuracy:0.2846715328467153\n",
      "Epoch:32, Accuracy:0.2956204379562044\n",
      "Epoch:33, Accuracy:0.2956204379562044\n",
      "Epoch:34, Accuracy:0.3722627737226277\n",
      "Epoch:35, Accuracy:0.32116788321167883\n",
      "Epoch:36, Accuracy:0.3978102189781022\n",
      "Epoch:37, Accuracy:0.3686131386861314\n",
      "Epoch:38, Accuracy:0.3795620437956204\n",
      "Epoch:39, Accuracy:0.4124087591240876\n",
      "Epoch:40, Accuracy:0.42700729927007297\n",
      "Epoch:41, Accuracy:0.45255474452554745\n",
      "Epoch:42, Accuracy:0.5036496350364964\n",
      "Epoch:43, Accuracy:0.43795620437956206\n",
      "Epoch:44, Accuracy:0.5036496350364964\n",
      "Epoch:45, Accuracy:0.5291970802919708\n",
      "Epoch:46, Accuracy:0.41605839416058393\n",
      "Epoch:47, Accuracy:0.43795620437956206\n",
      "Epoch:48, Accuracy:0.4416058394160584\n",
      "Epoch:49, Accuracy:0.4635036496350365\n",
      "Epoch:50, Accuracy:0.4562043795620438\n",
      "Epoch:51, Accuracy:0.5182481751824818\n",
      "Epoch:52, Accuracy:0.4562043795620438\n",
      "Epoch:53, Accuracy:0.572992700729927\n",
      "Epoch:54, Accuracy:0.5985401459854015\n",
      "Epoch:55, Accuracy:0.5291970802919708\n",
      "Epoch:56, Accuracy:0.6277372262773723\n",
      "Epoch:57, Accuracy:0.6386861313868614\n",
      "Epoch:58, Accuracy:0.6605839416058394\n",
      "Epoch:59, Accuracy:0.6715328467153284\n",
      "Epoch:60, Accuracy:0.5766423357664233\n",
      "Epoch:61, Accuracy:0.6678832116788321\n",
      "Epoch:62, Accuracy:0.6167883211678832\n",
      "Epoch:63, Accuracy:0.45985401459854014\n",
      "Epoch:64, Accuracy:0.5\n",
      "Epoch:65, Accuracy:0.3686131386861314\n",
      "Epoch:66, Accuracy:0.30656934306569344\n",
      "Epoch:67, Accuracy:0.3905109489051095\n",
      "Epoch:68, Accuracy:0.39416058394160586\n",
      "Epoch:69, Accuracy:0.38321167883211676\n",
      "Epoch:70, Accuracy:0.4306569343065693\n",
      "Epoch:71, Accuracy:0.4781021897810219\n",
      "Epoch:72, Accuracy:0.49635036496350365\n",
      "Epoch:73, Accuracy:0.5036496350364964\n",
      "Epoch:74, Accuracy:0.551094890510949\n",
      "Epoch:75, Accuracy:0.5437956204379562\n",
      "Epoch:76, Accuracy:0.5656934306569343\n",
      "Epoch:77, Accuracy:0.5948905109489051\n",
      "Epoch:78, Accuracy:0.6532846715328468\n",
      "Epoch:79, Accuracy:0.6496350364963503\n",
      "Epoch:80, Accuracy:0.6788321167883211\n",
      "Epoch:81, Accuracy:0.7043795620437956\n",
      "Epoch:82, Accuracy:0.6605839416058394\n",
      "Epoch:83, Accuracy:0.48175182481751827\n",
      "Epoch:84, Accuracy:0.708029197080292\n",
      "Epoch:85, Accuracy:0.6167883211678832\n",
      "Epoch:86, Accuracy:0.6094890510948905\n",
      "Epoch:87, Accuracy:0.6131386861313869\n",
      "Epoch:88, Accuracy:0.4708029197080292\n",
      "Epoch:89, Accuracy:0.5401459854014599\n",
      "Epoch:90, Accuracy:0.6131386861313869\n",
      "Epoch:91, Accuracy:0.5255474452554745\n",
      "Epoch:92, Accuracy:0.6167883211678832\n",
      "Epoch:93, Accuracy:0.6423357664233577\n",
      "Epoch:94, Accuracy:0.6970802919708029\n",
      "Epoch:95, Accuracy:0.6058394160583942\n",
      "Epoch:96, Accuracy:0.7408759124087592\n",
      "Epoch:97, Accuracy:0.6094890510948905\n",
      "Epoch:98, Accuracy:0.5875912408759124\n",
      "Epoch:99, Accuracy:0.6423357664233577\n",
      "Epoch:100, Accuracy:0.6094890510948905\n",
      "Epoch:101, Accuracy:0.635036496350365\n",
      "Epoch:102, Accuracy:0.7627737226277372\n",
      "Epoch:103, Accuracy:0.7627737226277372\n",
      "Epoch:104, Accuracy:0.8065693430656934\n",
      "Epoch:105, Accuracy:0.8102189781021898\n",
      "Epoch:106, Accuracy:0.8357664233576643\n",
      "Epoch:107, Accuracy:0.8211678832116789\n",
      "Epoch:108, Accuracy:0.8686131386861314\n",
      "Epoch:109, Accuracy:0.8321167883211679\n",
      "Epoch:110, Accuracy:0.864963503649635\n",
      "Epoch:111, Accuracy:0.8613138686131386\n",
      "Epoch:112, Accuracy:0.8576642335766423\n",
      "Epoch:113, Accuracy:0.7299270072992701\n",
      "Epoch:114, Accuracy:0.7591240875912408\n",
      "Epoch:115, Accuracy:0.5291970802919708\n",
      "Epoch:116, Accuracy:0.8175182481751825\n",
      "Epoch:117, Accuracy:0.7481751824817519\n",
      "Epoch:118, Accuracy:0.8540145985401459\n",
      "Epoch:119, Accuracy:0.8065693430656934\n",
      "Epoch:120, Accuracy:0.8321167883211679\n",
      "Epoch:121, Accuracy:0.7737226277372263\n",
      "Epoch:122, Accuracy:0.781021897810219\n",
      "Epoch:123, Accuracy:0.708029197080292\n",
      "Epoch:124, Accuracy:0.6934306569343066\n",
      "Epoch:125, Accuracy:0.7700729927007299\n",
      "Epoch:126, Accuracy:0.8029197080291971\n",
      "Epoch:127, Accuracy:0.8795620437956204\n",
      "Epoch:128, Accuracy:0.8832116788321168\n",
      "Epoch:129, Accuracy:0.9197080291970803\n",
      "Epoch:130, Accuracy:0.948905109489051\n",
      "Epoch:131, Accuracy:0.9525547445255474\n",
      "Epoch:132, Accuracy:0.9744525547445255\n",
      "Epoch:133, Accuracy:0.9817518248175182\n",
      "Epoch:134, Accuracy:0.9817518248175182\n",
      "Epoch:135, Accuracy:0.9890510948905109\n",
      "Epoch:136, Accuracy:0.9890510948905109\n",
      "Epoch:137, Accuracy:0.9890510948905109\n",
      "Epoch:138, Accuracy:0.9890510948905109\n",
      "Epoch:139, Accuracy:0.9927007299270073\n",
      "Epoch:140, Accuracy:0.9927007299270073\n",
      "Epoch:141, Accuracy:0.9927007299270073\n",
      "Epoch:142, Accuracy:0.9963503649635036\n",
      "Epoch:143, Accuracy:1.0\n",
      "Epoch:144, Accuracy:1.0\n",
      "Epoch:145, Accuracy:1.0\n",
      "Epoch:146, Accuracy:1.0\n",
      "Epoch:147, Accuracy:1.0\n",
      "Epoch:148, Accuracy:1.0\n",
      "Epoch:149, Accuracy:1.0\n",
      "Epoch:150, Accuracy:1.0\n",
      "Epoch:151, Accuracy:1.0\n",
      "Epoch:152, Accuracy:1.0\n",
      "Epoch:153, Accuracy:1.0\n",
      "Epoch:154, Accuracy:1.0\n",
      "Epoch:155, Accuracy:1.0\n",
      "Epoch:156, Accuracy:1.0\n",
      "Epoch:157, Accuracy:1.0\n",
      "Epoch:158, Accuracy:1.0\n",
      "Epoch:159, Accuracy:1.0\n",
      "Epoch:160, Accuracy:1.0\n",
      "Epoch:161, Accuracy:1.0\n",
      "Epoch:162, Accuracy:1.0\n",
      "Epoch:163, Accuracy:1.0\n",
      "Epoch:164, Accuracy:1.0\n",
      "Epoch:165, Accuracy:1.0\n",
      "Epoch:166, Accuracy:1.0\n",
      "Epoch:167, Accuracy:1.0\n",
      "Epoch:168, Accuracy:1.0\n",
      "Epoch:169, Accuracy:1.0\n",
      "Epoch:170, Accuracy:1.0\n",
      "Epoch:171, Accuracy:1.0\n",
      "Epoch:172, Accuracy:1.0\n",
      "Epoch:173, Accuracy:1.0\n",
      "Epoch:174, Accuracy:1.0\n",
      "Epoch:175, Accuracy:1.0\n",
      "Epoch:176, Accuracy:1.0\n",
      "Epoch:177, Accuracy:1.0\n",
      "Epoch:178, Accuracy:1.0\n",
      "Epoch:179, Accuracy:1.0\n",
      "Epoch:180, Accuracy:1.0\n",
      "Epoch:181, Accuracy:1.0\n",
      "Epoch:182, Accuracy:1.0\n",
      "Epoch:183, Accuracy:1.0\n",
      "Epoch:184, Accuracy:1.0\n",
      "Epoch:185, Accuracy:1.0\n",
      "Epoch:186, Accuracy:1.0\n",
      "Epoch:187, Accuracy:1.0\n",
      "Epoch:188, Accuracy:1.0\n",
      "Epoch:189, Accuracy:1.0\n",
      "Epoch:190, Accuracy:1.0\n",
      "Epoch:191, Accuracy:1.0\n",
      "Epoch:192, Accuracy:1.0\n",
      "Epoch:193, Accuracy:1.0\n",
      "Epoch:194, Accuracy:1.0\n",
      "Epoch:195, Accuracy:1.0\n",
      "Epoch:196, Accuracy:1.0\n",
      "Epoch:197, Accuracy:1.0\n",
      "Epoch:198, Accuracy:1.0\n",
      "Epoch:199, Accuracy:1.0\n",
      "Epoch:200, Accuracy:1.0\n",
      "Epoch:201, Accuracy:1.0\n",
      "Epoch:202, Accuracy:1.0\n",
      "Epoch:203, Accuracy:1.0\n",
      "Epoch:204, Accuracy:1.0\n",
      "Epoch:205, Accuracy:1.0\n",
      "Epoch:206, Accuracy:1.0\n",
      "Epoch:207, Accuracy:1.0\n",
      "Epoch:208, Accuracy:1.0\n",
      "Epoch:209, Accuracy:1.0\n",
      "Epoch:210, Accuracy:1.0\n",
      "Epoch:211, Accuracy:1.0\n",
      "Epoch:212, Accuracy:1.0\n",
      "Epoch:213, Accuracy:1.0\n",
      "Epoch:214, Accuracy:1.0\n",
      "Epoch:215, Accuracy:1.0\n",
      "Epoch:216, Accuracy:1.0\n",
      "Epoch:217, Accuracy:1.0\n",
      "Epoch:218, Accuracy:1.0\n",
      "Epoch:219, Accuracy:1.0\n",
      "Epoch:220, Accuracy:1.0\n",
      "Epoch:221, Accuracy:1.0\n",
      "Epoch:222, Accuracy:1.0\n",
      "Epoch:223, Accuracy:1.0\n",
      "Epoch:224, Accuracy:1.0\n",
      "Epoch:225, Accuracy:1.0\n",
      "Epoch:226, Accuracy:1.0\n",
      "Epoch:227, Accuracy:1.0\n",
      "Epoch:228, Accuracy:1.0\n",
      "Epoch:229, Accuracy:1.0\n",
      "Epoch:230, Accuracy:1.0\n",
      "Epoch:231, Accuracy:1.0\n",
      "Epoch:232, Accuracy:1.0\n",
      "Epoch:233, Accuracy:1.0\n",
      "Epoch:234, Accuracy:1.0\n",
      "Epoch:235, Accuracy:1.0\n",
      "Epoch:236, Accuracy:1.0\n",
      "Epoch:237, Accuracy:1.0\n",
      "Epoch:238, Accuracy:1.0\n",
      "Epoch:239, Accuracy:1.0\n",
      "Epoch:240, Accuracy:1.0\n",
      "Epoch:241, Accuracy:1.0\n",
      "Epoch:242, Accuracy:1.0\n",
      "Epoch:243, Accuracy:1.0\n",
      "Epoch:244, Accuracy:1.0\n",
      "Epoch:245, Accuracy:1.0\n",
      "Epoch:246, Accuracy:1.0\n",
      "Epoch:247, Accuracy:1.0\n",
      "Epoch:248, Accuracy:1.0\n",
      "Epoch:249, Accuracy:1.0\n",
      "Epoch:250, Accuracy:1.0\n",
      "Epoch:251, Accuracy:1.0\n",
      "Epoch:252, Accuracy:1.0\n",
      "Epoch:253, Accuracy:1.0\n",
      "Epoch:254, Accuracy:1.0\n",
      "Epoch:255, Accuracy:1.0\n",
      "Epoch:256, Accuracy:1.0\n",
      "Epoch:257, Accuracy:1.0\n",
      "Epoch:258, Accuracy:1.0\n",
      "Epoch:259, Accuracy:1.0\n"
     ]
    }
   ],
   "source": [
    "use_cuda = True\n",
    "if torch.cuda.is_available():\n",
    "    model = CNNLargeNet2().cuda()\n",
    "Y = trainSmall(model, train_dataset, batch_size=64, learning_rate=0.005, num_epochs=260)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "In the last adjustment of hyperparameters, our training results showed overfitting. This indicates that our model is ready for the next step of training. In the following code, we rewrote the data loader and training function, and added checkpoints for each epoch. We attempted to use 60% of the entire dataset as training data, 20% as validation data, and the remaining 20% as test data.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-12T19:49:06.167753710Z",
     "start_time": "2023-11-12T19:49:06.167378697Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "Label 0: 890 images\n",
      "Label 1: 208 images\n",
      "Label 2: 439 images\n",
      "Label 3: 570 images\n",
      "Label 4: 1406 images\n",
      "Label 5: 524 images\n",
      "Label 6: 746 images\n",
      "Label 7: 775 images\n"
     ]
    }
   ],
   "source": [
    "features_or = []\n",
    "labels_or = []\n",
    "train_data_or = []\n",
    "data_transform1 = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "def create_train2():\n",
    "    for i, photo in enumerate(classeses):\n",
    "        path = os.path.join('C:/Users/Z/Desktop/MIE1517/data', photo)\n",
    "        label = i  # Use the index of the class as the label\n",
    "\n",
    "        # Loop over to get every image in the current class\n",
    "        for img_name in os.listdir(path):\n",
    "            img_path = os.path.join(path, img_name)\n",
    "            img_pil = cv.imread(img_path)\n",
    "            img_pil = Image.fromarray(cv.cvtColor(img_pil, cv.COLOR_BGR2RGB))\n",
    "            transformed_image1 = data_transform1(img_pil)\n",
    "\n",
    "            if img_pil is None:\n",
    "                print(\"Error loading image:\", img_pil)\n",
    "                continue\n",
    "            # Append the original image and its label to the list\n",
    "            features_or.append(transformed_image1)\n",
    "            labels_or.append(label)\n",
    "\n",
    "            train_data_or.append([img_pil, label])\n",
    "create_train2()\n",
    "print(type(features_or[0]))\n",
    "# Count the occurrences of each label\n",
    "label_counts_or = Counter(labels_or)\n",
    "\n",
    "# Print the label counts\n",
    "for label, count in label_counts_or.items():\n",
    "    print(f\"Label {label}: {count} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels_or\n",
    "features = features_or\n",
    "# Shuffle the labels and features in the same order\n",
    "combined = list(zip(labels, features))\n",
    "labels, features = zip(*combined)\n",
    "\n",
    "# Create a dictionary to store images by label\n",
    "label_to_images = defaultdict(list)\n",
    "\n",
    "# Group images by label\n",
    "for label, img in zip(labels, features):\n",
    "    label_to_images[label].append(img)\n",
    "\n",
    "# Set the ratios for train, validation, and test sets\n",
    "train_ratio = 0.6\n",
    "validation_ratio = 0.2\n",
    "test_ratio = 0.2\n",
    "\n",
    "train_data = []\n",
    "validation_data = []\n",
    "test_data = []\n",
    "\n",
    "# Split data for each label\n",
    "for label, images in label_to_images.items():\n",
    "    random.shuffle(images)  # Shuffle the images for each label\n",
    "\n",
    "    num_images = len(images)\n",
    "    num_train = int(train_ratio * num_images)\n",
    "    num_validation = int(validation_ratio * num_images)\n",
    "    num_test = num_images - num_train - num_validation\n",
    "\n",
    "    train_data.extend([(img, label) for img in images[:num_train]])\n",
    "    validation_data.extend([(img, label) for img in images[num_train:num_train + num_validation]])\n",
    "    test_data.extend([(img, label) for img in images[num_train + num_validation:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNLargeNet(nn.Module):\n",
    "    def __init__( self, output1=32, output2=64, output3=128, output4=256):\n",
    "        super(CNNLargeNet, self).__init__()\n",
    "        self.name = \"CNN\"\n",
    "        \n",
    "        # Define the sequential layers for feature extraction\n",
    "        self.features = nn.Sequential(\n",
    "            # Convolutional Layer 1\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            # Convolutional Layer 2\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            # Convolutional Layer 3\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            # Convolutional Layer 4\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            # Convolutional Layer 5\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        \n",
    "        # Flatten the tensor for the fully connected layers\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 8)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)  # Pass the input through the feature layers\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor for the classifier\n",
    "        x = self.classifier(x)  # Pass the flattened tensor through the classifier\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name(name, batch_size, learning_rate, epoch):\n",
    "    path = \"model_{0}_bs{1}_lr{2}_epoch{3}\".format(name, batch_size, learning_rate, epoch)\n",
    "    return path\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    \"\"\" Evaluate the network \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in loader:\n",
    "      if use_cuda and torch.cuda.is_available():\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "      outputs = model(inputs)\n",
    "      predicted = outputs.max(1, keepdim=True)[1]\n",
    "      total += inputs.shape[0]\n",
    "      correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainmodel(model, train_dataset, val_dataset, batch=64, learningRate=0.01, num_epochs=300):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learningRate)\n",
    "    \n",
    "    model_checkpoint_path = 'D:/MIE1517/output'  # You can change the directory as needed\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch, shuffle=False) \n",
    "\n",
    "    train_accuracy = np.zeros(num_epochs)\n",
    "    train_losses = np.zeros(num_epochs)\n",
    "    validation_accuracy = np.zeros(num_epochs)\n",
    "    validation_losses = np.zeros(num_epochs)\n",
    "    iters = []\n",
    "\n",
    "    # Check CUDA availability\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    n = 0  # Initialize the iteration counter\n",
    "    # Training\n",
    "    print(\"Training Begin...\\n\")\n",
    "    start_time = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        # Train mode\n",
    "        model.train()  # Set the model to training mode\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            # Get the inputs\n",
    "            inputs, labels = data\n",
    "            # Set up for gpu running\n",
    "            if use_cuda and torch.cuda.is_available():\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass, backward pass, and optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            n += 1\n",
    "            # Calculate loss\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        train_losses[epoch] = running_loss\n",
    "        train_accuracy[epoch] = evaluate(model, train_loader)\n",
    "        \n",
    "        # Evaluation mode\n",
    "        model.eval()  # Set the model to evaluation mode for accuracy computation\n",
    "        valid_loss = 0.0\n",
    "        # Running without gradients are computed and model weights update\n",
    "        for inputs, labels in val_loader:\n",
    "            if use_cuda and torch.cuda.is_available():\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            valid_loss += loss.item()\n",
    "\n",
    "        validation_losses[epoch] = valid_loss\n",
    "        validation_accuracy[epoch] = evaluate(model, val_loader)\n",
    "        iters.append(n)\n",
    "        \n",
    "        # Print progress for the epoch\n",
    "        print((\"Epoch {}: Train Accuracy: {}, Train loss: {} |\"+\n",
    "               \"Validation Accuracy: {}, Validation loss: {}\").format(\n",
    "                   epoch + 1,\n",
    "                   train_accuracy[epoch],\n",
    "                   train_losses[epoch],\n",
    "                   validation_accuracy[epoch],\n",
    "                   validation_losses[epoch]))\n",
    "\n",
    "        # Save model checkpoint every 5 epochs\n",
    "        # if (epoch + 1) % 5 == 0:  # +1 because epochs start from 0\n",
    "            # Save the current model checkpoint to a file\n",
    "        model_path = get_model_name(model.name, batch, learningRate, epoch)\n",
    "        model_path = os.path.join(model_checkpoint_path, model_path)\n",
    "        torch.save(model.state_dict(), \"{}.pt\".format(model_path))\n",
    "\n",
    "    print(\"Finshied Training\")\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(\"Total time elapsed: {:.2f} seconds\".format(elapsed_time))\n",
    "    # Write the train/test loss/err into CSV file for plotting later\n",
    "    # Save model checkpoint\n",
    "    epochs = np.arange(1, num_epochs + 1)\n",
    "    np.savetxt(\"{}_train_acc.csv\".format(model_checkpoint_path), train_accuracy)\n",
    "    np.savetxt(\"{}_train_loss.csv\".format(model_checkpoint_path), train_losses)\n",
    "    np.savetxt(\"{}_val_acc.csv\".format(model_checkpoint_path), validation_accuracy)\n",
    "    np.savetxt(\"{}_val_loss.csv\".format(model_checkpoint_path), validation_losses)\n",
    "\n",
    "    plt.title(\"Training Loss Curve\")\n",
    "    plt.plot(iters, train_losses, label=\"Train\")\n",
    "    plt.xlabel(\"iters\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.title(\"Accuracy Curve\")\n",
    "    plt.plot(iters, train_accuracy, label=\"Train\")\n",
    "    plt.xlabel(\"iters\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.show()\n",
    "    print(\"Finished Training\")\n",
    "    return iters, train_losses, train_accuracy, validation_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Begin...\n",
      "\n",
      "Epoch 1: Train Accuracy: 0.24669867947178872, Train loss: 485.4797168970108 |Validation Accuracy: 0.2587917042380523, Validation loss: 35.40146100521088\n",
      "Epoch 2: Train Accuracy: 0.25540216086434575, Train loss: 106.2787618637085 |Validation Accuracy: 0.2551848512173129, Validation loss: 35.74875247478485\n",
      "Epoch 3: Train Accuracy: 0.24429771908763506, Train loss: 106.01051235198975 |Validation Accuracy: 0.23715058611361586, Validation loss: 35.52350211143494\n",
      "Epoch 4: Train Accuracy: 0.2530012004801921, Train loss: 104.76455867290497 |Validation Accuracy: 0.2533814247069432, Validation loss: 35.40428078174591\n",
      "Epoch 5: Train Accuracy: 0.2530012004801921, Train loss: 104.6904878616333 |Validation Accuracy: 0.2533814247069432, Validation loss: 35.248910546302795\n",
      "Epoch 6: Train Accuracy: 0.2530012004801921, Train loss: 103.96354961395264 |Validation Accuracy: 0.2533814247069432, Validation loss: 35.33258938789368\n",
      "Epoch 7: Train Accuracy: 0.2530012004801921, Train loss: 104.58709156513214 |Validation Accuracy: 0.2533814247069432, Validation loss: 35.58008944988251\n",
      "Epoch 8: Train Accuracy: 0.2530012004801921, Train loss: 104.64674961566925 |Validation Accuracy: 0.2533814247069432, Validation loss: 35.30897557735443\n",
      "Epoch 9: Train Accuracy: 0.2530012004801921, Train loss: 104.21884179115295 |Validation Accuracy: 0.2533814247069432, Validation loss: 35.49858772754669\n",
      "Epoch 10: Train Accuracy: 0.2527010804321729, Train loss: 104.05564165115356 |Validation Accuracy: 0.2515779981965735, Validation loss: 35.38320326805115\n",
      "Epoch 11: Train Accuracy: 0.2530012004801921, Train loss: 103.9314192533493 |Validation Accuracy: 0.2533814247069432, Validation loss: 35.3780962228775\n",
      "Epoch 12: Train Accuracy: 0.2530012004801921, Train loss: 104.12396693229675 |Validation Accuracy: 0.2533814247069432, Validation loss: 35.107085824012756\n",
      "Epoch 13: Train Accuracy: 0.2530012004801921, Train loss: 103.73823976516724 |Validation Accuracy: 0.2533814247069432, Validation loss: 35.35266184806824\n",
      "Epoch 14: Train Accuracy: 0.2530012004801921, Train loss: 104.11182916164398 |Validation Accuracy: 0.2533814247069432, Validation loss: 35.14752686023712\n",
      "Epoch 15: Train Accuracy: 0.2530012004801921, Train loss: 103.82148349285126 |Validation Accuracy: 0.2533814247069432, Validation loss: 35.212727665901184\n",
      "Epoch 16: Train Accuracy: 0.2530012004801921, Train loss: 103.65259170532227 |Validation Accuracy: 0.2533814247069432, Validation loss: 35.394485116004944\n",
      "Epoch 17: Train Accuracy: 0.2530012004801921, Train loss: 104.21688461303711 |Validation Accuracy: 0.2533814247069432, Validation loss: 35.19212830066681\n",
      "Epoch 18: Train Accuracy: 0.2530012004801921, Train loss: 103.62237906455994 |Validation Accuracy: 0.2533814247069432, Validation loss: 35.20077908039093\n",
      "Epoch 19: Train Accuracy: 0.2530012004801921, Train loss: 104.35771262645721 |Validation Accuracy: 0.2533814247069432, Validation loss: 35.536439418792725\n",
      "Epoch 20: Train Accuracy: 0.2530012004801921, Train loss: 104.6897474527359 |Validation Accuracy: 0.2533814247069432, Validation loss: 35.31949853897095\n",
      "Epoch 21: Train Accuracy: 0.2530012004801921, Train loss: 104.12846601009369 |Validation Accuracy: 0.2533814247069432, Validation loss: 35.30682909488678\n",
      "Epoch 22: Train Accuracy: 0.2530012004801921, Train loss: 103.86183321475983 |Validation Accuracy: 0.2533814247069432, Validation loss: 35.27958011627197\n",
      "Epoch 23: Train Accuracy: 0.2530012004801921, Train loss: 103.94126522541046 |Validation Accuracy: 0.2533814247069432, Validation loss: 35.3345764875412\n",
      "Epoch 24: Train Accuracy: 0.2530012004801921, Train loss: 104.1831955909729 |Validation Accuracy: 0.2533814247069432, Validation loss: 35.356382608413696\n",
      "Epoch 25: Train Accuracy: 0.2530012004801921, Train loss: 103.757936835289 |Validation Accuracy: 0.2533814247069432, Validation loss: 35.22792112827301\n",
      "Epoch 26: Train Accuracy: 0.2530012004801921, Train loss: 103.6955999135971 |Validation Accuracy: 0.2533814247069432, Validation loss: 35.621468901634216\n",
      "Epoch 27: Train Accuracy: 0.2530012004801921, Train loss: 103.44011807441711 |Validation Accuracy: 0.2533814247069432, Validation loss: 35.07829225063324\n",
      "Epoch 28: Train Accuracy: 0.2530012004801921, Train loss: 103.28565585613251 |Validation Accuracy: 0.2533814247069432, Validation loss: 35.09285855293274\n",
      "Epoch 29: Train Accuracy: 0.2530012004801921, Train loss: 102.65012240409851 |Validation Accuracy: 0.2533814247069432, Validation loss: 35.45600891113281\n",
      "Epoch 30: Train Accuracy: 0.2527010804321729, Train loss: 103.1660897731781 |Validation Accuracy: 0.2533814247069432, Validation loss: 35.02439987659454\n",
      "Epoch 31: Train Accuracy: 0.2527010804321729, Train loss: 102.82255327701569 |Validation Accuracy: 0.2533814247069432, Validation loss: 35.364808559417725\n",
      "Epoch 32: Train Accuracy: 0.2530012004801921, Train loss: 103.00622403621674 |Validation Accuracy: 0.2533814247069432, Validation loss: 35.10087716579437\n",
      "Epoch 33: Train Accuracy: 0.2536014405762305, Train loss: 103.22379720211029 |Validation Accuracy: 0.26149684400360684, Validation loss: 35.16257655620575\n",
      "Epoch 34: Train Accuracy: 0.2530012004801921, Train loss: 103.44942438602448 |Validation Accuracy: 0.2533814247069432, Validation loss: 35.08189797401428\n",
      "Epoch 35: Train Accuracy: 0.2530012004801921, Train loss: 103.12322759628296 |Validation Accuracy: 0.2533814247069432, Validation loss: 35.10048174858093\n",
      "Epoch 36: Train Accuracy: 0.2539015606242497, Train loss: 103.39071023464203 |Validation Accuracy: 0.2533814247069432, Validation loss: 35.105738401412964\n",
      "Epoch 37: Train Accuracy: 0.2530012004801921, Train loss: 103.53674674034119 |Validation Accuracy: 0.2533814247069432, Validation loss: 35.083845138549805\n",
      "Epoch 38: Train Accuracy: 0.2530012004801921, Train loss: 103.6161515712738 |Validation Accuracy: 0.2533814247069432, Validation loss: 35.080389618873596\n",
      "Epoch 39: Train Accuracy: 0.2530012004801921, Train loss: 103.4220061302185 |Validation Accuracy: 0.2533814247069432, Validation loss: 35.0266227722168\n",
      "Epoch 40: Train Accuracy: 0.2530012004801921, Train loss: 103.08749186992645 |Validation Accuracy: 0.2533814247069432, Validation loss: 35.1819726228714\n",
      "Epoch 41: Train Accuracy: 0.2530012004801921, Train loss: 102.93579232692719 |Validation Accuracy: 0.2533814247069432, Validation loss: 34.99542701244354\n",
      "Epoch 42: Train Accuracy: 0.2530012004801921, Train loss: 103.59367632865906 |Validation Accuracy: 0.2533814247069432, Validation loss: 35.168413043022156\n",
      "Epoch 43: Train Accuracy: 0.2530012004801921, Train loss: 103.55779194831848 |Validation Accuracy: 0.2533814247069432, Validation loss: 35.14651954174042\n",
      "Epoch 44: Train Accuracy: 0.2530012004801921, Train loss: 103.39014160633087 |Validation Accuracy: 0.2533814247069432, Validation loss: 35.069620013237\n",
      "Epoch 45: Train Accuracy: 0.2530012004801921, Train loss: 103.06234240531921 |Validation Accuracy: 0.2533814247069432, Validation loss: 35.00040805339813\n",
      "Epoch 46: Train Accuracy: 0.2530012004801921, Train loss: 104.27232909202576 |Validation Accuracy: 0.2533814247069432, Validation loss: 35.61888647079468\n",
      "Epoch 47: Train Accuracy: 0.2530012004801921, Train loss: 104.16431975364685 |Validation Accuracy: 0.2533814247069432, Validation loss: 35.31994950771332\n",
      "Epoch 48: Train Accuracy: 0.2530012004801921, Train loss: 104.05877196788788 |Validation Accuracy: 0.2533814247069432, Validation loss: 35.29570436477661\n",
      "Epoch 49: Train Accuracy: 0.2530012004801921, Train loss: 104.06250166893005 |Validation Accuracy: 0.2533814247069432, Validation loss: 35.27316069602966\n",
      "Epoch 50: Train Accuracy: 0.2530012004801921, Train loss: 103.44758141040802 |Validation Accuracy: 0.2533814247069432, Validation loss: 35.16643238067627\n",
      "Finshied Training\n",
      "Total time elapsed: 877.25 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "use_cuda = True\n",
    "if torch.cuda.is_available():\n",
    "    model = CNNLargeNet().cuda()\n",
    "Y = trainmodel(model, train_data, validation_data, batch=64, learningRate=0.005, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "if torch.cuda.is_available():\n",
    "    model = CNNLargeNet().cuda()\n",
    "Y = trainmodel(model, train_data, validation_data, batch=64, learningRate=0.001, num_epochs=520)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
