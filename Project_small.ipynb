{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arthur-ca/MIE1517/blob/YayunYang/Project_small.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yq0MKgApDInX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "import torchvision\n",
        "from torchvision import datasets, models\n",
        "from collections import defaultdict\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms.functional as F1\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
        "from torchvision.datasets import ImageFolder\n",
        "import cv2 as cv\n",
        "import tensorflow as tf\n",
        "import gc\n",
        "from collections import Counter\n",
        "import imgaug.augmenters as iaa"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "directory_path = '/content/gdrive/MyDrive/archive'\n",
        "ds_store_path = os.path.join(directory_path, '.DS_Store')\n",
        "\n",
        "if os.path.exists(ds_store_path):\n",
        "    os.remove(ds_store_path)\n",
        "else:\n",
        "    print(\".DS_Store file does not exist in the directory.\")"
      ],
      "metadata": {
        "id": "fTd6YA73JsJC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11591e23-0766-4fcc-b198-d7831c3014c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".DS_Store file does not exist in the directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "PjxPEAukDNt-",
        "outputId": "0434ef2d-373a-4498-8a0f-1f57f4f16bf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-c88d3c74aa89>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdrive_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/MyDrive/archive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrive_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/MyDrive/archive'"
          ]
        }
      ],
      "source": [
        "#First link it to google drive and check the subfolder of the data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive_content = os.listdir('/content/gdrive/MyDrive/archive')\n",
        "print(drive_content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "lHFVdw5apSEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6_Ip_NB52CQ",
        "outputId": "c32d294c-3d28-4010-8340-c747d34b8a47"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['surprise',\n",
              " 'neutrality',\n",
              " 'fear',\n",
              " 'happiness',\n",
              " 'sadness',\n",
              " 'contempt',\n",
              " 'anger',\n",
              " 'disgust']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "classeses = []\n",
        "for i in os.listdir('/content/gdrive/MyDrive/archive'):\n",
        "    if i!=5:\n",
        "        classeses.append(i)\n",
        "classeses"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def gauss_noise_tensor(img):\n",
        "#     assert isinstance(img, torch.Tensor)\n",
        "#     dtype = img.dtype\n",
        "#     if not img.is_floating_point():\n",
        "#         img = img.to(torch.float32)\n",
        "\n",
        "#     sigma = 25.0\n",
        "\n",
        "#     out = img + sigma * torch.randn_like(img)\n",
        "\n",
        "#     if out.dtype != dtype:\n",
        "#         out = out.to(dtype)\n",
        "\n",
        "#     return out\n",
        "# class ImgAugTransform:\n",
        "#     def __init__(self):\n",
        "#         self.aug = iaa.Sequential([\n",
        "#             iaa.Resize({\"height\": 224, \"width\": 224}),\n",
        "#             iaa.Sometimes(0.25, iaa.GaussianBlur(sigma=(0, 3.0))),\n",
        "#             iaa.Sometimes(0.25, iaa.Affine(rotate=(-20, 20), mode='symmetric')),\n",
        "#             iaa.Sometimes(0.25, iaa.OneOf([\n",
        "#                 iaa.Dropout(p=(0, 0.1)),\n",
        "#                 iaa.CoarseDropout(0.1, size_percent=0.5)\n",
        "#             ])),\n",
        "#             iaa.AddToHueAndSaturation(value=(-10, 10), per_channel=True)\n",
        "#         ])\n",
        "\n",
        "#     def __call__(self, img):\n",
        "#         img = np.array(img)\n",
        "\n",
        "#         augmented_img = self.aug.augment_image(img)\n",
        "\n",
        "#         # Convert the augmented image to PyTorch tensor\n",
        "#         augmented_tensor = F1.to_tensor(augmented_img)\n",
        "#         return self.aug.augment_image(img)\n",
        "#   imgaug_transform = ImgAugTransform()"
      ],
      "metadata": {
        "id": "EkEP0L_ASYVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_or = []\n",
        "labels_or = []\n",
        "train_data_or = []\n",
        "data_transform1 = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "def create_train2(data_percentage=5):\n",
        "    for i, photo in enumerate(classeses):\n",
        "        path = os.path.join('/content/gdrive/MyDrive/archive', photo)\n",
        "        label = i  # Use the index of the class as the label\n",
        "\n",
        "        # List all images in the class folder\n",
        "        img_list = os.listdir(path)\n",
        "\n",
        "        # Calculate the number of images to load (5% of total)\n",
        "        num_images_to_load = int(len(img_list) * (data_percentage / 100))\n",
        "\n",
        "        # Randomly select a subset of images\n",
        "        selected_images = random.sample(img_list, num_images_to_load)\n",
        "\n",
        "\n",
        "        for img_name in selected_images:\n",
        "            img_path = os.path.join(path, img_name)\n",
        "            img_pil = Image.open(img_path)\n",
        "            transformed_image1 = data_transform1(img_pil)\n",
        "\n",
        "            if img_pil is None:\n",
        "                print(\"Error loading image:\", img_path)\n",
        "                continue\n",
        "\n",
        "            # Append the original image and its label to the list\n",
        "            features_or.append(transformed_image1)\n",
        "            labels_or.append(label)\n",
        "\n",
        "            train_data_or.append([img_pil, label])\n",
        "\n",
        "create_train2(data_percentage=5)  # Load only 5% of the data\n",
        "print(type(features_or[0]))\n",
        "# Count the occurrences of each label\n",
        "label_counts_or = Counter(labels_or)\n",
        "\n",
        "# Print the label counts\n",
        "for label, count in label_counts_or.items():\n",
        "    print(f\"Label {label}: {count} images\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjPs44Ion4HI",
        "outputId": "fbcb4fd7-c826-43bb-c41f-22eaa10adc66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "Label 0: 38 images\n",
            "Label 1: 26 images\n",
            "Label 2: 28 images\n",
            "Label 3: 70 images\n",
            "Label 4: 37 images\n",
            "Label 5: 10 images\n",
            "Label 6: 44 images\n",
            "Label 7: 21 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a transformation to convert PIL images to PyTorch tensors\n",
        "data_transform_to_tensor = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Convert images and labels to PyTorch tensors\n",
        "train_images = torch.stack([data_transform_to_tensor(data[0]) for data in train_data_or])\n",
        "train_labels = torch.tensor([data[1] for data in train_data_or])\n",
        "\n",
        "# Assuming you have a DataLoader for your training loop\n",
        "train_dataset = torch.utils.data.TensorDataset(train_images, train_labels)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "46ITZDBRT51_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy(model, dataset):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for imgs, labels in torch.utils.data.DataLoader(dataset, batch_size=64):\n",
        "        #############################################\n",
        "        #To Enable GPU Usage\n",
        "        if use_cuda and torch.cuda.is_available():\n",
        "          imgs = imgs.cuda()\n",
        "          labels = labels.cuda()\n",
        "        #############################################\n",
        "        output = model(imgs)\n",
        "        #select index with maximum prediction score\n",
        "        pred = output.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "        total += imgs.shape[0]\n",
        "    return correct / total"
      ],
      "metadata": {
        "id": "bxh0XEA-SRrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainSmall(model, data, batch_size=64, learning_rate=0.01, num_epochs=500):\n",
        "    train_loader = torch.utils.data.DataLoader(data, batch_size=batch_size)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    train_acc = []\n",
        "\n",
        "    # training\n",
        "    print(\"Training Start\")\n",
        "    n = 0  # the number of iterations\n",
        "    for epoch in range(num_epochs):\n",
        "        for imgs, labels in iter(train_loader):\n",
        "            #############################################\n",
        "            # To Enable GPU Usage\n",
        "            imgs = imgs.cuda()\n",
        "            labels = labels.cuda()\n",
        "            #############################################\n",
        "\n",
        "            # Check if imgs is already a tensor\n",
        "            if not torch.is_tensor(imgs):\n",
        "                img_to_tensor = transforms.ToTensor()\n",
        "                imgs = img_to_tensor(imgs)\n",
        "\n",
        "                # Convert input to float\n",
        "                imgs = imgs.float()\n",
        "\n",
        "            # Convert the input tensor to the desired type\n",
        "            imgs = imgs.type(torch.float32)\n",
        "\n",
        "            out = model(imgs)  # forward pass\n",
        "            loss = criterion(out, labels)  # compute the total loss\n",
        "            loss.backward()  # backward pass (compute parameter updates)\n",
        "            optimizer.step()  # make the updates for each parameter\n",
        "            optimizer.zero_grad()  # a clean-up step for PyTorch\n",
        "            n += 1\n",
        "\n",
        "        train_accuracy = get_accuracy(model, data)\n",
        "        train_acc.append(train_accuracy)\n",
        "        print(\"Epoch:{}, Accuracy:{}\".format(epoch, train_accuracy))\n",
        "    return train_acc"
      ],
      "metadata": {
        "id": "FE_M9cyTQ9_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNNLargeNet2(nn.Module):\n",
        "    def __init__( self, output1=32, output2=64, output3=128, output4=256):\n",
        "        super(CNNLargeNet2, self).__init__()\n",
        "        self.name = \"CNN\"\n",
        "\n",
        "        # Define the sequential layers for feature extraction\n",
        "        self.features = nn.Sequential(\n",
        "            # Convolutional Layer 1\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # Convolutional Layer 2\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # Convolutional Layer 3\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # Convolutional Layer 4\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # Convolutional Layer 5\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "\n",
        "        # Flatten the tensor for the fully connected layers\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            #nn.Dropout(p=0.5),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            #nn.Dropout(p=0.5),\n",
        "            nn.Linear(512, 8)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)  # Pass the input through the feature layers\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor for the classifier\n",
        "        x = self.classifier(x)  # Pass the flattened tensor through the classifier\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "ghFYeltCS2-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = True\n",
        "if torch.cuda.is_available():\n",
        "    model = CNNLargeNet2().cuda()\n",
        "Y = trainSmall(model, train_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRPxddC5TKOk",
        "outputId": "36b893f9-dfd9-412c-939e-1cb163f31fec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Start\n",
            "Epoch:0, Accuracy:0.07664233576642336\n",
            "Epoch:1, Accuracy:0.16058394160583941\n",
            "Epoch:2, Accuracy:0.22992700729927007\n",
            "Epoch:3, Accuracy:0.08394160583941605\n",
            "Epoch:4, Accuracy:0.2664233576642336\n",
            "Epoch:5, Accuracy:0.2518248175182482\n",
            "Epoch:6, Accuracy:0.2518248175182482\n",
            "Epoch:7, Accuracy:0.26277372262773724\n",
            "Epoch:8, Accuracy:0.2737226277372263\n",
            "Epoch:9, Accuracy:0.2846715328467153\n",
            "Epoch:10, Accuracy:0.2846715328467153\n",
            "Epoch:11, Accuracy:0.28832116788321166\n",
            "Epoch:12, Accuracy:0.2591240875912409\n",
            "Epoch:13, Accuracy:0.2664233576642336\n",
            "Epoch:14, Accuracy:0.2664233576642336\n",
            "Epoch:15, Accuracy:0.27007299270072993\n",
            "Epoch:16, Accuracy:0.28102189781021897\n",
            "Epoch:17, Accuracy:0.2737226277372263\n",
            "Epoch:18, Accuracy:0.28832116788321166\n",
            "Epoch:19, Accuracy:0.2846715328467153\n",
            "Epoch:20, Accuracy:0.28102189781021897\n",
            "Epoch:21, Accuracy:0.2846715328467153\n",
            "Epoch:22, Accuracy:0.3029197080291971\n",
            "Epoch:23, Accuracy:0.291970802919708\n",
            "Epoch:24, Accuracy:0.2956204379562044\n",
            "Epoch:25, Accuracy:0.29927007299270075\n",
            "Epoch:26, Accuracy:0.3029197080291971\n",
            "Epoch:27, Accuracy:0.3175182481751825\n",
            "Epoch:28, Accuracy:0.3175182481751825\n",
            "Epoch:29, Accuracy:0.3357664233576642\n",
            "Epoch:30, Accuracy:0.3248175182481752\n",
            "Epoch:31, Accuracy:0.3467153284671533\n",
            "Epoch:32, Accuracy:0.35036496350364965\n",
            "Epoch:33, Accuracy:0.354014598540146\n",
            "Epoch:34, Accuracy:0.3284671532846715\n",
            "Epoch:35, Accuracy:0.3722627737226277\n",
            "Epoch:36, Accuracy:0.3795620437956204\n",
            "Epoch:37, Accuracy:0.36496350364963503\n",
            "Epoch:38, Accuracy:0.3795620437956204\n",
            "Epoch:39, Accuracy:0.38321167883211676\n",
            "Epoch:40, Accuracy:0.3905109489051095\n",
            "Epoch:41, Accuracy:0.38321167883211676\n",
            "Epoch:42, Accuracy:0.4051094890510949\n",
            "Epoch:43, Accuracy:0.3978102189781022\n",
            "Epoch:44, Accuracy:0.40145985401459855\n",
            "Epoch:45, Accuracy:0.4051094890510949\n",
            "Epoch:46, Accuracy:0.4051094890510949\n",
            "Epoch:47, Accuracy:0.40875912408759124\n",
            "Epoch:48, Accuracy:0.40875912408759124\n",
            "Epoch:49, Accuracy:0.4306569343065693\n",
            "Epoch:50, Accuracy:0.4343065693430657\n",
            "Epoch:51, Accuracy:0.43795620437956206\n",
            "Epoch:52, Accuracy:0.4489051094890511\n",
            "Epoch:53, Accuracy:0.49635036496350365\n",
            "Epoch:54, Accuracy:0.4854014598540146\n",
            "Epoch:55, Accuracy:0.46715328467153283\n",
            "Epoch:56, Accuracy:0.5109489051094891\n",
            "Epoch:57, Accuracy:0.5401459854014599\n",
            "Epoch:58, Accuracy:0.5656934306569343\n",
            "Epoch:59, Accuracy:0.5218978102189781\n",
            "Epoch:60, Accuracy:0.33211678832116787\n",
            "Epoch:61, Accuracy:0.3978102189781022\n",
            "Epoch:62, Accuracy:0.23722627737226276\n",
            "Epoch:63, Accuracy:0.21532846715328466\n",
            "Epoch:64, Accuracy:0.24087591240875914\n",
            "Epoch:65, Accuracy:0.22992700729927007\n",
            "Epoch:66, Accuracy:0.22262773722627738\n",
            "Epoch:67, Accuracy:0.17153284671532848\n",
            "Epoch:68, Accuracy:0.18613138686131386\n",
            "Epoch:69, Accuracy:0.21532846715328466\n",
            "Epoch:70, Accuracy:0.1678832116788321\n",
            "Epoch:71, Accuracy:0.29927007299270075\n",
            "Epoch:72, Accuracy:0.3467153284671533\n",
            "Epoch:73, Accuracy:0.3722627737226277\n",
            "Epoch:74, Accuracy:0.35766423357664234\n",
            "Epoch:75, Accuracy:0.3759124087591241\n",
            "Epoch:76, Accuracy:0.39416058394160586\n",
            "Epoch:77, Accuracy:0.3905109489051095\n",
            "Epoch:78, Accuracy:0.3467153284671533\n",
            "Epoch:79, Accuracy:0.32116788321167883\n",
            "Epoch:80, Accuracy:0.3759124087591241\n",
            "Epoch:81, Accuracy:0.28832116788321166\n",
            "Epoch:82, Accuracy:0.32116788321167883\n",
            "Epoch:83, Accuracy:0.3102189781021898\n",
            "Epoch:84, Accuracy:0.3686131386861314\n",
            "Epoch:85, Accuracy:0.3722627737226277\n",
            "Epoch:86, Accuracy:0.33211678832116787\n",
            "Epoch:87, Accuracy:0.35036496350364965\n",
            "Epoch:88, Accuracy:0.3759124087591241\n",
            "Epoch:89, Accuracy:0.3795620437956204\n",
            "Epoch:90, Accuracy:0.40875912408759124\n",
            "Epoch:91, Accuracy:0.28102189781021897\n",
            "Epoch:92, Accuracy:0.24452554744525548\n",
            "Epoch:93, Accuracy:0.25547445255474455\n",
            "Epoch:94, Accuracy:0.25547445255474455\n",
            "Epoch:95, Accuracy:0.2518248175182482\n",
            "Epoch:96, Accuracy:0.2518248175182482\n",
            "Epoch:97, Accuracy:0.27007299270072993\n",
            "Epoch:98, Accuracy:0.2773722627737226\n",
            "Epoch:99, Accuracy:0.27007299270072993\n",
            "Epoch:100, Accuracy:0.2737226277372263\n",
            "Epoch:101, Accuracy:0.28102189781021897\n",
            "Epoch:102, Accuracy:0.2956204379562044\n",
            "Epoch:103, Accuracy:0.25547445255474455\n",
            "Epoch:104, Accuracy:0.33941605839416056\n",
            "Epoch:105, Accuracy:0.3248175182481752\n",
            "Epoch:106, Accuracy:0.2737226277372263\n",
            "Epoch:107, Accuracy:0.3357664233576642\n",
            "Epoch:108, Accuracy:0.21897810218978103\n",
            "Epoch:109, Accuracy:0.3795620437956204\n",
            "Epoch:110, Accuracy:0.36496350364963503\n",
            "Epoch:111, Accuracy:0.35766423357664234\n",
            "Epoch:112, Accuracy:0.3795620437956204\n",
            "Epoch:113, Accuracy:0.3102189781021898\n",
            "Epoch:114, Accuracy:0.42700729927007297\n",
            "Epoch:115, Accuracy:0.33941605839416056\n",
            "Epoch:116, Accuracy:0.43795620437956206\n",
            "Epoch:117, Accuracy:0.44525547445255476\n",
            "Epoch:118, Accuracy:0.46715328467153283\n",
            "Epoch:119, Accuracy:0.4781021897810219\n",
            "Epoch:120, Accuracy:0.3357664233576642\n",
            "Epoch:121, Accuracy:0.3175182481751825\n",
            "Epoch:122, Accuracy:0.3029197080291971\n",
            "Epoch:123, Accuracy:0.31386861313868614\n",
            "Epoch:124, Accuracy:0.3467153284671533\n",
            "Epoch:125, Accuracy:0.3029197080291971\n",
            "Epoch:126, Accuracy:0.41605839416058393\n",
            "Epoch:127, Accuracy:0.42700729927007297\n",
            "Epoch:128, Accuracy:0.44525547445255476\n",
            "Epoch:129, Accuracy:0.45255474452554745\n",
            "Epoch:130, Accuracy:0.4744525547445255\n",
            "Epoch:131, Accuracy:0.4854014598540146\n",
            "Epoch:132, Accuracy:0.5109489051094891\n",
            "Epoch:133, Accuracy:0.5036496350364964\n",
            "Epoch:134, Accuracy:0.4744525547445255\n",
            "Epoch:135, Accuracy:0.4562043795620438\n",
            "Epoch:136, Accuracy:0.4927007299270073\n",
            "Epoch:137, Accuracy:0.5145985401459854\n",
            "Epoch:138, Accuracy:0.4635036496350365\n",
            "Epoch:139, Accuracy:0.4708029197080292\n",
            "Epoch:140, Accuracy:0.4744525547445255\n",
            "Epoch:141, Accuracy:0.5072992700729927\n",
            "Epoch:142, Accuracy:0.3686131386861314\n",
            "Epoch:143, Accuracy:0.33941605839416056\n",
            "Epoch:144, Accuracy:0.3795620437956204\n",
            "Epoch:145, Accuracy:0.4306569343065693\n",
            "Epoch:146, Accuracy:0.4306569343065693\n",
            "Epoch:147, Accuracy:0.4489051094890511\n",
            "Epoch:148, Accuracy:0.4562043795620438\n",
            "Epoch:149, Accuracy:0.45255474452554745\n",
            "Epoch:150, Accuracy:0.45255474452554745\n",
            "Epoch:151, Accuracy:0.45985401459854014\n",
            "Epoch:152, Accuracy:0.4635036496350365\n",
            "Epoch:153, Accuracy:0.45255474452554745\n",
            "Epoch:154, Accuracy:0.45985401459854014\n",
            "Epoch:155, Accuracy:0.45985401459854014\n",
            "Epoch:156, Accuracy:0.3722627737226277\n",
            "Epoch:157, Accuracy:0.3284671532846715\n",
            "Epoch:158, Accuracy:0.45985401459854014\n",
            "Epoch:159, Accuracy:0.24452554744525548\n",
            "Epoch:160, Accuracy:0.34306569343065696\n",
            "Epoch:161, Accuracy:0.22992700729927007\n",
            "Epoch:162, Accuracy:0.20802919708029197\n",
            "Epoch:163, Accuracy:0.22627737226277372\n",
            "Epoch:164, Accuracy:0.4124087591240876\n",
            "Epoch:165, Accuracy:0.40145985401459855\n",
            "Epoch:166, Accuracy:0.4124087591240876\n",
            "Epoch:167, Accuracy:0.28102189781021897\n",
            "Epoch:168, Accuracy:0.26277372262773724\n",
            "Epoch:169, Accuracy:0.4233576642335766\n",
            "Epoch:170, Accuracy:0.4343065693430657\n",
            "Epoch:171, Accuracy:0.3795620437956204\n",
            "Epoch:172, Accuracy:0.4197080291970803\n",
            "Epoch:173, Accuracy:0.354014598540146\n",
            "Epoch:174, Accuracy:0.40875912408759124\n",
            "Epoch:175, Accuracy:0.3613138686131387\n",
            "Epoch:176, Accuracy:0.4306569343065693\n",
            "Epoch:177, Accuracy:0.36496350364963503\n",
            "Epoch:178, Accuracy:0.44525547445255476\n",
            "Epoch:179, Accuracy:0.3467153284671533\n",
            "Epoch:180, Accuracy:0.44525547445255476\n",
            "Epoch:181, Accuracy:0.40145985401459855\n",
            "Epoch:182, Accuracy:0.44525547445255476\n",
            "Epoch:183, Accuracy:0.40875912408759124\n",
            "Epoch:184, Accuracy:0.4489051094890511\n",
            "Epoch:185, Accuracy:0.38321167883211676\n",
            "Epoch:186, Accuracy:0.4489051094890511\n",
            "Epoch:187, Accuracy:0.4306569343065693\n",
            "Epoch:188, Accuracy:0.4562043795620438\n",
            "Epoch:189, Accuracy:0.45985401459854014\n",
            "Epoch:190, Accuracy:0.4562043795620438\n",
            "Epoch:191, Accuracy:0.45985401459854014\n",
            "Epoch:192, Accuracy:0.4562043795620438\n",
            "Epoch:193, Accuracy:0.45985401459854014\n",
            "Epoch:194, Accuracy:0.45985401459854014\n",
            "Epoch:195, Accuracy:0.45985401459854014\n",
            "Epoch:196, Accuracy:0.45985401459854014\n",
            "Epoch:197, Accuracy:0.45985401459854014\n",
            "Epoch:198, Accuracy:0.45985401459854014\n",
            "Epoch:199, Accuracy:0.4562043795620438\n",
            "Epoch:200, Accuracy:0.4562043795620438\n",
            "Epoch:201, Accuracy:0.45985401459854014\n",
            "Epoch:202, Accuracy:0.43795620437956206\n",
            "Epoch:203, Accuracy:0.45985401459854014\n",
            "Epoch:204, Accuracy:0.45985401459854014\n",
            "Epoch:205, Accuracy:0.33211678832116787\n",
            "Epoch:206, Accuracy:0.45985401459854014\n",
            "Epoch:207, Accuracy:0.46715328467153283\n",
            "Epoch:208, Accuracy:0.23722627737226276\n",
            "Epoch:209, Accuracy:0.22992700729927007\n",
            "Epoch:210, Accuracy:0.22992700729927007\n",
            "Epoch:211, Accuracy:0.24087591240875914\n",
            "Epoch:212, Accuracy:0.23357664233576642\n",
            "Epoch:213, Accuracy:0.22992700729927007\n",
            "Epoch:214, Accuracy:0.22992700729927007\n",
            "Epoch:215, Accuracy:0.22992700729927007\n",
            "Epoch:216, Accuracy:0.22992700729927007\n",
            "Epoch:217, Accuracy:0.22992700729927007\n",
            "Epoch:218, Accuracy:0.22627737226277372\n",
            "Epoch:219, Accuracy:0.22992700729927007\n",
            "Epoch:220, Accuracy:0.23357664233576642\n",
            "Epoch:221, Accuracy:0.23722627737226276\n",
            "Epoch:222, Accuracy:0.24087591240875914\n",
            "Epoch:223, Accuracy:0.24087591240875914\n",
            "Epoch:224, Accuracy:0.24087591240875914\n",
            "Epoch:225, Accuracy:0.24452554744525548\n",
            "Epoch:226, Accuracy:0.24817518248175183\n",
            "Epoch:227, Accuracy:0.24817518248175183\n",
            "Epoch:228, Accuracy:0.24817518248175183\n",
            "Epoch:229, Accuracy:0.23722627737226276\n",
            "Epoch:230, Accuracy:0.23722627737226276\n",
            "Epoch:231, Accuracy:0.23357664233576642\n",
            "Epoch:232, Accuracy:0.23357664233576642\n",
            "Epoch:233, Accuracy:0.24087591240875914\n",
            "Epoch:234, Accuracy:0.22992700729927007\n",
            "Epoch:235, Accuracy:0.22992700729927007\n",
            "Epoch:236, Accuracy:0.22262773722627738\n",
            "Epoch:237, Accuracy:0.2116788321167883\n",
            "Epoch:238, Accuracy:0.22992700729927007\n",
            "Epoch:239, Accuracy:0.22992700729927007\n",
            "Epoch:240, Accuracy:0.23722627737226276\n",
            "Epoch:241, Accuracy:0.22992700729927007\n",
            "Epoch:242, Accuracy:0.4197080291970803\n",
            "Epoch:243, Accuracy:0.42700729927007297\n",
            "Epoch:244, Accuracy:0.4124087591240876\n",
            "Epoch:245, Accuracy:0.40145985401459855\n",
            "Epoch:246, Accuracy:0.4416058394160584\n",
            "Epoch:247, Accuracy:0.4416058394160584\n",
            "Epoch:248, Accuracy:0.44525547445255476\n",
            "Epoch:249, Accuracy:0.44525547445255476\n",
            "Epoch:250, Accuracy:0.39416058394160586\n",
            "Epoch:251, Accuracy:0.45255474452554745\n",
            "Epoch:252, Accuracy:0.40145985401459855\n",
            "Epoch:253, Accuracy:0.45255474452554745\n",
            "Epoch:254, Accuracy:0.45985401459854014\n",
            "Epoch:255, Accuracy:0.4635036496350365\n",
            "Epoch:256, Accuracy:0.4562043795620438\n",
            "Epoch:257, Accuracy:0.4635036496350365\n",
            "Epoch:258, Accuracy:0.46715328467153283\n",
            "Epoch:259, Accuracy:0.46715328467153283\n",
            "Epoch:260, Accuracy:0.45985401459854014\n",
            "Epoch:261, Accuracy:0.4635036496350365\n",
            "Epoch:262, Accuracy:0.46715328467153283\n",
            "Epoch:263, Accuracy:0.46715328467153283\n",
            "Epoch:264, Accuracy:0.4562043795620438\n",
            "Epoch:265, Accuracy:0.45985401459854014\n",
            "Epoch:266, Accuracy:0.46715328467153283\n",
            "Epoch:267, Accuracy:0.46715328467153283\n",
            "Epoch:268, Accuracy:0.45985401459854014\n",
            "Epoch:269, Accuracy:0.33211678832116787\n",
            "Epoch:270, Accuracy:0.46715328467153283\n",
            "Epoch:271, Accuracy:0.46715328467153283\n",
            "Epoch:272, Accuracy:0.4708029197080292\n",
            "Epoch:273, Accuracy:0.46715328467153283\n",
            "Epoch:274, Accuracy:0.4708029197080292\n",
            "Epoch:275, Accuracy:0.4744525547445255\n",
            "Epoch:276, Accuracy:0.4744525547445255\n",
            "Epoch:277, Accuracy:0.4744525547445255\n",
            "Epoch:278, Accuracy:0.4744525547445255\n",
            "Epoch:279, Accuracy:0.4744525547445255\n",
            "Epoch:280, Accuracy:0.4744525547445255\n",
            "Epoch:281, Accuracy:0.4744525547445255\n",
            "Epoch:282, Accuracy:0.4708029197080292\n",
            "Epoch:283, Accuracy:0.4744525547445255\n",
            "Epoch:284, Accuracy:0.4744525547445255\n",
            "Epoch:285, Accuracy:0.4744525547445255\n",
            "Epoch:286, Accuracy:0.4744525547445255\n",
            "Epoch:287, Accuracy:0.5766423357664233\n",
            "Epoch:288, Accuracy:0.572992700729927\n",
            "Epoch:289, Accuracy:0.572992700729927\n",
            "Epoch:290, Accuracy:0.583941605839416\n",
            "Epoch:291, Accuracy:0.5875912408759124\n",
            "Epoch:292, Accuracy:0.5766423357664233\n",
            "Epoch:293, Accuracy:0.5912408759124088\n",
            "Epoch:294, Accuracy:0.5912408759124088\n",
            "Epoch:295, Accuracy:0.5948905109489051\n",
            "Epoch:296, Accuracy:0.5948905109489051\n",
            "Epoch:297, Accuracy:0.5912408759124088\n",
            "Epoch:298, Accuracy:0.5948905109489051\n",
            "Epoch:299, Accuracy:0.5948905109489051\n",
            "Epoch:300, Accuracy:0.5948905109489051\n",
            "Epoch:301, Accuracy:0.5948905109489051\n",
            "Epoch:302, Accuracy:0.5948905109489051\n",
            "Epoch:303, Accuracy:0.5948905109489051\n",
            "Epoch:304, Accuracy:0.5948905109489051\n",
            "Epoch:305, Accuracy:0.5948905109489051\n",
            "Epoch:306, Accuracy:0.5912408759124088\n",
            "Epoch:307, Accuracy:0.5948905109489051\n",
            "Epoch:308, Accuracy:0.5948905109489051\n",
            "Epoch:309, Accuracy:0.5948905109489051\n",
            "Epoch:310, Accuracy:0.5875912408759124\n",
            "Epoch:311, Accuracy:0.5948905109489051\n",
            "Epoch:312, Accuracy:0.5912408759124088\n",
            "Epoch:313, Accuracy:0.5875912408759124\n",
            "Epoch:314, Accuracy:0.5912408759124088\n",
            "Epoch:315, Accuracy:0.5875912408759124\n",
            "Epoch:316, Accuracy:0.5948905109489051\n",
            "Epoch:317, Accuracy:0.5948905109489051\n",
            "Epoch:318, Accuracy:0.5948905109489051\n",
            "Epoch:319, Accuracy:0.5948905109489051\n",
            "Epoch:320, Accuracy:0.5912408759124088\n",
            "Epoch:321, Accuracy:0.5948905109489051\n",
            "Epoch:322, Accuracy:0.5912408759124088\n",
            "Epoch:323, Accuracy:0.5912408759124088\n",
            "Epoch:324, Accuracy:0.5693430656934306\n",
            "Epoch:325, Accuracy:0.5109489051094891\n",
            "Epoch:326, Accuracy:0.583941605839416\n",
            "Epoch:327, Accuracy:0.4708029197080292\n",
            "Epoch:328, Accuracy:0.19708029197080293\n",
            "Epoch:329, Accuracy:0.17153284671532848\n",
            "Epoch:330, Accuracy:0.16423357664233576\n",
            "Epoch:331, Accuracy:0.17153284671532848\n",
            "Epoch:332, Accuracy:0.17518248175182483\n",
            "Epoch:333, Accuracy:0.18248175182481752\n",
            "Epoch:334, Accuracy:0.17883211678832117\n",
            "Epoch:335, Accuracy:0.18613138686131386\n",
            "Epoch:336, Accuracy:0.18248175182481752\n",
            "Epoch:337, Accuracy:0.18613138686131386\n",
            "Epoch:338, Accuracy:0.18248175182481752\n",
            "Epoch:339, Accuracy:0.18248175182481752\n",
            "Epoch:340, Accuracy:0.18248175182481752\n",
            "Epoch:341, Accuracy:0.18613138686131386\n",
            "Epoch:342, Accuracy:0.19343065693430658\n",
            "Epoch:343, Accuracy:0.1897810218978102\n",
            "Epoch:344, Accuracy:0.19343065693430658\n",
            "Epoch:345, Accuracy:0.19343065693430658\n",
            "Epoch:346, Accuracy:0.19708029197080293\n",
            "Epoch:347, Accuracy:0.29927007299270075\n",
            "Epoch:348, Accuracy:0.29927007299270075\n",
            "Epoch:349, Accuracy:0.29927007299270075\n",
            "Epoch:350, Accuracy:0.29927007299270075\n",
            "Epoch:351, Accuracy:0.29927007299270075\n",
            "Epoch:352, Accuracy:0.29927007299270075\n",
            "Epoch:353, Accuracy:0.29927007299270075\n",
            "Epoch:354, Accuracy:0.29927007299270075\n",
            "Epoch:355, Accuracy:0.29927007299270075\n",
            "Epoch:356, Accuracy:0.29927007299270075\n",
            "Epoch:357, Accuracy:0.29927007299270075\n",
            "Epoch:358, Accuracy:0.29927007299270075\n",
            "Epoch:359, Accuracy:0.29927007299270075\n",
            "Epoch:360, Accuracy:0.29927007299270075\n",
            "Epoch:361, Accuracy:0.29927007299270075\n",
            "Epoch:362, Accuracy:0.29927007299270075\n",
            "Epoch:363, Accuracy:0.29927007299270075\n",
            "Epoch:364, Accuracy:0.29927007299270075\n",
            "Epoch:365, Accuracy:0.2956204379562044\n",
            "Epoch:366, Accuracy:0.2956204379562044\n",
            "Epoch:367, Accuracy:0.2956204379562044\n",
            "Epoch:368, Accuracy:0.2956204379562044\n",
            "Epoch:369, Accuracy:0.2956204379562044\n",
            "Epoch:370, Accuracy:0.2956204379562044\n",
            "Epoch:371, Accuracy:0.2956204379562044\n",
            "Epoch:372, Accuracy:0.2956204379562044\n",
            "Epoch:373, Accuracy:0.2956204379562044\n",
            "Epoch:374, Accuracy:0.2956204379562044\n",
            "Epoch:375, Accuracy:0.2956204379562044\n",
            "Epoch:376, Accuracy:0.2956204379562044\n",
            "Epoch:377, Accuracy:0.2956204379562044\n",
            "Epoch:378, Accuracy:0.2956204379562044\n",
            "Epoch:379, Accuracy:0.2956204379562044\n",
            "Epoch:380, Accuracy:0.2956204379562044\n",
            "Epoch:381, Accuracy:0.2956204379562044\n",
            "Epoch:382, Accuracy:0.2956204379562044\n",
            "Epoch:383, Accuracy:0.2956204379562044\n",
            "Epoch:384, Accuracy:0.2956204379562044\n",
            "Epoch:385, Accuracy:0.2956204379562044\n",
            "Epoch:386, Accuracy:0.2956204379562044\n",
            "Epoch:387, Accuracy:0.2956204379562044\n",
            "Epoch:388, Accuracy:0.2956204379562044\n",
            "Epoch:389, Accuracy:0.2956204379562044\n",
            "Epoch:390, Accuracy:0.2956204379562044\n",
            "Epoch:391, Accuracy:0.2956204379562044\n",
            "Epoch:392, Accuracy:0.2956204379562044\n",
            "Epoch:393, Accuracy:0.2956204379562044\n",
            "Epoch:394, Accuracy:0.2956204379562044\n",
            "Epoch:395, Accuracy:0.29927007299270075\n",
            "Epoch:396, Accuracy:0.29927007299270075\n",
            "Epoch:397, Accuracy:0.2956204379562044\n",
            "Epoch:398, Accuracy:0.2956204379562044\n",
            "Epoch:399, Accuracy:0.2773722627737226\n",
            "Epoch:400, Accuracy:0.2737226277372263\n",
            "Epoch:401, Accuracy:0.2773722627737226\n",
            "Epoch:402, Accuracy:0.2773722627737226\n",
            "Epoch:403, Accuracy:0.28102189781021897\n",
            "Epoch:404, Accuracy:0.2773722627737226\n",
            "Epoch:405, Accuracy:0.2737226277372263\n",
            "Epoch:406, Accuracy:0.28102189781021897\n",
            "Epoch:407, Accuracy:0.27007299270072993\n",
            "Epoch:408, Accuracy:0.28102189781021897\n",
            "Epoch:409, Accuracy:0.2846715328467153\n",
            "Epoch:410, Accuracy:0.2773722627737226\n",
            "Epoch:411, Accuracy:0.28102189781021897\n",
            "Epoch:412, Accuracy:0.2846715328467153\n",
            "Epoch:413, Accuracy:0.2846715328467153\n",
            "Epoch:414, Accuracy:0.2846715328467153\n",
            "Epoch:415, Accuracy:0.28102189781021897\n",
            "Epoch:416, Accuracy:0.2846715328467153\n",
            "Epoch:417, Accuracy:0.2846715328467153\n",
            "Epoch:418, Accuracy:0.2846715328467153\n",
            "Epoch:419, Accuracy:0.2846715328467153\n",
            "Epoch:420, Accuracy:0.2846715328467153\n",
            "Epoch:421, Accuracy:0.2846715328467153\n",
            "Epoch:422, Accuracy:0.2846715328467153\n",
            "Epoch:423, Accuracy:0.28832116788321166\n",
            "Epoch:424, Accuracy:0.28832116788321166\n",
            "Epoch:425, Accuracy:0.28832116788321166\n",
            "Epoch:426, Accuracy:0.28832116788321166\n",
            "Epoch:427, Accuracy:0.28832116788321166\n",
            "Epoch:428, Accuracy:0.28832116788321166\n",
            "Epoch:429, Accuracy:0.28832116788321166\n",
            "Epoch:430, Accuracy:0.28832116788321166\n",
            "Epoch:431, Accuracy:0.28832116788321166\n",
            "Epoch:432, Accuracy:0.28832116788321166\n",
            "Epoch:433, Accuracy:0.28832116788321166\n",
            "Epoch:434, Accuracy:0.28832116788321166\n",
            "Epoch:435, Accuracy:0.28832116788321166\n",
            "Epoch:436, Accuracy:0.28832116788321166\n",
            "Epoch:437, Accuracy:0.28832116788321166\n",
            "Epoch:438, Accuracy:0.28832116788321166\n",
            "Epoch:439, Accuracy:0.28832116788321166\n",
            "Epoch:440, Accuracy:0.28832116788321166\n",
            "Epoch:441, Accuracy:0.28832116788321166\n",
            "Epoch:442, Accuracy:0.28832116788321166\n",
            "Epoch:443, Accuracy:0.28832116788321166\n",
            "Epoch:444, Accuracy:0.28832116788321166\n",
            "Epoch:445, Accuracy:0.291970802919708\n",
            "Epoch:446, Accuracy:0.291970802919708\n",
            "Epoch:447, Accuracy:0.291970802919708\n",
            "Epoch:448, Accuracy:0.291970802919708\n",
            "Epoch:449, Accuracy:0.291970802919708\n",
            "Epoch:450, Accuracy:0.291970802919708\n",
            "Epoch:451, Accuracy:0.291970802919708\n",
            "Epoch:452, Accuracy:0.291970802919708\n",
            "Epoch:453, Accuracy:0.291970802919708\n",
            "Epoch:454, Accuracy:0.291970802919708\n",
            "Epoch:455, Accuracy:0.291970802919708\n",
            "Epoch:456, Accuracy:0.291970802919708\n",
            "Epoch:457, Accuracy:0.291970802919708\n",
            "Epoch:458, Accuracy:0.291970802919708\n",
            "Epoch:459, Accuracy:0.291970802919708\n",
            "Epoch:460, Accuracy:0.291970802919708\n",
            "Epoch:461, Accuracy:0.291970802919708\n",
            "Epoch:462, Accuracy:0.291970802919708\n",
            "Epoch:463, Accuracy:0.291970802919708\n",
            "Epoch:464, Accuracy:0.291970802919708\n",
            "Epoch:465, Accuracy:0.291970802919708\n",
            "Epoch:466, Accuracy:0.291970802919708\n",
            "Epoch:467, Accuracy:0.291970802919708\n",
            "Epoch:468, Accuracy:0.291970802919708\n",
            "Epoch:469, Accuracy:0.291970802919708\n",
            "Epoch:470, Accuracy:0.291970802919708\n",
            "Epoch:471, Accuracy:0.291970802919708\n",
            "Epoch:472, Accuracy:0.291970802919708\n",
            "Epoch:473, Accuracy:0.291970802919708\n",
            "Epoch:474, Accuracy:0.291970802919708\n",
            "Epoch:475, Accuracy:0.291970802919708\n",
            "Epoch:476, Accuracy:0.291970802919708\n",
            "Epoch:477, Accuracy:0.291970802919708\n",
            "Epoch:478, Accuracy:0.291970802919708\n",
            "Epoch:479, Accuracy:0.291970802919708\n",
            "Epoch:480, Accuracy:0.291970802919708\n",
            "Epoch:481, Accuracy:0.291970802919708\n",
            "Epoch:482, Accuracy:0.291970802919708\n",
            "Epoch:483, Accuracy:0.291970802919708\n",
            "Epoch:484, Accuracy:0.291970802919708\n",
            "Epoch:485, Accuracy:0.291970802919708\n",
            "Epoch:486, Accuracy:0.291970802919708\n",
            "Epoch:487, Accuracy:0.291970802919708\n",
            "Epoch:488, Accuracy:0.291970802919708\n",
            "Epoch:489, Accuracy:0.291970802919708\n",
            "Epoch:490, Accuracy:0.291970802919708\n",
            "Epoch:491, Accuracy:0.291970802919708\n",
            "Epoch:492, Accuracy:0.291970802919708\n",
            "Epoch:493, Accuracy:0.291970802919708\n",
            "Epoch:494, Accuracy:0.291970802919708\n",
            "Epoch:495, Accuracy:0.291970802919708\n",
            "Epoch:496, Accuracy:0.291970802919708\n",
            "Epoch:497, Accuracy:0.291970802919708\n",
            "Epoch:498, Accuracy:0.291970802919708\n",
            "Epoch:499, Accuracy:0.291970802919708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = True\n",
        "if torch.cuda.is_available():\n",
        "    model = CNNLargeNet2().cuda()\n",
        "Y = trainSmall(model, train_dataset, batch_size=64, learning_rate=0.005, num_epochs=260)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUfbTExPwd0U",
        "outputId": "162126e6-ea50-459e-c867-f6dfa2169b57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Start\n",
            "Epoch:0, Accuracy:0.07664233576642336\n",
            "Epoch:1, Accuracy:0.25547445255474455\n",
            "Epoch:2, Accuracy:0.07664233576642336\n",
            "Epoch:3, Accuracy:0.24817518248175183\n",
            "Epoch:4, Accuracy:0.2664233576642336\n",
            "Epoch:5, Accuracy:0.27007299270072993\n",
            "Epoch:6, Accuracy:0.26277372262773724\n",
            "Epoch:7, Accuracy:0.27007299270072993\n",
            "Epoch:8, Accuracy:0.29927007299270075\n",
            "Epoch:9, Accuracy:0.30656934306569344\n",
            "Epoch:10, Accuracy:0.31386861313868614\n",
            "Epoch:11, Accuracy:0.3029197080291971\n",
            "Epoch:12, Accuracy:0.29927007299270075\n",
            "Epoch:13, Accuracy:0.3102189781021898\n",
            "Epoch:14, Accuracy:0.3102189781021898\n",
            "Epoch:15, Accuracy:0.31386861313868614\n",
            "Epoch:16, Accuracy:0.291970802919708\n",
            "Epoch:17, Accuracy:0.3248175182481752\n",
            "Epoch:18, Accuracy:0.30656934306569344\n",
            "Epoch:19, Accuracy:0.31386861313868614\n",
            "Epoch:20, Accuracy:0.3029197080291971\n",
            "Epoch:21, Accuracy:0.291970802919708\n",
            "Epoch:22, Accuracy:0.29927007299270075\n",
            "Epoch:23, Accuracy:0.3029197080291971\n",
            "Epoch:24, Accuracy:0.3175182481751825\n",
            "Epoch:25, Accuracy:0.3248175182481752\n",
            "Epoch:26, Accuracy:0.32116788321167883\n",
            "Epoch:27, Accuracy:0.33941605839416056\n",
            "Epoch:28, Accuracy:0.34306569343065696\n",
            "Epoch:29, Accuracy:0.3357664233576642\n",
            "Epoch:30, Accuracy:0.35036496350364965\n",
            "Epoch:31, Accuracy:0.34306569343065696\n",
            "Epoch:32, Accuracy:0.34306569343065696\n",
            "Epoch:33, Accuracy:0.3613138686131387\n",
            "Epoch:34, Accuracy:0.3467153284671533\n",
            "Epoch:35, Accuracy:0.3795620437956204\n",
            "Epoch:36, Accuracy:0.36496350364963503\n",
            "Epoch:37, Accuracy:0.33941605839416056\n",
            "Epoch:38, Accuracy:0.31386861313868614\n",
            "Epoch:39, Accuracy:0.33941605839416056\n",
            "Epoch:40, Accuracy:0.34306569343065696\n",
            "Epoch:41, Accuracy:0.3795620437956204\n",
            "Epoch:42, Accuracy:0.3722627737226277\n",
            "Epoch:43, Accuracy:0.3759124087591241\n",
            "Epoch:44, Accuracy:0.3905109489051095\n",
            "Epoch:45, Accuracy:0.3978102189781022\n",
            "Epoch:46, Accuracy:0.42700729927007297\n",
            "Epoch:47, Accuracy:0.4124087591240876\n",
            "Epoch:48, Accuracy:0.3795620437956204\n",
            "Epoch:49, Accuracy:0.44525547445255476\n",
            "Epoch:50, Accuracy:0.42700729927007297\n",
            "Epoch:51, Accuracy:0.35036496350364965\n",
            "Epoch:52, Accuracy:0.39416058394160586\n",
            "Epoch:53, Accuracy:0.3978102189781022\n",
            "Epoch:54, Accuracy:0.4197080291970803\n",
            "Epoch:55, Accuracy:0.36496350364963503\n",
            "Epoch:56, Accuracy:0.354014598540146\n",
            "Epoch:57, Accuracy:0.33941605839416056\n",
            "Epoch:58, Accuracy:0.38321167883211676\n",
            "Epoch:59, Accuracy:0.3686131386861314\n",
            "Epoch:60, Accuracy:0.3759124087591241\n",
            "Epoch:61, Accuracy:0.42700729927007297\n",
            "Epoch:62, Accuracy:0.4562043795620438\n",
            "Epoch:63, Accuracy:0.45985401459854014\n",
            "Epoch:64, Accuracy:0.4744525547445255\n",
            "Epoch:65, Accuracy:0.5109489051094891\n",
            "Epoch:66, Accuracy:0.4854014598540146\n",
            "Epoch:67, Accuracy:0.3686131386861314\n",
            "Epoch:68, Accuracy:0.4781021897810219\n",
            "Epoch:69, Accuracy:0.4927007299270073\n",
            "Epoch:70, Accuracy:0.5620437956204379\n",
            "Epoch:71, Accuracy:0.42700729927007297\n",
            "Epoch:72, Accuracy:0.5036496350364964\n",
            "Epoch:73, Accuracy:0.46715328467153283\n",
            "Epoch:74, Accuracy:0.43795620437956206\n",
            "Epoch:75, Accuracy:0.45985401459854014\n",
            "Epoch:76, Accuracy:0.5036496350364964\n",
            "Epoch:77, Accuracy:0.4343065693430657\n",
            "Epoch:78, Accuracy:0.49635036496350365\n",
            "Epoch:79, Accuracy:0.5401459854014599\n",
            "Epoch:80, Accuracy:0.5328467153284672\n",
            "Epoch:81, Accuracy:0.6167883211678832\n",
            "Epoch:82, Accuracy:0.6496350364963503\n",
            "Epoch:83, Accuracy:0.5547445255474452\n",
            "Epoch:84, Accuracy:0.40145985401459855\n",
            "Epoch:85, Accuracy:0.635036496350365\n",
            "Epoch:86, Accuracy:0.5328467153284672\n",
            "Epoch:87, Accuracy:0.4562043795620438\n",
            "Epoch:88, Accuracy:0.5802919708029197\n",
            "Epoch:89, Accuracy:0.5145985401459854\n",
            "Epoch:90, Accuracy:0.5985401459854015\n",
            "Epoch:91, Accuracy:0.6021897810218978\n",
            "Epoch:92, Accuracy:0.44525547445255476\n",
            "Epoch:93, Accuracy:0.6678832116788321\n",
            "Epoch:94, Accuracy:0.6824817518248175\n",
            "Epoch:95, Accuracy:0.6386861313868614\n",
            "Epoch:96, Accuracy:0.6934306569343066\n",
            "Epoch:97, Accuracy:0.718978102189781\n",
            "Epoch:98, Accuracy:0.5072992700729927\n",
            "Epoch:99, Accuracy:0.6605839416058394\n",
            "Epoch:100, Accuracy:0.6751824817518248\n",
            "Epoch:101, Accuracy:0.635036496350365\n",
            "Epoch:102, Accuracy:0.7116788321167883\n",
            "Epoch:103, Accuracy:0.7846715328467153\n",
            "Epoch:104, Accuracy:0.781021897810219\n",
            "Epoch:105, Accuracy:0.4051094890510949\n",
            "Epoch:106, Accuracy:0.4233576642335766\n",
            "Epoch:107, Accuracy:0.3248175182481752\n",
            "Epoch:108, Accuracy:0.20802919708029197\n",
            "Epoch:109, Accuracy:0.4051094890510949\n",
            "Epoch:110, Accuracy:0.4489051094890511\n",
            "Epoch:111, Accuracy:0.43795620437956206\n",
            "Epoch:112, Accuracy:0.4744525547445255\n",
            "Epoch:113, Accuracy:0.5291970802919708\n",
            "Epoch:114, Accuracy:0.5255474452554745\n",
            "Epoch:115, Accuracy:0.5036496350364964\n",
            "Epoch:116, Accuracy:0.5401459854014599\n",
            "Epoch:117, Accuracy:0.5948905109489051\n",
            "Epoch:118, Accuracy:0.6167883211678832\n",
            "Epoch:119, Accuracy:0.6204379562043796\n",
            "Epoch:120, Accuracy:0.6423357664233577\n",
            "Epoch:121, Accuracy:0.635036496350365\n",
            "Epoch:122, Accuracy:0.6642335766423357\n",
            "Epoch:123, Accuracy:0.6496350364963503\n",
            "Epoch:124, Accuracy:0.6496350364963503\n",
            "Epoch:125, Accuracy:0.5656934306569343\n",
            "Epoch:126, Accuracy:0.42700729927007297\n",
            "Epoch:127, Accuracy:0.4343065693430657\n",
            "Epoch:128, Accuracy:0.4562043795620438\n",
            "Epoch:129, Accuracy:0.48175182481751827\n",
            "Epoch:130, Accuracy:0.5182481751824818\n",
            "Epoch:131, Accuracy:0.5255474452554745\n",
            "Epoch:132, Accuracy:0.5547445255474452\n",
            "Epoch:133, Accuracy:0.583941605839416\n",
            "Epoch:134, Accuracy:0.5437956204379562\n",
            "Epoch:135, Accuracy:0.6167883211678832\n",
            "Epoch:136, Accuracy:0.572992700729927\n",
            "Epoch:137, Accuracy:0.6861313868613139\n",
            "Epoch:138, Accuracy:0.6386861313868614\n",
            "Epoch:139, Accuracy:0.7043795620437956\n",
            "Epoch:140, Accuracy:0.6970802919708029\n",
            "Epoch:141, Accuracy:0.6496350364963503\n",
            "Epoch:142, Accuracy:0.7226277372262774\n",
            "Epoch:143, Accuracy:0.6934306569343066\n",
            "Epoch:144, Accuracy:0.7153284671532847\n",
            "Epoch:145, Accuracy:0.6824817518248175\n",
            "Epoch:146, Accuracy:0.7262773722627737\n",
            "Epoch:147, Accuracy:0.718978102189781\n",
            "Epoch:148, Accuracy:0.7226277372262774\n",
            "Epoch:149, Accuracy:0.656934306569343\n",
            "Epoch:150, Accuracy:0.6715328467153284\n",
            "Epoch:151, Accuracy:0.45985401459854014\n",
            "Epoch:152, Accuracy:0.6861313868613139\n",
            "Epoch:153, Accuracy:0.6277372262773723\n",
            "Epoch:154, Accuracy:0.551094890510949\n",
            "Epoch:155, Accuracy:0.583941605839416\n",
            "Epoch:156, Accuracy:0.5802919708029197\n",
            "Epoch:157, Accuracy:0.5364963503649635\n",
            "Epoch:158, Accuracy:0.6496350364963503\n",
            "Epoch:159, Accuracy:0.5255474452554745\n",
            "Epoch:160, Accuracy:0.635036496350365\n",
            "Epoch:161, Accuracy:0.7262773722627737\n",
            "Epoch:162, Accuracy:0.7518248175182481\n",
            "Epoch:163, Accuracy:0.7262773722627737\n",
            "Epoch:164, Accuracy:0.8102189781021898\n",
            "Epoch:165, Accuracy:0.8175182481751825\n",
            "Epoch:166, Accuracy:0.8138686131386861\n",
            "Epoch:167, Accuracy:0.8467153284671532\n",
            "Epoch:168, Accuracy:0.843065693430657\n",
            "Epoch:169, Accuracy:0.8576642335766423\n",
            "Epoch:170, Accuracy:0.8211678832116789\n",
            "Epoch:171, Accuracy:0.8138686131386861\n",
            "Epoch:172, Accuracy:0.843065693430657\n",
            "Epoch:173, Accuracy:0.791970802919708\n",
            "Epoch:174, Accuracy:0.6496350364963503\n",
            "Epoch:175, Accuracy:0.7481751824817519\n",
            "Epoch:176, Accuracy:0.5072992700729927\n",
            "Epoch:177, Accuracy:0.5036496350364964\n",
            "Epoch:178, Accuracy:0.6277372262773723\n",
            "Epoch:179, Accuracy:0.6715328467153284\n",
            "Epoch:180, Accuracy:0.7116788321167883\n",
            "Epoch:181, Accuracy:0.7846715328467153\n",
            "Epoch:182, Accuracy:0.7883211678832117\n",
            "Epoch:183, Accuracy:0.7627737226277372\n",
            "Epoch:184, Accuracy:0.7846715328467153\n",
            "Epoch:185, Accuracy:0.8248175182481752\n",
            "Epoch:186, Accuracy:0.8284671532846716\n",
            "Epoch:187, Accuracy:0.8540145985401459\n",
            "Epoch:188, Accuracy:0.8722627737226277\n",
            "Epoch:189, Accuracy:0.8759124087591241\n",
            "Epoch:190, Accuracy:0.8759124087591241\n",
            "Epoch:191, Accuracy:0.8941605839416058\n",
            "Epoch:192, Accuracy:0.9014598540145985\n",
            "Epoch:193, Accuracy:0.8941605839416058\n",
            "Epoch:194, Accuracy:0.8576642335766423\n",
            "Epoch:195, Accuracy:0.7408759124087592\n",
            "Epoch:196, Accuracy:0.8795620437956204\n",
            "Epoch:197, Accuracy:0.8138686131386861\n",
            "Epoch:198, Accuracy:0.6934306569343066\n",
            "Epoch:199, Accuracy:0.6934306569343066\n",
            "Epoch:200, Accuracy:0.7116788321167883\n",
            "Epoch:201, Accuracy:0.44525547445255476\n",
            "Epoch:202, Accuracy:0.5802919708029197\n",
            "Epoch:203, Accuracy:0.6824817518248175\n",
            "Epoch:204, Accuracy:0.7372262773722628\n",
            "Epoch:205, Accuracy:0.708029197080292\n",
            "Epoch:206, Accuracy:0.8102189781021898\n",
            "Epoch:207, Accuracy:0.8248175182481752\n",
            "Epoch:208, Accuracy:0.7700729927007299\n",
            "Epoch:209, Accuracy:0.8357664233576643\n",
            "Epoch:210, Accuracy:0.864963503649635\n",
            "Epoch:211, Accuracy:0.8941605839416058\n",
            "Epoch:212, Accuracy:0.916058394160584\n",
            "Epoch:213, Accuracy:0.9233576642335767\n",
            "Epoch:214, Accuracy:0.9197080291970803\n",
            "Epoch:215, Accuracy:0.927007299270073\n",
            "Epoch:216, Accuracy:0.9525547445255474\n",
            "Epoch:217, Accuracy:0.9452554744525548\n",
            "Epoch:218, Accuracy:0.9598540145985401\n",
            "Epoch:219, Accuracy:0.9671532846715328\n",
            "Epoch:220, Accuracy:0.9598540145985401\n",
            "Epoch:221, Accuracy:0.9744525547445255\n",
            "Epoch:222, Accuracy:0.948905109489051\n",
            "Epoch:223, Accuracy:0.9562043795620438\n",
            "Epoch:224, Accuracy:0.9598540145985401\n",
            "Epoch:225, Accuracy:0.927007299270073\n",
            "Epoch:226, Accuracy:0.9562043795620438\n",
            "Epoch:227, Accuracy:0.6715328467153284\n",
            "Epoch:228, Accuracy:0.38321167883211676\n",
            "Epoch:229, Accuracy:0.27007299270072993\n",
            "Epoch:230, Accuracy:0.4306569343065693\n",
            "Epoch:231, Accuracy:0.551094890510949\n",
            "Epoch:232, Accuracy:0.4927007299270073\n",
            "Epoch:233, Accuracy:0.46715328467153283\n",
            "Epoch:234, Accuracy:0.4562043795620438\n",
            "Epoch:235, Accuracy:0.4416058394160584\n",
            "Epoch:236, Accuracy:0.5109489051094891\n",
            "Epoch:237, Accuracy:0.5218978102189781\n",
            "Epoch:238, Accuracy:0.5656934306569343\n",
            "Epoch:239, Accuracy:0.5948905109489051\n",
            "Epoch:240, Accuracy:0.6094890510948905\n",
            "Epoch:241, Accuracy:0.6386861313868614\n",
            "Epoch:242, Accuracy:0.6277372262773723\n",
            "Epoch:243, Accuracy:0.6788321167883211\n",
            "Epoch:244, Accuracy:0.7226277372262774\n",
            "Epoch:245, Accuracy:0.7664233576642335\n",
            "Epoch:246, Accuracy:0.7737226277372263\n",
            "Epoch:247, Accuracy:0.7883211678832117\n",
            "Epoch:248, Accuracy:0.7992700729927007\n",
            "Epoch:249, Accuracy:0.7737226277372263\n",
            "Epoch:250, Accuracy:0.8576642335766423\n",
            "Epoch:251, Accuracy:0.843065693430657\n",
            "Epoch:252, Accuracy:0.8357664233576643\n",
            "Epoch:253, Accuracy:0.843065693430657\n",
            "Epoch:254, Accuracy:0.8613138686131386\n",
            "Epoch:255, Accuracy:0.8357664233576643\n",
            "Epoch:256, Accuracy:0.8832116788321168\n",
            "Epoch:257, Accuracy:0.8576642335766423\n",
            "Epoch:258, Accuracy:0.864963503649635\n",
            "Epoch:259, Accuracy:0.8211678832116789\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}